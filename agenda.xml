<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xml:id="agenda">
   <teiHeader>
      <fileDesc>
         <titleStmt>
            <title xml:lang="en">What's on the agenda?</title>
            <title xml:lang="en">Topic modelling parliamentary debates before and during the
               COVID-19 pandemic</title>
            <title xml:lang="sl">Kaj je na dnevnem redu?</title>
            <title xml:lang="sl">Tematsko modeliranje parlamentarnih razprav pred in med epidemijo
               covida-19</title>
            <author>
               <forename>Ajda</forename>
               <surname>Pretnar Žagar</surname>
            </author>
            <author>
               <forename>Kristina</forename>
               <surname>Pahor de Maiti</surname>
            </author>
            <author>
               <forename>Darja</forename>
               <surname>Fišer</surname>
            </author>
            <respStmt>
               <resp>Reviewer / Recenzenta</resp>
               <name>Çağrı Çöltekin</name>
               <name>Marta Kołczyńska</name>
            </respStmt>
            <respStmt>
               <resp>TEI Encoding / Kodiranje TEI</resp>
               <name>Andrej Pančur</name>
            </respStmt>
         </titleStmt>
         <editionStmt>
            <edition>Editon 1.0</edition>
         </editionStmt>
         <publicationStmt>
            <authority>CLARIN.SI</authority>
            <authority>DARIAH-SI</authority>
            <publisher>Inštitut za novejšo zgodovino / Institute of Contemporary History</publisher>
            <date when="2022">2022</date>
            <availability>
               <licence>http://creativecommons.org/licenses/by-nc-nd/4.0/</licence>
               <p>This work by Ajda Pretnar Žagar, Kristina Pahor de Maiti and Darja Fišer is
                  licensed under a <ref target="http://creativecommons.org/licenses/by-nc-nd/4.0/"
                     >Creative Commons Attribution Non-commercial Non-derivative 4.0 International
                     license</ref>
               </p>
               <p rend="CIP">Kataložni zapis o publikaciji (CIP) pripravili v Narodni in
                  univerzitetni knjižnici v Ljubljani&lt;br/&gt; &lt;a href="https://cobiss.si/"
                  target="_blank"&gt;COBISS.SI&lt;/a&gt;-ID=&lt;a
                  href="https://plus.si.cobiss.net/opac7/bib/67891971"
                  target="_blank"&gt;67891971&lt;/a&gt;&lt;br/&gt; ISBN 978-961-7104-06-6
                  (html)&lt;br/&gt;</p>
            </availability>
            <idno type="ISBN"/>
            <idno type="URI">https://sidih.github.io/agenda/</idno>
            <idno type="hdl">http://hdl.handle.net/20.500.12325/2177</idno>
            <idno type="COBISS.SI"/>
         </publicationStmt>
         <sourceDesc>
            <p>No source, born digital.</p>
         </sourceDesc>
      </fileDesc>
      <profileDesc>
         <abstract xml:lang="en">
            <p>In democratic countries, a parliament is a central representative and legislative
               institution. Digital transcripts of parliamentary sessions are a unique research
               source as they reflect the political, societal, and cultural atmosphere of a certain
               period. The transcripts are typically available in the form of parliamentary
               corpora.In democratic countries, a parliament is a central representative and
               legislative institution. Digital transcripts of parliamentary sessions are a unique
               research source as they reflect the political, societal, and cultural atmosphere of a
               certain period. The transcripts are typically available in the form of parliamentary
               corpora.</p>
            <p>In this tutorial, we will analyse the transcripts of parliamentary debates ParlaMint,
               for which we will employ advanced automatic analytical techniques, specifically topic
               modelling. The aim of the tutorial is to introduce researchers in the humanities and
               social sciences to text mining, showing the value of such approaches for research in
               these scientific fields. The tutorial breaks down the particularities of
               parliamentary discourse and topic modelling by answering concrete research
               questions.</p>
         </abstract>
         <abstract xml:lang="sl">
            <p>V demokratičnih državah parlament deluje kot osrednje predstavniško in zakonodajno
               telo. Digitalni zapisi parlamentarnih razprav omogočajo raziskovanje političnega,
               družbenega in kulturnega vzdušje določenega časa. Ti zapisi so raziskovalcem tipično
               na voljo v obliki korpusov.</p>
            <p>V tem učnem gradivu bomo analizirali zapise parlamentarnih debat ParlaMint, pri čemer
               bomo uporabili napredne avtomatske analitične tehnike oz. točneje tematsko
               modeliranje. Namen učnega gradiva je raziskovalke in raziskovalce s področja
               humanistike in družboslovja vpeljati v svet rudarjenja besedil ter prikazati vrednost
               tovrstnih pristopov za družboslovne in humanistične raziskave. Učno gradivo razlaga
               posebnosti parlamentarnega diskurza in uporabo tematskega modeliranja za reševanje
               konkretnih raziskovalnih vprašanj.</p>
         </abstract>
         <textClass>
            <keywords xml:lang="en">
               <term>parliamentary debates</term>
               <term>parliamentary corpora</term>
               <term>text mining</term>
               <term>topic modelling</term>
            </keywords>
            <keywords xml:lang="sl">
               <term>parlamentarne razprave</term>
               <term>parlamentarni korpusi</term>
               <term>rudarjenje besedil</term>
               <term>tematsko modeliranje</term>
            </keywords>
         </textClass>
         <langUsage>
            <language ident="en">
               <term xml:lang="en">English</term>
               <term xml:lang="sl">angleščina</term>
            </language>
            <language ident="sl">
               <term xml:lang="en">Slovenian</term>
               <term xml:lang="sl">slovenščina</term>
            </language>
         </langUsage>
      </profileDesc>
   </teiHeader>
   <text>
      <front>
         <titlePage>
            <docTitle>
               <titlePart xml:lang="en">What's on the agenda?</titlePart>
               <titlePart xml:lang="en">Topic modelling parliamentary debates before and during the
                  COVID-19 pandemic</titlePart>
               <titlePart xml:lang="sl">Kaj je na dnevnem redu?</titlePart>
               <titlePart xml:lang="sl">Tematsko modeliranje parlamentarnih razprav pred in med
                  epidemijo covida-19</titlePart>
            </docTitle>
            <docAuthor>Ajda Pretnar Žagar</docAuthor>
            <docAuthor>Kristina Pahor de Maiti</docAuthor>
            <docAuthor>Darja Fišer</docAuthor>
            <graphic url="https://sidih.si/cdn/2177/thumbnail.jpg"/>
            <docImprint>
               <publisher>Inštitut za novejšo zgodovino / Institute of Contemporary
                  History</publisher>
               <pubPlace>Ljubljana</pubPlace>
               <docDate>2022</docDate>
            </docImprint>
         </titlePage>
         <divGen type="cip" xml:id="cip" xml:lang="en" corresp="#cip-sl">
            <head>Colophon</head>
         </divGen>
         <divGen type="cip" xml:id="cip-sl" xml:lang="sl" corresp="#cip">
            <head>Kolofon</head>
         </divGen>
         <divGen type="toc" xml:id="toc" xml:lang="en" corresp="#sl-toc">
            <head>Table of Contents</head>
         </divGen>
         <divGen type="toc" xml:id="sl-toc" xml:lang="sl" corresp="#toc">
            <head>Kazalo vsebine</head>
         </divGen>
         <divGen type="search" xml:id="search" xml:lang="en" corresp="#sl-search">
            <head>Search</head>
         </divGen>
         <divGen type="search" xml:id="sl-search" xml:lang="sl" corresp="#search">
            <head>Iskanje</head>
         </divGen>
         <div type="preface" xml:id="preface1" xml:lang="en" corresp="#preface1-sl">
            <head xml:id="head-11">1. Introduction</head>
            <p xml:id="p-6">In democratic countries, a parliament is a central representative and
               legislative institution. It is composed of elected representatives through which the
               citizens have a voice in shaping and enacting laws and thus participate in governing
               all areas of life and social activities. In addition, the parliament often controls
               the executive branch (<ref target="#Norton.2002">Norton, 2002</ref>). Due to the
               parliament’s crucial role in the development of society, its activity has always been
               an important topic of research in the humanities and social sciences.</p>
            <p xml:id="p-7">In the last two decades, the progress of technology, the increased
               interest of the media and the citizens in the work of the parliament, and the desire
               for greater transparency have made the data about the parliamentary activity –
               including the records of parliamentary debates – more accessible (<ref
                  target="#Norton.2002">Norton, 2002</ref>). The records are a unique research
               source as the parliamentary debates reflect the political, societal, and cultural
               atmosphere of a certain period (<ref target="#Ilie.2010">Ilie, 2010</ref>). Since
               parliamentary discourse is highly regulated and parliamentary records are often
               available in digital form, they are a convenient source for building parliamentary
               corpora. These are temporally limited and structured collections of debate records
               with added metadata on the speakers and speeches and linguistic annotations (<ref
                  target="#Truan.2021">Truan and Romary, 2021</ref>).</p>
            <p xml:id="p-8">Usually, parliamentary corpora include large amounts of data that cannot
               be analysed by hand within a reasonable time frame. Concordancers are popular tools
               to analyse corpora. You can familiarize yourself with them in a <ref
                  target="https://sidih.github.io/voices/index.html">related tutorial</ref> (<ref
                  target="#Fišer.2021">Fišer and Pahor de Maiti, 2021</ref>). Other tools, such as
                  <ref target="https://orangedatamining.com/">Orange</ref> (<ref
                  target="#Demšar.2013">Demšar et al., 2013</ref>), used in this tutorial, enable
               text mining approaches which take large amounts of data to extract patterns and
               information that are not obvious from the text at first glance (<ref
                  target="#Wiedemann.2016">Wiedemann, 2016</ref>).</p>
            <p xml:id="p-9">Among other things, text mining techniques have been used for sentiment
               analysis of parliamentary debates (<ref target="#Rheault.2016">Rheault et al.,
                  2016</ref>; <ref target="#Rudkowsky.">Rudkowsky et al., 2017</ref>), for modelling
               policy conflict between the cabinet parties (<ref target="#Bergmann.2018">Bergmann et
                  al., 2018</ref>), for opinion mining (<ref target="#Abercrombie.2020">Abercrombie
                  and Batista-Navarro, 2020</ref>), modelling argumentation (<ref
                  target="#Petukhova.2015">Petukhova et al., 2015</ref>), etc. Among these, topic
               modelling (<ref target="#Meeks.2012">Meeks and Weingart, 2012</ref>) is one of the
               most often used text mining techniques in the digital humanities and the one that
               will be the focus of this tutorial.</p>
            <p xml:id="p-10">This tutorial introduces researchers in the humanities and social
               sciences to text mining and shows the value of such approaches for research in these
               scientific fields. The tutorial breaks down the particularities of parliamentary
               discourse and topic modelling by answering concrete research questions. The analysis
               is based on the freely accessible corpus of British parliamentary debates <ref
                  target="http://hdl.handle.net/11356/1432">ParlaMint</ref> (<ref
                  target="#Erjavec.2021">Erjavec et al., 2021</ref>) and the <ref
                  target="https://orangedatamining.com/">Orange</ref> tool (<ref
                  target="#Demšar.2013">Demšar et al., 2013</ref>), which enables the use of
               advanced text mining techniques without any programming knowledge.</p>
         </div>
         <div type="preface" xml:id="preface1-sl" xml:lang="sl" corresp="#preface1">
            <head xml:id="sl-head-1">1. Uvod</head>
            <p xml:id="sl-p-3">V demokratičnih državah parlament deluje kot osrednje predstavniško
               in zakonodajno telo. To pomeni, da ga sestavljajo izvoljeni predstavniki
                  državljanov<note place="foot" xml:id="ftn1-sl" n="1">V učnem gradivu uporabljamo
                  generični moški spol.</note>, ki v njihovem imenu sodelujejo pri oblikovanju in
               sprejemanju zakonov ter tako urejajo vsa področja življenja in delovanja v družbi.
               Parlament pogosto nadzoruje tudi delo izvršilne oblasti (<ref
                  target="#Norton.2002.sl">Norton, 2002</ref>). Zaradi ključne vloge, ki jo ima
               parlament pri razvoju in življenju družbe, je delovanje parlamenta vedno znova
               pomemben in aktualen predmet humanističnih in družboslovnih raziskav.</p>
            <p xml:id="sl-p-4">V zadnjih dveh desetletjih so zaradi napredka tehnologije, povečanega
               zanimanja medijev in državljanov za delo parlamenta ter želje po večji
               transparentnosti podatki o dogajanju v parlamentu, vključno z zapisi parlamentarnih
               sej, postali bolj dostopni (<ref target="#Norton.2002.sl">Norton, 2002</ref>). Zapisi
               sej so edinstven raziskovalni vir, saj parlamentarne razprave odsevajo politično,
               družbeno in kulturno vzdušje določenega časa (<ref target="#Ilie.2010.sl">Ilie,
                  2010</ref>). Zaradi ustaljenosti parlamentarnega diskurza in digitalnega formata
               pa so zapisi parlamentarnih sej tudi priročen vir za izdelavo parlamentarnih
               korpusov. Pri tem gre za časovno zamejene in strukturirane nabore zapisov sej, ki so
               dodatno opremljeni z metapodatki o govorcih in govorih ter jezikoslovnimi oznakami
                  (<ref target="#Truan.2021.sl">Truan in Romary, 2021</ref>).</p>
            <p xml:id="sl-p-5">Parlamentarni korpusi običajno vsebujejo velike količine podatkov, ki
               jih je v razumnem času nemogoče obdelati ročno. Eno od priljubljenih orodij za
               analizo korpusov so konkordančniki, s katerimi se lahko spoznate v <ref
                  target="https://sidih.github.io/voices/index-sl.html">
                  <hi rend="underline color(1155CC)">sorodnem učnem gradivu</hi>
               </ref> (gl. <ref target="#Fišer.2021.sl">Fišer in Pahor de Maiti, 2021</ref>), druga
               orodja, npr. <ref target="https://orangedatamining.com/">
                  <hi rend="underline color(1155CC)">Orange</hi>
               </ref> (<ref target="#Demšar.2013.sl">Demšar idr., 2013</ref>), ki ga bomo
               uporabljali v tem učnem gradivu, pa omogočajo uporabo naprednih avtomatskih
               analitičnih tehnik oz. t. i. rudarjenje besedil, na podlagi katerega je iz velikih
               količin podatkov mogoče izluščiti vzorce in informacije, ki na prvi pogled niso
               razvidni iz besedila (<ref target="#Wiedemann.2016.sl">Wiedemann, 2016</ref>).</p>
            <p xml:id="sl-p-6">Tehnike rudarjenja besedil so raznovrstne in se jih med drugim
               uporablja za analizo čustvene zaznamovanosti parlamentarnih razprav (<ref
                  target="#Rheault.2016.sl">Rheault idr., 2016</ref>; <ref target="#Rudkowsky..sl"
                  >Rudkowsky idr., n.d.</ref>), prepoznavo politične opredelitve (<ref
                  target="#Bergmann.2018.sl">Bergmann idr., 2018</ref>) ali stališča poslancev (<ref
                  target="#Abercrombie.2020.sl">Abercrombie in Batista-Navarro, 2020</ref>),
               modeliranje argumentacije v parlamentarnih razpravah (<ref
                  target="#Petukhova.2015.sl">Petukhova idr., 2015</ref>) in podobno. Ena od njih je
               tudi tematsko modeliranje (<ref target="#Meeks.2012.sl">Meeks in Weingart,
               2012</ref>), ki sodi med najbolj razširjene tehnike s področja besedilnega rudarjenja
               v digitalni humanistiki in ki se ji bomo posvetili v tem učnem gradivu.</p>
            <p xml:id="sl-p-7">Namen učnega gradiva je raziskovalce s področja humanistike in
               družboslovja vpeljati v svet rudarjenja besedil ter prikazati vrednost tovrstnih
               pristopov za družboslovne in humanistične raziskave. Učno gradivo razlaga posebnosti
               parlamentarnega diskurza in uporabo tematskega modeliranja za reševanje konkretnih
               raziskovalnih vprašanj. Analiza temelji na prosto dostopnem korpusu slovenskih
               parlamentarnih razprav <ref target="http://hdl.handle.net/11356/1432">
                  <hi rend="underline color(1155CC)">ParlaMint</hi>
               </ref> (<ref target="#Erjavec.2021.sl">Erjavec idr., 2021</ref>) ter na orodju <ref
                  target="https://orangedatamining.com/">
                  <hi rend="underline color(1155CC)">Orange</hi>
               </ref> (<ref target="#Demšar.2013.sl">Demšar idr., 2013</ref>), ki uporabniku brez
               znanja programiranja omogoča uporabo naprednih metod rudarjenja besedil.</p>
         </div>
         <div type="preface" xml:id="preface2" xml:lang="en" corresp="#preface2-sl">
            <head xml:id="head-12">2. Tutorial overview and instructions</head>
            <p xml:id="p-11">The tutorial is divided into the theoretical and empirical parts. In
               the theoretical part, the characteristics of parliamentary debates and the ParlaMint
               corpora are presented in <ref target="#ch3">Chapter 3</ref> and the topic modelling
               method in <ref target="#ch4">Chapter 4</ref>. The empirical part begins with <ref
                  target="#ch5">Chapter 5</ref>, guiding the reader through analysis preparation and
               explaining how to set up the Orange software, import and check the data, and prepare
               a data sample for the analysis. <ref target="#ch6">Chapter 6</ref> moves on to the
               central empirical part of the tutorial, composed of three related tasks. The tasks
               use topic modelling and various visualisations to explore the topics of the debates
               and the prominence of different topics in general and during the COVID-19
               pandemic.</p>
            <p xml:id="p-12">All the resources and tools used in this tutorial are freely accessible
               online. You can find the detailed instructions on downloading the <ref
                  target="http://hdl.handle.net/11356/1432">ParlaMint</ref> data and setting up the
                  <ref target="https://orangedatamining.com/">Orange</ref> software in <ref
                  target="#ch5">Chapter 5</ref>. If you are mainly interested in analysing texts in
               Orange, you can begin with <ref target="#ch5">Chapter 5</ref>. However, we recommend
               reading the introductory theoretical chapters containing key information on
               understanding the data and the topic modelling method. Reading the entire tutorial
               will reduce the possibility of non-critical use of the method and inappropriate
               interpretation of the results.</p>
            <p xml:id="p-13">Alongside the descriptions of the procedures, the materials include
               numerous screenshots that show widget<note place="foot" xml:id="ftn1" n="1">Building
                  blocks performing different steps of the analysis.</note> settings and results. At
               the beginning and end of each task, you will find the workflow with the sequence of
               widgets used. The complete workflow is available for download in <ref target="#ch5.1"
                  >Chapter 5.1</ref>. However, we recommend that you create your own workflow by
               following the instructions in the tutorial in order to better understand the
               individual steps of the analysis. The <hi rend="bold">widget </hi>names are typeset
               in bold, while <hi rend="italic">widget settings</hi>, <hi rend="italic">variable
                  names, search queries </hi>and<hi rend="italic"> discussed words</hi> are
               italicized.</p>
            <p xml:id="p-14">Certain steps of the tutorial might be quite laborious for some
               computers which results in the process in Orange being stuck or aborted. In this
               case, you can opt for <hi rend="italic">Option 2</hi> instructions which will be
               provided in the relevant parts of the tutorial.</p>
            <note rend="bluebox" xml:id="note-2">
               <p>The orange <hi rend="italic">Try-it-yourself</hi> frames include instructions for
                  independent research and help you consolidate the acquired knowledge.</p>
            </note>
         </div>
         <div type="preface" xml:id="preface2-sl" xml:lang="sl" corresp="#preface2">
            <head xml:id="sl-head-2">2. Pregled učnega gradiva in navodila za uporabo</head>
            <p xml:id="sl-p-8">Učno gradivo je razdeljeno na teoretični in praktični del. V
               teoretičnem delu predstavimo značilnosti parlamentarnih razprav in korpus ParlaMint
                  (<ref target="#ch3-sl">3. poglavje</ref>) ter metodo tematskega modeliranja (<ref
                  target="#ch4-sl">4. poglavje</ref>). Praktični del se začne s poglavjem, ki nas
               vodi skozi pripravo na analizo in v katerem je razloženo, kako namestiti program
               Orange, uvoziti in pregledati podatke ter pripraviti vzorec podatkov za analizo (<ref
                  target="#ch5-sl">5. poglavje</ref>). V naslednjem poglavju preidemo na osrednji
               praktični del učnega gradiva (<ref target="#ch6-sl">6. poglavje</ref>), ki ga
               sestavljajo tri povezane naloge. V teh nalogah z metodo tematskega modeliranja in
               različnimi vizualizacijami raziščemo, o čem so govorili poslanci, kateri temi so
               posvetili največ pozornosti in katere teme so še posebej izstopale med epidemijo v
               primerjavi s predepidemičnim obdobjem.</p>
            <p xml:id="sl-p-9">Vsi viri in orodja, uporabljeni v tem učnem gradivu, so prosto
               dostopni na spletu. Podrobna navodila glede prenosa podatkov <ref
                  target="http://hdl.handle.net/11356/1432">ParlaMint</ref> in namestitve programa
                  <ref target="https://orangedatamining.com/">Orange</ref> so navedena v <ref
                  target="#ch5.1-sl">poglavju 5.1</ref>. Če vas zanima predvsem analiza besedil v
               programu Orange, lahko začnete s <ref target="#ch5-sl">5. poglavjem</ref>, vendar
               priporočamo, da si preberete tudi začetna teoretična poglavja, saj vsebujejo ključne
               informacije za razumevanje podatkov in metode tematskega modeliranja, kar zmanjša
               možnost za nekritično uporabo metode in neustrezno interpretacijo rezultatov.</p>
            <p xml:id="sl-p-10">Poleg opisa postopkov učno gradivo vsebuje tudi številne posnetke
               zaslonov, ki prikazujejo nastavitve gradnikov<note place="foot" xml:id="ftn2-sl"
                  n="2">Gradniki predstavljajo posamezne korake analize.</note> in dobljene
               rezultate. Na začetku in koncu vsake naloge je prikazan delotok, ki prikazuje
               sosledje uporabljenih gradnikov. Celoten delotok je na voljo za prenos v <ref
                  target="#ch5.1-sl">poglavju 5.1</ref>, vendar priporočamo, da delotok sestavite
               sami ob sledenju navodilom v učnem gradivu, saj boste tako najbolje razumeli
               posamezne korake analize. Imena <hi rend="bold">gradnikov </hi>so v besedilu zapisana
               odebeljeno, <hi rend="italic">nastavitve gradnikov</hi>, <hi rend="italic">imena
                  spremenljivk, iskalni ukazi, obravnavane besede</hi> ter <hi rend="italic"
                  >angleške ustreznice izrazov</hi> pa so označene ležeče.</p>
            <note rend="bluebox" xml:id="sl-note-3">
               <p>Oranžni okvirčki <hi rend="italic">Poskusite sami</hi> vsebujejo navodila za
                  samostojno raziskovanje podatkov in utrjevanje pridobljenega znanja.</p>
            </note>
         </div>
      </front>
      <body>
         <div type="chapter" xml:id="ch3" xml:lang="en" corresp="#ch3-sl">
            <head xml:id="head-13">3. Parliamentary debates</head>
            <p xml:id="p-16">The tutorial analyses MPs’ speeches during parliamentary sessions. This
               chapter focuses on certain general characteristics of parliamentary debates since
               knowing the data well is crucial for developing research questions and interpreting
               results.</p>
            <div type="subchapter" xml:id="ch3.1">
               <head xml:id="head-14">3.1. Characteristics of parliamentary debates</head>
               <p xml:id="p-17">Parliament is a central political institution. Its institutional
                  nature dictates a clearly defined structure and complex rules of its
                     activities,<note place="foot" xml:id="ftn2" n="2">The key and binding rules of
                     procedure governing parliamentary organisation and work as well as the MPs’
                     rights and obligations are codified in the rules of procedure of individual
                     parliaments, i.e., <ref
                        target="http://www.pisrs.si/Pis.web/pregledPredpisa?id=POSL34">the Rules of
                        Procedure of Slovenian National Assembly</ref>, <ref
                        target="https://erskinemay.parliament.uk/">the Rules of Procedure of the UK
                        Parliament</ref>,<ref
                        target="https://www.btg-bestellservice.de/pdf/80060000.pdf"/>
                     <ref target="https://www.btg-bestellservice.de/pdf/80060000.pdf">the Rules of
                        Procedure of the German Bundestag</ref>, etc.</note> while numerous informal
                  conventions have developed through history, too (<ref target="#Norton.2002"
                     >Norton, 2002</ref>). These rules differ from parliament to parliament, and
                  they change over time (<ref target="#Sieberer.2011">Sieberer et al., 2011</ref>).
                  Therefore, they must be known to the researcher(s) for appropriate analysis design
                  and data interpretation. The research also has to consider local and global
                  political contexts, power relations among MPs and their various public and private
                  roles, and the different audiences present at the debate (e.g., other MPs, guests,
                  and the public) (<ref target="#Ilie.2010">Ilie, 2010</ref>).</p>
               <p xml:id="p-18">Parliamentary sessions follow a clear structure; they have a defined
                  agenda, a designated person leads them, and the floor is passed from one person to
                  another following clear rules (see <ref target="#Proksch.2010">Proksch and Slapin,
                     2010</ref>). Special rules also apply to specific items on the agenda or the
                  types of debates, e.g., to MPs’ questions and initiatives or interpellations. The
                  structure bears great importance in shaping and limiting parliamentary debates,
                  i.e., the acts of communication in the specific parliamentary environment.</p>
               <p xml:id="p-19">A part of the broader concept of political discourse, parliamentary
                  discourse is its most institutionalised and formal subtype strictly governed by
                  rules (<ref target="#Bayley.2004">Bayley, 2004</ref>). It is a key characteristic
                  of a parliament, which is the central space for the political debate of a
                  community. Here, not only the contents of the debate matter but also the style of
                  speaking, i.e., the discursive strategies that the speakers use in their speeches,
                  and other, non-linguistic circumstances. Therefore, research of parliamentary
                  activities uses an increasingly interdisciplinary approach to the material, which
                  enables comprehensive interpretation of events and processes of causes and
                  consequences (<ref target="#Bayley.2004">Bayley, 2004</ref>; <ref
                     target="#Ilie.2010">Ilie, 2010</ref>).</p>
            </div>
            <div type="subchapter" xml:id="ch3.2">
               <head xml:id="head-15">3.2. Parliamentary corpora</head>
               <p xml:id="p-20">The primary source for the research of parliamentary discourse are
                  the records of parliamentary debates. For most parliaments, they are transcribed
                  and publicly accessible in digital form. Digital form is important both for the
                  public and the research community, yet the actual usefulness of the records
                  depends on the focus of the research (see <ref target="#Mollin.2007">Mollin,
                     2007</ref>). Much like parliamentary discourse, the records have their
                  particularities which originate from the nature of their source (spoken texts) and
                  from different transcribing traditions of individual parliaments (transcription
                  guidelines differ from parliament to parliament and are generally not made
                  public). As formal written sources, parliamentary records are undoubtedly credible
                  in terms of their content – but not necessarily so when compared to the actual
                  spoken text. The records are <ref target="ch4.2-sl">not exact transcriptions of
                     the speeches</ref> and, therefore, usually lack some or all elements of spoken
                  language (e.g., fillers, false starts) and the information on the non-verbal
                  communication (e.g., interruptions, gestures) (<ref target="#Bayley.2004">Bayley,
                     2004</ref>). However, they often include additional information or metadata,
                  such as the list of speakers, voting results, the material discussed, etc.</p>
               <p xml:id="p-21">Parliamentary records in digital form are a convenient source for
                     <ref target="https://www.clarin.eu/resource-families/parliamentary-corpora"
                     >parliamentary corpora</ref>, i.e., structured collections of texts enriched
                  with various data. Parliamentary corpora usually include rich metadata that
                  contains varied information on the session (e.g., date, type, agenda), speeches
                  and speakers (e.g., name, date of birth, party affiliation). They are generally
                  abundant in linguistic annotations (e.g., part of speech, basic word form, named
                  entity). Researchers can use these annotations and metadata to perform various
                  kinds of analyses apart from the simple content analysis of the textual data (see
                     <ref target="#Pančur.2016">Pančur and Šorn, 2016</ref>).</p>
               <p xml:id="p-22">Due to their rich metadata and continuity, <ref
                     target="https://www.clarin.eu/resource-families/parliamentary-corpora"
                     >parliamentary corpora</ref> are invaluable for various research areas, which
                  have grown increasingly interconnected. They include linguistics (<ref
                     target="#Bayley.2004">Bayley, 2004</ref>), history (<ref target="#Piersma.2014"
                     >Piersma et al., 2014</ref>), political science (<ref target="#Rheault.2020"
                     >Rheault and Cochrane, 2020</ref>), demographics (<ref target="#Kilroy.2021"
                     >Kilroy, 2021</ref>), etc. Researchers can access parliamentary corpora through
                     <ref target="https://sidih.github.io/voices/ch3-sl.html">concordancers</ref>
                  (i.e., web tools for researching and analysing corpora) or <ref
                     target="https://www.clarin.si/repository/xmlui/discover?query=parl*&amp;submit=I%C5%A1%C4%8Di&amp;filtertype_2=title&amp;filter_relational_operator_2=contains&amp;filter_2=&amp;query=parl*"
                     >repo</ref>
                  <ref
                     target="https://www.clarin.si/repository/xmlui/discover?query=parl*&amp;submit=I%C5%A1%C4%8Di&amp;filtertype_2=title&amp;filter_relational_operator_2=contains&amp;filter_2=&amp;query=parl*"
                     >sitories of language data resources</ref>, which provide access to entire
                  corpora in various formats to be analysed with different tools. The latter option
                  will be chosen for this tutorial (see <ref target="#ch5.2">Chapter 5.2</ref>).</p>
            </div>
            <div type="subchapter" xml:id="ch3.3">
               <head xml:id="head-16">3.3. The ParlaMint corpus</head>
               <p xml:id="p-23">The tutorial will use data from the family of <ref
                     target="http://hdl.handle.net/11356/1432">ParlaMint</ref> corpora (<ref
                     target="#Erjavec.2021">Erjavec et al., 2021</ref>), which contains
                  parliamentary debate records from 17 countries: Belgium, Bulgaria, Croatia, the
                  Czech Republic, Denmark, France, Great Britain, Hungary, Iceland, Italy, Latvia,
                  Lithuania, the Netherlands, Poland, Romania, Slovenia, and Turkey. Most ParlaMint
                  corpora cover the period from 2015 to mid-2020 or more. Designed by the research
                  infrastructure for language resources and technologies <ref
                     target="https://www.clarin.eu/">CLARIN </ref>
                  <ref target="https://www.clarin.eu/">ERIC</ref>, this corpus family contains 500
                  million words in 5 million speeches produced by around 11 thousand speakers. The
                  ParlaMint corpora are divided into two sub-corpora: <hi rend="italic"
                     >Reference</hi> (i.e., the reference period) and <hi rend="italic">COVID</hi>,
                  which mark the periods before and during the COVID-19 pandemic (i.e., <hi
                     rend="italic">Reference </hi>before November 2019; <hi rend="italic">COVID</hi>
                  from November 2019 onwards).</p>
               <p xml:id="p-24">Each national corpus has been encoded following the same scheme
                  based on the <ref target="https://clarin-eric.github.io/parla-clarin/"
                     >Parla-CLARIN</ref> encoding recommendations (<ref target="#Erjavec.2019"
                     >Erjavec and Pančur, 2019</ref>). Common encoding ensures that the national
                  parts of ParlaMint are comparable which makes ParlaMint a valuable resource for
                  comparative and transnational analyses that have so far been difficult to perform.
                  Furthermore, ParlaMint covers a diverse set of European countries, which increases
                  the possibilities of exploring different non-Western parliamentary democracies and
                  acquiring new knowledge about parliamentary systems. This is crucial given that
                  previous research mostly centred around Western countries and especially because
                  comparative research proved very important in improving our understanding of
                  positive and negative parliamentary practices and advancing the development of
                  parliamentary systems (<ref target="#Norton.2002">Norton, 2002</ref>).</p>
               <p xml:id="p-25">The tutorial uses the British ParlaMint corpus, ParlaMint-GB, which
                  encompasses the debates from the House of Lords and the House of Commons. The
                  House of Lords currently has 300 members, most of whom are elected, while the rest
                  are appointed. It reviews bills proposed by the House of Commons. The House of
                  Commons consists of 650 elected members and has the primary legislative function.
                  ParlaMint-GB covers four parliamentary terms between January 2015 and March 2021,
                  and holds around 100 million words (<ref target="#Erjavec.2022">Erjavec et al.,
                     2022</ref>). The tutorial will use the <ref
                     target="https://www.clarin.si/repository/xmlui/handle/11356/1431"
                     >linguistically annotated version of the corpus </ref>
                  <ref target="https://www.clarin.si/repository/xmlui/handle/11356/1431">2.1</ref>
                     (<ref target="#Erjavec.2021">Erjavec et al., 2021b</ref>), which includes
                  sentence segmentation (the sentences are delimited), tokenization (tokens, numbers
                  and punctuation marks are defined as the basic analytical unit), lemmatisation,
                  morphosyntactic annotations, and named entities (see <ref target="#ch5.3">Chapter
                     5.3</ref>).</p>
            </div>
         </div>
         <div type="chapter" xml:id="ch3-sl" xml:lang="sl" corresp="#ch3">
            <head xml:id="sl-head-3">3. Parlamentarne razprave</head>
            <p xml:id="sl-p-12">V učnem gradivu analiziramo govore poslancev na parlamentarnih
               sejah. V tem poglavju se zato najprej posvetimo nekaterim splošnim značilnostim, ki
               veljajo za parlamentarne razprave, saj je dobro poznavanje gradiva ključnega pomena
               tako pri oblikovanju raziskovalnih vprašanj kot pri interpretaciji rezultatov.</p>
            <div type="subchapter" xml:id="ch3.1-sl">
               <head xml:id="sl-head-4">3.1. Parlamentarne razprave</head>
               <p xml:id="sl-p-13">Zaradi svoje institucionalne narave ima parlament jasno določeno
                  strukturo in kompleksna pravila delovanja<note place="foot" xml:id="ftn3-sl" n="3"
                     >Ključna in zavezujoča pravila delovanja, ki urejajo organizacijo in delo
                     parlamenta ter pravice in dolžnosti parlamentarcev, so zapisana v poslovnikih
                     posameznega parlamenta, npr. <ref
                        target="http://www.pisrs.si/Pis.web/pregledPredpisa?id=POSL34">v poslovniku
                        slovenskega državnega zbora</ref>, <ref
                        target="https://erskinemay.parliament.uk/">poslovniku britanskega
                        parlamenta</ref>, <ref
                        target="https://www.btg-bestellservice.de/pdf/80060000.pdf">poslovniku
                        nemškega zveznega parlamenta</ref> itd.</note>, skozi zgodovino pa so se
                  oblikovali tudi številni neformalni dogovori obnašanja (<ref
                     target="#Norton.2002.sl">Norton, 2002</ref>). Ta pravila se med posameznimi
                  parlamenti razlikujejo, spreminjajo pa se tudi skozi čas (<ref
                     target="#Sieberer.2011.sl">Sieberer idr., 2011</ref>), zato jih je za ustrezno
                  zasnovo analize in interpretacijo podatkov nujno treba poznati. Poleg tega se je
                  pri analizi treba zavedati tudi vpliva, ki ga imajo na parlamentarne razprave
                  lokalni in globalni politični kontekst, različne javne in zasebne vloge
                  parlamentarcev in razmerja moči med njimi ter različna občinstva, ki lahko
                  spremljajo isto razpravo (npr. ostali parlamentarci, gosti, javnost) (<ref
                     target="#Ilie.2010.sl">Ilie, 2010</ref>).</p>
               <p xml:id="sl-p-14">Parlamentarne seje so vedno natančno strukturirane: imajo torej
                  opredeljen dnevni red, seje vodi za to določena oseba, predajanje besede pa poteka
                  po jasnih pravilih (prim. <ref target="#Proksch.2010.sl">Proksch in Slapin,
                     2010</ref>). Posebna pravila veljajo tudi za specifične točke dnevnega reda
                  oziroma vrste razprav, npr. za poslanska vprašanja in pobude ali za interpelacije.
                  Vse to pomembno oblikuje in omejuje parlamentarni diskurz, tj. dejanje
                  sporazumevanja v specifičnem okolju parlamenta.</p>
               <p xml:id="sl-p-15">Parlamentarni diskurz je sicer le del širšega pojma političnega
                  diskurza, znotraj katerega predstavlja najbolj institucionalizirani, s pravili
                  zamejeni in uradni podtip (<ref target="#Bayley.2004.sl">Bayley, 2004</ref>).
                  Parlamentarni diskurz je tako ključna značilnost parlamenta, ki je osrednji
                  prostor skupnosti za politično razpravo. Pri tem pa ni pomembna zgolj vsebina
                  razprave, ampak v veliki meri tudi način govora oziroma diskurzivne strategije, ki
                  jih govorci uporabljajo v svojih govorih, ter ostale, nejezikovne okoliščine.
                  Trend raziskav parlamentarnega dogajanja gre zato vse bolj v smeri
                  interdisciplinarnega pristopa h gradivu, ki omogoča široko interpretacijo dogodkov
                  in procesov, vzrokov in posledic (<ref target="#Bayley.2004.sl">Bayley,
                  2004</ref>; <ref target="#Ilie.2010.sl">Ilie, 2010</ref>).</p>
            </div>
            <div type="subchapter" xml:id="ch3.2-sl">
               <head xml:id="sl-head-5">3.2. Korpusi parlamentarnih razprav</head>
               <p xml:id="sl-p-16">Temeljni vir za raziskovanje parlamentarnega diskurza so zapisi
                  parlamentarnih sej, ki so za večino parlamentov že javno dostopni v digitalni
                  obliki. Obstoj zapisov, predvsem pa njihova dostopnost v digitalni obliki je
                  izjemnega pomena tako za javnost, saj lajša nadzor nad delom parlamenta, kot tudi
                  za raziskovalno skupnost, vendar je dejanska uporabnost zapisov odvisna od
                  raziskovalnega problema (prim. <ref target="#Mollin.2007.sl">Mollin, 2007</ref>).
                  Tako kot parlamentarni diskurz imajo namreč tudi zapisi sej svoje posebnosti, ki
                  izhajajo iz tradicije zapisovanja, ki velja v posameznem parlamentu (smernice za
                  zapisovanje se med parlamenti razlikujejo in običajno niso prosto dostopne), in iz
                  dejstva, da so zapisi pisna različica sicer govorjenih nastopov poslancev. Zapisi
                  parlamentarnih sej kot uradni pisni viri so nedvomno verodostojni na ravni
                  vsebine, ne pa nujno tudi na ravni izgovorjenega besedila. Zapisi namreč <ref
                     target="ch4.2-sl">
                     <hi rend="underline color(0000FF)">niso natančne transkripcije govorov</hi>
                  </ref> in zato običajno ne vsebujejo, vsaj ne v celoti, prvin govorjenega jezika
                  (npr. mašil, popravkov) in številnih informacij o neverbalni komunikaciji v
                  dvorani (npr. prekinitev, gest), ki jih je sicer mogoče zaznati ob spremljanju
                  dejanskega nastopa govorcev (<ref target="#Bayley.2004.sl">Bayley, 2004</ref>).
                  Pogosto pa zapisi vsebujejo tudi različne dodatne informacije oziroma metapodatke,
                  npr. seznam govorcev, rezultate glasovanja, obravnavano gradivo ipd.</p>
               <p xml:id="sl-p-17">Parlamentarni zapisi v digitalni obliki so priročen vir za
                  izdelavo <ref target="https://sidih.github.io/voices/ch3-sl.html">
                     <hi rend="underline color(0000FF)">parlamentarnih korpusov</hi>
                  </ref>, torej strukturiranih zbirk besedil, ki so obogatena z različnimi
                  informacijami. Glede na dostopno gradivo so lahko parlamentarni korpusi tudi
                  večmodalni, če poleg besedila vsebujejo tudi zvočne in/ali video posnetke, npr.
                     <ref
                     target="https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0005-CF9C-4">
                     <hi rend="underline color(0000FF)">korpus razprav iz češkega parlamenta</hi>
                  </ref>. Parlamentarni korpusi običajno vsebujejo bogate metapodatke, ki
                  vključujejo raznovrstne podatke o sejah (npr. datum, vrsta seje, dnevni red),
                  govorih in govorcih (npr. ime, datum rojstva, strankarska pripadnost), običajno pa
                  so tudi bogato jezikoslovno označeni (npr. besedne vrste, osnovna oblika besede,
                  imenske entitete). Vse te oznake raziskovalcem omogočajo, da pri oblikovanju
                  raziskovalnih vprašanj upoštevajo tudi različne kombinacije spremenljivk (glejte
                     <ref target="#Pančur.2016.sl">Pančur in Šorn, 2016</ref>).</p>
               <p xml:id="sl-p-18">Ravno zaradi bogatih informacij in kontinuiranosti so <ref
                     target="https://www.clarin.eu/resource-families/parliamentary-corpora"
                     >parlamentarni korpusi</ref> vir informacij za vrsto področij, ki se pri
                  raziskovanju vse bolj prepletajo, mdr. za jezikoslovje (<ref
                     target="#Bayley.2004.sl">Bayley, 2004</ref>), zgodovino (<ref
                     target="#Piersma.2014.sl">Piersma idr., 2014</ref>), politične vede (<ref
                     target="#Rheault.2020.sl">Rheault in Cochrane, 2020</ref>), demografijo (<ref
                     target="#Kilroy.2021.sl">Kilroy, 2021</ref>) ipd. Raziskovalcem so
                  parlamentarni korpusi <ref target="https://sidih.github.io/voices/ch3-sl.html">
                     <hi rend="underline color(0000FF)">dostopni prek konkordančnikov</hi>
                  </ref> (tj. spletnih orodij za raziskovanje in analizo besedil v korpusih) ali pa
                  v <ref
                     target="https://www.clarin.si/repository/xmlui/discover?query=parl*&amp;submit=I%C5%A1%C4%8Di&amp;filtertype_2=title&amp;filter_relational_operator_2=contains&amp;filter_2=&amp;query=parl*">
                     <hi rend="underline color(0000FF)">repozitorijih jezikovnih virov</hi>
                  </ref>, kjer je mogoče dostopati do celotnega korpusa v različnih formatih in ga
                  nato obdelati z različnimi orodji. To zadnjo možnost bomo izkoristili tudi v tem
                  učnem gradivu (glejte <ref target="#ch5.2-sl">poglavje 5.2</ref>).</p>
            </div>
            <div type="subchapter" xml:id="ch3.3-sl">
               <head xml:id="sl-head-6">3.3. Korpus ParlaMint</head>
               <p xml:id="sl-p-19">V tem učnem gradivu bomo uporabili podatke iz družine korpusov
                     <ref target="http://hdl.handle.net/11356/1432">ParlaMint</ref> (<ref
                     target="#Erjavec.2021.sl">Erjavec idr., 2021</ref>), ki vsebuje zapise
                  parlamentarnih sej 17 držav: Belgije, Bolgarije, Češke, Danske, Francije, Hrvaške,
                  Islandije, Italije, Latvije, Litve, Madžarske, Nizozemske, Poljske, Romunije,
                  Slovenije, Turčije in Velike Britanije. Večina korpusov ParlaMint pokriva obdobje
                  od 2015 do sredine 2020. Družina korpusov je nastala pod okriljem raziskovalne
                  infrastrukture za jezikovne vire in tehnologije <ref
                     target="https://www.clarin.eu">
                     <hi rend="underline color(0000FF)">CLARIN ERIC</hi>
                  </ref> in vsebuje pol milijarde besed oziroma pet milijonov govorov, ki jih je
                  izreklo približno 11 tisoč govorcev. Korpusi ParlaMint so razdeljeni na dva
                  podkorpusa, in sicer <hi rend="italic">Reference</hi> (referenčno obdobje) in <hi
                     rend="italic">COVID</hi>, ki zajemata čas pred epidemijo covida-19 in med njo
                  (tj. pred novembrom 2019 oziroma od novembra 2019 naprej).</p>
               <p xml:id="sl-p-20">Vsak od korpusov za posamezno državo je označen po enotni shemi,
                  ki temelji na smernicah za označevanje <ref
                     target="https://clarin-eric.github.io/parla-clarin/">
                     <hi rend="underline color(0000FF)">Parla-CLARIN</hi>
                  </ref> (<ref target="#Erjavec.2019.sl">Erjavec in Pančur, 2019</ref>). To
                  zagotavlja maksimalno primerljivost nacionalnih delov ParlaMinta. Ravno zaradi te
                  značilnosti je ParlaMint dragocen vir za politične, sociološke, zgodovinske,
                  jezikoslovne in druge raziskave, saj omogoča primerjalne analize, ki so bile do
                  zdaj zaradi različne strukture parlamentarnih korpusov težko izvedljive. Poleg
                  tega ParlaMint pokriva širok nabor evropskih držav, kar širi območje vedenja o
                  parlamentarizmu, ki je še vedno zgoščeno predvsem okoli zahodnih držav.
                  Primerjalne raziskave so tako ključnega pomena za napredek pri razumevanju
                  pozitivnih in negativnih parlamentarnih praks in posledično za razvoj
                  parlamentarnih sistemov (<ref target="#Norton.2002.sl">Norton, 2002</ref>).</p>
               <p xml:id="sl-p-21">V učnem gradivu bomo uporabili slovenski del korpusa ParlaMint.
                  ParlaMint-SI vključuje razprave iz Državnega zbora, ki je <hi rend="color(202122)"
                     >osrednja in najvišja predstavniška in zakonodajna institucija v državi</hi>.
                  Državni zbor sestavlja 90 poslancev (88 predstavnikov ljudstva in dva predstavnika
                  narodnih manjšin), ki so izvoljeni na podlagi splošne volilne pravice (<ref
                     target="#Brezovšek.2012.sl">Brezovšek idr., 2012</ref>). ParlaMint-SI pokriva
                  dva parlamentarna mandata v šestletnem obdobju (avgust 2014–julij 2020) in obsega
                  približno 20 milijonov besed (<ref target="#Erjavec.2022.sl">Erjavec idr.,
                     2022</ref>). Uporabili bomo <ref
                     target="https://www.clarin.si/repository/xmlui/handle/11356/1431">
                     <hi rend="underline color(0000FF)">jezikoslovno označeno različico korpusa
                        2.1</hi>
                  </ref> (<ref target="#Erjavec.2021.sl">Erjavec idr., 2021</ref>), ki je tudi
                  stavčno segmentirana (s tem so določene meje povedi) in tokenizirana (s tem je
                  pojavnica – beseda, številka, ločilo – določena kot osnovna enota za analizo).</p>
            </div>
         </div>
         <div type="chapter" xml:id="ch4" xml:lang="en" corresp="#ch4-sl">
            <head xml:id="head-17">4. Topic modelling</head>
            <p xml:id="p-26">To analyse parliamentary debates, we will use topic modelling, one of
               the text mining techniques used for researching large data sets. Given that several
               topic modelling methods exist, it is vital to know the advantages and disadvantages
               of each to choose the one that yields optimal results, which would provide quality
               results and ensure a critical interpretation of the results (<ref
                  target="#Shadrova.2021">Shadrova, 2021</ref>). In this chapter, we present the
               selected method of topic modelling and some examples of its application to
               parliamentary discourse.</p>
            <p xml:id="p-27">Topic modelling is a popular technique for automatic text analysis,
               which extracts the main topics in a corpus. A topic model assigns each document in
               the corpus to one or more topics. These topics are not actual text topics but rather
               sets of words that co-occur with high probability and hence form a single topic. The
               researcher must then manually define or name the topic described with these sets of
               words.</p>
            <p xml:id="p-28">Various methods (algorithms) can perform topic modelling on a corpus
                  (<ref target="#Vayansky.2020">Vayansky and Kumar, 2020</ref>). One of the most
               frequent ones is LDA or <hi rend="italic">latent Dirichlet allocation</hi>, which we
               will use in our analysis. The method was developed by <ref target="#Pritchard.2000"
                  >Pritchard et al. (2000)</ref> and adapted for text analysis by <ref
                  target="#Blei.2003">Blei, Ng, and Jordan (2003)</ref>. The method is best suited
               for processing large textual data sets which cannot be analysed manually due to their
               size.</p>
            <div type="subchapter" xml:id="ch4.1">
               <head xml:id="head-18">4.1. The LDA method</head>
               <p xml:id="p-29">The LDA method includes the following steps, performed in
                  iteration:</p>
               <list type="ordered" xml:id="list-1">
                  <item>The algorithm first randomly allocates topics to the words in the
                     corpus.<lb/>
                  </item>
               </list>
               <table rend="rules" xml:id="table-1">
                  <row>
                     <cell rend="center">
                        <p style="text-align:center;">
                           <hi rend="bold smallcaps">word</hi>
                        </p>
                        <p>
                           <hi rend="bold smallcaps">document</hi>
                        </p>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">epidemic</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">crisis</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">tax</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">economy</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc1</hi>
                     </cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc2</hi>
                     </cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc3</hi>
                     </cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc4</hi>
                     </cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 2</cell>
                  </row>
               </table>
               <list type="ordered:2" rend="ordered" xml:id="list-2">
                  <item>Next, the algorithm counts the number of times a particular topic appears in
                     each document (left table) and the number of times a certain topic is assigned
                     to each word (right table).</item>
               </list>
               <table rend="rules" xml:id="table-2">
                  <row>
                     <cell rend="List_Paragraph">
                        <table rend="rules">
                           <row>
                              <cell rend="left"/>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">topic 1</hi>
                              </cell>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">topic 2</hi>
                              </cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">doc1</hi>
                              </cell>
                              <cell rend="left">2</cell>
                              <cell rend="left">2</cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">doc2</hi>
                              </cell>
                              <cell rend="left">3</cell>
                              <cell rend="left">1</cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">doc3</hi>
                              </cell>
                              <cell rend="left">2</cell>
                              <cell rend="left">2</cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">doc4</hi>
                              </cell>
                              <cell rend="left">1</cell>
                              <cell rend="left">3</cell>
                           </row>
                        </table>
                     </cell>
                     <cell rend="List_Paragraph">
                        <table rend="rules">
                           <row>
                              <cell rend="left"/>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">topic 1</hi>
                              </cell>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">topic 2</hi>
                              </cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">epidemic</hi>
                              </cell>
                              <cell rend="left">3</cell>
                              <cell rend="left">1</cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">crisis</hi>
                              </cell>
                              <cell rend="left">2</cell>
                              <cell rend="left">2</cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">tax</hi>
                              </cell>
                              <cell rend="left">1</cell>
                              <cell rend="left">3</cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">economy</hi>
                              </cell>
                              <cell rend="left">2</cell>
                              <cell rend="left">2</cell>
                           </row>
                        </table>
                     </cell>
                  </row>
               </table>
               <list type="ordered:3" rend="ordered" xml:id="list-3">
                  <item>The algorithm then assumes it no longer knows the topic of a given
                     word.</item>
               </list>
               <table rend="rules" xml:id="table-5">
                  <row>
                     <cell rend="left"/>
                     <cell rend="left">
                        <hi rend="bold smallcaps">epidemic</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">crisis</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">tax</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">economy</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc1</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold color(FF0000)">?</hi>
                     </cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc2</hi>
                     </cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc3</hi>
                     </cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc4</hi>
                     </cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 2</cell>
                  </row>
               </table>
               <list type="ordered:4" rend="ordered" xml:id="list-4">
                  <item>Then, it updates both tables from step 2 by once again computing the
                     frequency of topics in the corpus (left table) and the frequency of words in
                     the topics (right table).</item>
               </list>
               <table rend="rules" xml:id="table-6">
                  <row>
                     <cell rend="left"/>
                     <cell rend="left">
                        <hi rend="bold smallcaps">topic 1</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">topic 2</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc1</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold color(FF0000)">1</hi>
                     </cell>
                     <cell rend="left">2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc2</hi>
                     </cell>
                     <cell rend="left">3</cell>
                     <cell rend="left">1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc3</hi>
                     </cell>
                     <cell rend="left">2</cell>
                     <cell rend="left">2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc4</hi>
                     </cell>
                     <cell rend="left">1</cell>
                     <cell rend="left">3</cell>
                  </row>
               </table>
               <table rend="rules" xml:id="table-7">
                  <row>
                     <cell rend="left"/>
                     <cell rend="left">
                        <hi rend="bold smallcaps">topic 1</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">topic 2</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">epidemic</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold color(FF0000)">2</hi>
                     </cell>
                     <cell rend="left">1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">crisis</hi>
                     </cell>
                     <cell rend="left">2</cell>
                     <cell rend="left">2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">tax</hi>
                     </cell>
                     <cell rend="left">1</cell>
                     <cell rend="left">3</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">economy</hi>
                     </cell>
                     <cell rend="left">2</cell>
                     <cell rend="left">2</cell>
                  </row>
               </table>
               <list type="ordered:5" rend="ordered" xml:id="list-5">
                  <item>It computes the strength of the <hi rend="bold">connection between a
                        document and a topic</hi> (the probability of the topic in a document: the
                     blue rectangle) and the <hi rend="bold">connection between the topic and a
                        given word</hi> (the probability of a word in a topic: the red
                     rectangle).</item>
               </list>
               <figure xml:id="figure-1">
                  <graphic url="https://sidih.si/cdn/2177/Figure0.1_LDA-eng.png" height="239px"/>
               </figure>
               <list type="ordered:6" rend="ordered" xml:id="list-6">
                  <item>The purple rectangle is a product of the red and the blue rectangle and
                     represents the probability of a word in each topic. Based on the computed
                     probability (purple rectangles), the method determines which topic will be
                     assigned to a given document (green star which denotes a random allocation of
                     the topic to the document, based on the computed word-topic probabilities). <lb/>
                     <figure>
                        <graphic url="https://sidih.si/cdn/2177/Figure0.2_LDA-prob-eng.png"
                           height="239px"/>
                     </figure>
                     <lb/> In short, the algorithm assigns a new topic (green star) based on the
                     probability (purple rectangle). The probability distribution of topics in the
                     document is based on the Dirichlet distribution, which postulates that the
                     probability is never zero. Non-zero probability means that each word has at
                     least a small chance of belonging to a less frequent topic and, concurrently,
                     that even a lesser topic is present in a document. Once the topic is assigned
                     to the word, the documents-words table is updated. </item>
               </list>
               <table rend="rules" xml:id="table-8">
                  <row>
                     <cell rend="left"/>
                     <cell rend="left">
                        <hi rend="bold smallcaps">epidemic</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">crisis</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">tax</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">economy</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc1</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold color(FF0000)">topic 2</hi>
                     </cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc2</hi>
                     </cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc3</hi>
                     </cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc4</hi>
                     </cell>
                     <cell rend="left">topic 1</cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 2</cell>
                     <cell rend="left">topic 2</cell>
                  </row>
               </table>
               <list type="ordered:7" rend="ordered" xml:id="list-7">
                  <item>Based on the new value from the table in step 6, the algorithm updates both
                     tables: the topic-document and the word-topic table.</item>
               </list>
               <table rend="rules" xml:id="table-9">
                  <row>
                     <cell rend="left"/>
                     <cell rend="left">
                        <hi rend="bold smallcaps">topic 1</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">topic 2</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc1</hi>
                     </cell>
                     <cell rend="left">1</cell>
                     <cell rend="left">
                        <hi rend="bold color(FF0000)">3</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc2</hi>
                     </cell>
                     <cell rend="left">3</cell>
                     <cell rend="left">1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc3</hi>
                     </cell>
                     <cell rend="left">2</cell>
                     <cell rend="left">2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">doc4</hi>
                     </cell>
                     <cell rend="left">1</cell>
                     <cell rend="left">3</cell>
                  </row>
               </table>
               <table rend="rules" xml:id="table-10">
                  <row>
                     <cell rend="left"/>
                     <cell rend="left">
                        <hi rend="bold smallcaps">topic 1</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">topic 2</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">epidemic</hi>
                     </cell>
                     <cell rend="left">2</cell>
                     <cell rend="left">
                        <hi rend="bold color(FF0000)">2</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">crisis</hi>
                     </cell>
                     <cell rend="left">2</cell>
                     <cell rend="left">2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">tax</hi>
                     </cell>
                     <cell rend="left">1</cell>
                     <cell rend="left">3</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">economy</hi>
                     </cell>
                     <cell rend="left">2</cell>
                     <cell rend="left">2</cell>
                  </row>
               </table>
               <list type="ordered:8" rend="ordered" xml:id="list-8">
                  <item>The procedure is repeated until the topic assignments stop changing. The
                     result is a topic model. The topic is defined by a set of words which
                     frequently co-occur in the text.</item>
               </list>
               <p xml:id="p-32">Above, we have described the Gibbs sampling version of LDA. Please
                  note that Orange uses variational inference instead of Gibbs sampling. Gibbs
                  sampling is much more precise, while variational inference is faster for larger
                  data sets.</p>
            </div>
            <div type="subchapter" xml:id="ch4.2">
               <head xml:id="head-19">4.2. Characteristics of the LDA method</head>
               <p xml:id="p-33">LDA is based on multiple assumptions. The first one is that the
                  topic is defined by the words that frequently appear together. LDA is a
                  language-independent method since it merges words into groups based on their
                  occurrence in the text and not on their meaning. The same method can thus be used
                  on corpora in different languages. At the same time, each word can be assigned to
                  multiple topics; however, its probability in each topic will vary.</p>
               <p xml:id="p-34">The second assumption is that not all topics in the corpus appear
                  equally often, and that they are unrelated. LDA does not define potential
                  connections between the topics; however, it shows the probability distribution of
                  topics in the text, which defines their importance in each document. Each document
                  contains several topics, with one topic usually standing out (i.e., the document
                  contains more words associated with the main topic compared to other topics).</p>
               <p xml:id="p-35">The third assumption is that the number of topics is predefined. The
                  researcher must first set the number of topics into which the algorithm sorts the
                  documents. The optimal number of topics for a given corpus is the one at which it
                  is easiest to interpret viable topics for given sets of words that must be
                  informative in terms of the research problem. Researchers, therefore, typically
                  apply the topic modelling procedure several times for a given research problem,
                  each time setting a different number of topics, and assessing the informativeness
                  of the word sets that the algorithm extracted from the corpus. Some researchers
                  also use additional statistical tests to adjudicate between results of models with
                  different numbers of topics (<ref target="#Smith.2019">Smith and Graham,
                     2019</ref>). Even though a suitable number of topics differs from case to case,
                  the usual number ranges between 5 and 50 topics (<ref target="#Arun.2010">Arun et
                     al., 2010</ref>) and many papers go with 20 topics (<ref target="#Zhao.2015"
                     >Zhao et al., 2015</ref>; <ref target="#Gkoumas.2018">Gkoumas et al.,
                     2018</ref>; <ref target="#Rosa.2021">Rosa et al., 2021</ref>).</p>
               <p xml:id="p-36">The fourth assumption is that word order in a corpus is not
                  important. LDA works based on the so-called bag of words which does not consider
                  the linguistic structure or specific connections between the words. This
                  assumption is problematic because the word order is one of the key characteristics
                  of language.</p>
               <p xml:id="p-37">The results are importantly affected by document order, as the
                  method randomly assigns topics to documents at the beginning. If the document
                  order changes, the initial assignments will also change. The temporal sequence
                  (i.e., the timestamp) of the documents can also importantly affect the
                  characteristics of the documents (<ref target="#Vayansky.2020">Vayansky and Kumar,
                     2020</ref>).</p>
            </div>
            <div type="subchapter" xml:id="ch4.3">
               <head xml:id="head-20">4.3. Data preprocessing</head>
               <p xml:id="p-38">Before topic modelling, the data requires preparation which usually
                  includes tokenisation (splitting the text into tokens, usually words, numbers, and
                  punctuation), lemmatisation (assigning the base form to each token), and
                  part-of-speech tagging (assigning the part of speech, e.g., verb, to each token).
                  The procedure enables us to perform topic modelling on a single word form.
                  Research has shown that lemmatisation and limiting the tokens to nouns improve the
                  algorithm's speed and results. The improvement shows in the coherence or the
                  sensible relations between word sets, based on which it is easier to assign a
                  topic (<ref target="#Martin.2015">Martin and Johnson, 2015</ref>). Differentiating
                  by part-of-speech tags can also be used for answering different research
                  questions. <ref target="#Zwaan.2016">Van der Zwaan et al. (2016)</ref> performed
                  topic modelling on nouns to retrieve topics. They then ran the algorithm on verbs,
                  adjectives, and adverbs and used the results to elicit the positions of the MPs.
                  Before using LDA, we usually remove overly common words from the corpus: words
                  that can be too general (e.g., pronouns, prepositions) or too specific for the
                  genre (e.g., words of address, such as <hi rend="italic">esteemed</hi> in the
                  parliamentary corpus). Depending on the research problem, very rare words,
                  punctuation, capital letters, etc. can also be removed (<ref target="#Smith.2019"
                     >Smith and Graham, 2019</ref>)</p>
            </div>
            <div type="subchapter" xml:id="ch4.4">
               <head xml:id="head-21">4.4. Limitations of LDA</head>
               <p xml:id="p-39">One of the limitations of LDA is that the method requires long texts
                  for good results as it is based on word distributions, which are spurious in
                  shorter texts. LDA is thus not appropriate for topic modelling of tweets, user
                  reviews, or poetry. Even though it could be used to analyse, for example, Facebook
                  posts (see <ref target="#Serrano.2019">Serrano et al., 2019</ref>), it is
                  recommended to use other topic modelling methods for such tasks (<ref
                     target="#Albalawi.2020">Albalawi et al., 2020</ref>; <ref
                     target="#Morstatter.2018">Morstatter et al., 2018</ref>). Parliamentary
                  speeches are usually long enough to achieve good results with LDA. However,
                  certain speeches can be very short, and it is wise to remove them before running
                  the analysis (<ref target="#ch5.4">Chapter 5.4</ref>).</p>
               <p xml:id="p-40">Another limitation is the assumption that words, just like the
                  documents and the topics, are not co-dependent, which is linguistically imprecise
                  on the one hand and does not allow for an analysis of correlations between words
                  or between documents on the other. LDA suffices since these correlations are not
                  the focal point for many research problems. However, if correlation is important
                  (e.g., if we are interested in topic progression over time), there are more
                  suitable methods, such as dynamic topic modelling (<ref
                     target="#Müller-Hansen.2021">Müller-Hansen et al., 2021</ref>).</p>
               <p xml:id="p-41">LDA will also underperform if the text does not address the topic
                  coherently but touches upon the topic with a few words only. On the other hand,
                  the method works extremely well for longer, thematically well-defined texts, such
                  as news, academic papers, political speeches, and certain literary genres.</p>
               <p xml:id="p-42">The next limitation is related to the number of topics the
                  researcher has to define autonomously and is usually the result of trial and
                  error. <ref target="#Allen.2020">Allen and Murdock (2020)</ref> warn about overly
                  specific topics representing only small sections of the text when the number of
                  requested topics is high, making it difficult to establish thematic relations
                  between texts. Conversely, when the number of topics is very limited, they will
                  frequently be too general and thus uninformative to the research.</p>
               <p xml:id="p-43">As a final limitation, we can mention the difficulty of interpreting
                  topic modelling results, including how the results are published. As the result of
                  topic modelling are individual sets of words, there is a danger that the
                  researcher will recognize a pattern in them even when none is present, meaning
                  they will identify the topics they had expected (<ref target="#Shadrova.2021"
                     >Shadrova, 2021</ref>). It is thus vital to consider the number of inspected
                  words when defining a topic. The results can differ if the researcher assigns
                  topics based on the first ten or thirty words provided by the algorithm (<ref
                     target="#Allen.2020">Allen and Murdock, 2020</ref>). Qualitative reading and
                  understanding the original text segments in which the top listed words appear are
                  crucial for accurately interpreting word sets and identifying topics. When working
                  in a group, defining the common guidelines for topic identification in advance is
                  also recommended.</p>
               <p xml:id="p-44">Topic modelling with the LDA method is thus not a one-size-fits-all
                  solution that could provide the researcher with robust conclusions without a
                  critical analysis of the results. Understanding the limitations of different topic
                  modelling methods is key to successfully using them for research purposes, since
                  quantitative, automated methods can successfully augment the researcher's
                  analytical abilities, but they cannot replace human interpretation (<ref
                     target="#Grimmer.2013">Grimmer and Stewart, 2013</ref>). Nonetheless, the topic
                  modelling technique provides an important advantage over the manual approach,
                  specifically with regard to the processing of large data sets, enabling a more
                  robust data-based generalisation than using a small-sample analysis (<ref
                     target="#Jacobs.2019">Jacobs and Tschötschel, 2019</ref>). Moreover, topic
                  modelling enables greater objectivity of the results (<ref
                     target="#Müller-Hansen.2021">Müller-Hansen et al., 2021</ref>), even though the
                  technique is not entirely objective due to the aforementioned topic definition
                  process based on word sets.</p>
               <p xml:id="p-45">On the other hand, this is one of the advantages of the technique as
                  the algorithm does not give direct answers but forces the researcher to consider
                  the context when forming the final results (<ref target="#Schmidt.2012">Schmidt,
                     2012</ref>). Topic modelling also enhances systematisation of the analysis and
                  enables a comparatively better reproducibility of the results (<ref
                     target="#Jacobs.2019">Jacobs and Tschötschel, 2019</ref>). The popularity and
                  relevance of the technique for the research in the humanities and social sciences
                  are evident from the many publications that use topic modelling as a part of their
                  methodology (see <ref target="#ch4.5">Chapter 4.5</ref>).</p>
            </div>
            <div type="subchapter" xml:id="ch4.5">
               <head xml:id="head-22">4.5. Topic modelling of parliamentary debates</head>
               <p xml:id="p-46">In the humanities and social sciences, particularly in political
                  science, topic modelling is increasingly used as an important technique to
                  complement established, qualitative analytical approaches in analysing large data
                  sets. The results of topic modelling may inform the qualitative analysis (e.g.,
                  the researcher can identify relevant texts about a specific topic) or can be used
                  as the principal outcome of the analysis. In this chapter, we provide some
                  examples of both from recent applications of the topic modelling technique to
                  parliamentary data.</p>
               <p xml:id="p-47">Topic modelling allows us to <hi rend="bold">identify the topics
                  </hi>addressed in parliamentary speeches. <ref target="#Schuler.2020">Schuler
                     (2020)</ref>, for example, used LDA to analyse the debates in the Vietnamese
                  parliament and compared the results with topics from the news, also extracted with
                  LDA, and with the list of areas under the direct management of the Communist Party
                  (CP). He analysed whether MPs in an authoritarian system, such as the Vietnamese,
                  express their opinions and actively debate important topics. He discovered that
                  they debate only topics outside the CP's direct management, with the party
                  encouraging such debates to pressure the government and blame it for the outcomes
                  of the policies. However, the party does not encourage debates pertaining to areas
                  directly managed by the CP committees. Moreover, debates concerning topics open
                  for discussion do not involve all MPs but mostly those who are not members of the
                  CP and were elected as full-time representatives.</p>
               <p xml:id="p-48">
                  <ref target="#Chizhik.2021">Chizhik and Sergeyev (2021)</ref> also used topic
                  modelling to discover topics in parliamentary debates by analysing three decades
                  of Russian MPs' speeches. They researched whether the activity of the
                  parliamentary parties is related to the public's scepticism regarding the
                  multiparty system as a basis for democracy. They established that parties in the
                  Russian parliament focus mostly on foreign affairs, the economy, and the balance
                  of power between different branches of the government. At the same time, other
                  social issues generate much less debate. Furthermore, speeches from all parties,
                  but especially from the long-established ones, show a strong prevalence for
                  ideological and propagandistic discourse.</p>
               <p xml:id="p-49">We saw how topic modelling enables acquiring a general overview of
                  the material, which can suffice if the researcher’s aim is, for example, to
                  observe the frequency of topics under consideration in the parliament. But topic
                  modelling can also be used to retrieve more specific results. As parliamentary
                  corpora are usually rich with metadata, <hi rend="bold">topics can be explored in
                     relation to other variables </hi>(such as gender, age, party affiliation,
                  mandate etc.), which elicits the topics that stand out most when the selected
                  variable changes. We can thus observe how popular a topic was through time or with
                  a certain party. <ref target="#Curran.2018">Curran et al. (2018)</ref> used LDA
                  and the analysis of complex networks to elicit topics in the New Zealand
                  parliament, which they then related to MPs and the parties. In this way, they not
                  only retrieved popular topics of parliamentary debates for different periods and
                  interpreted them in the context of external events (e.g., the 2011 earthquake) but
                  also defined the interest of a party in each topic. Their results showed that the
                  Labour Party debated the real estate crisis much more ardently than the
                  then-governing National Party. The latter claimed most of the debate, while the
                  contribution of other parties decreased over time. The MPs' specialisations for
                  different topics also decreased, which is evident from the large number of topics
                  addressed by the majority of the MPs.</p>
               <p xml:id="p-50">
                  <ref target="#deCampos.2021">De Campos et al. (2021)</ref> used LDA in combination
                  with the available metadata to create thematic profiles of Spanish MPs which
                  reflect the subject matters they discuss in the parliament. Metadata was also used
                  in research by <ref target="#Høyland.2019">Høyland and Søyland (2019)</ref>. In
                  1919, Norway changed its electoral system to become substantially more dependent
                  on party politics, reducing MPs’ autonomy. Høyland and Søyland investigated
                  whether the change in the political system affected the topics in parliamentary
                  debates. They used a version of LDA called structural topic modelling (STM), which
                  considers both the word distributions and the selected metadata when computing the
                  results. They determined that the topic distribution clearly shows that
                  institutional organisation influences the behaviour of the MPs. After the reform
                  that emphasised party politics, the topics showing clear ideological differences
                  between the parties became more frequent, while MPs gave fewer speeches that
                  directly criticized other MPs. Furthermore, MPs more frequently discussed topics
                  of general interest (e.g., the educational system) and more rarely topics related
                  directly to the issues of their constituents (e.g., improving the infrastructure
                  of a remote town).</p>
               <p xml:id="p-51">Topic modelling enables <hi rend="bold">exploring the context and
                     selecting topics related to a given concept</hi>. <ref
                     target="#Müller-Hansen.2021">Müller-Hansen et al. (2021)</ref> used a version
                  of LDA called dynamic topic modelling (DTM), which enables the analysis of topics
                  through time.<note place="foot" xml:id="ftn3" n="3">Time-based topic analysis can
                     be done with plain LDA, but a separate topic model must be built for each
                     period; the topics must be interpreted and then compared between time periods.
                     Such an approach requires a lot more manual and subjective work, which can
                     negatively affect the results. Another option for temporal topic analysis is
                        <hi rend="italic">dynamic non-negative matrix factorisation</hi> (<hi
                        rend="italic">dynamic NMF</hi>) (see <ref target="#Gkoumas.2018">Gkoumas et
                        al. 2018</ref>), which considers the time periods indirectly (<ref
                        target="#Müller-Hansen.2021">Müller-Hansen et al. 2021</ref>).</note> They
                  analysed seventy years of German parliamentary debates on coal and explored how
                  they changed through time. The debates from the early years of the corpus show
                  that the MPs considered coal the driver of economic progress and the guarantee of
                  energy safety. Conversely, in recent years MPs primarily talked about energy
                  transition, a general departure from coal, and the flourishing of renewable energy
                  sources. Furthermore, the researchers also established that smaller and younger
                  parties (e.g., the Greens) talk about coal in the context of energy transition and
                  environmental protection more frequently than the other parties.</p>
               <p xml:id="p-52">Topic modelling can <hi rend="bold">explore the context of a topic
                     or the interplay of topics</hi>. <ref target="#Blätte.2020">Blätte et al.
                     (2020)</ref> aimed to discover how frequently migration is addressed in common
                  European politics. They used LDA to create a topic model of parliamentary debates
                  from Austria, France, Germany, and the Netherlands. Then, they selected the three
                  topics which best represented migration and European matters and retrieved all
                  speeches with a high frequency of the two issues. The results show that the debate
                  on migration was predominantly an internal issue in the larger two countries
                  investigated (France and Germany). Particularly in Germany, the European aspect
                  practically disappeared, while the smaller two countries (Austria and the
                  Netherlands) had a larger share of speeches discussing migration from the European
                  perspective.</p>
               <p xml:id="p-53">In this tutorial, we partially rely on the methodology used by <ref
                     target="#Curran.2018">Curran et al. (2018)</ref> in the analysis of speeches in
                  New Zealand discussed earlier. However, as our analysis covers a shorter time, we
                  will not split the data into time slices. As seen in the literature, the analysis
                  could be upgraded with structural topic modelling, where we could consider, for
                  example, the party affiliation of the speakers and observe the differences among
                  them. We could also analyse the entire ParlaMint-GB corpus and use dynamic topic
                  modelling to observe the differences in time. Nevertheless, to compare the
                  pre-pandemic and pandemic periods, the use of the LDA method is adequate.</p>
            </div>
         </div>
         <div type="chapter" xml:id="ch4-sl" xml:lang="sl" corresp="#ch4">
            <head xml:id="sl-head-7">4. Tematsko modeliranje besedil</head>
            <p xml:id="sl-p-22">Za analizo parlamentarnih razprav bomo uporabili tematsko
               modeliranje, eno od tehnik rudarjenja besedil, ki se uporablja pri raziskovanju
               velikih količin podatkov. Za ustrezno izbiro metode raziskovanja, ki bo dala
               kakovostne rezultate, in za kritično interpretacijo rezultatov je nujno poznati
               delovanje ter prednosti in slabosti uporabljenih metod (prim. <ref
                  target="#Shadrova.2021.sl">Shadrova, 2021</ref>). Ker bomo v naši analizi kot
               tehniko tematskega modeliranja uporabili latentno Dirichletovo dodelitev, sledi
               predstavitev delovanja tehnike in izsledkov nekaterih raziskav, pri katerih je bila
               le-ta uporabljena na parlamentarnem diskurzu.</p>
            <p xml:id="sl-p-23">Tematsko modeliranje je priljubljena metoda za avtomatsko analizo
               besedil, na podlagi katere lahko iz korpusa izluščimo prevladujoče teme, ki se
               pojavljajo v preučevanih besedilih. Rezultat tematskega modeliranja je tematski
               model, ki ga sestavljajo <hi rend="italic">teme</hi>, ki pa ne zaznamujejo dejanske
               tematike, o kateri govori besedilo, ampak so zgolj skupine besed, ki glede na
               matematično verjetnost sodijo skupaj in naj bi predstavljale isto tematiko.
               Raziskovalec pa mora nato ročno opredeliti oziroma poimenovati temo, ki naj bi jo te
               besede predstavljale.</p>
            <p xml:id="sl-p-24">Za tematsko modeliranje korpusa je mogoče uporabiti različne tehnike
               oziroma algoritme (Vayansky in Kumar, 2020). Med najpogosteje uporabljenimi je
               tehnika LDA oziroma <hi rend="italic">latentna Dirichletova dodelitev</hi>, ki jo
               bomo uporabili tudi v naši analizi. Tehniko so razvili <ref
                  target="#Pritchard.2000.sl">Pritchard idr. (2000)</ref>, za analizo besedil pa so
               jo predlagali <ref target="#Blei.2003.sl">Blei, Ng in Jordan (2003)</ref>. Tehnika je
               izrazito primerna za obdelavo obsežnih zbirk besedilnih podatkov, ki jih zaradi
               velikosti ne moremo obdelati ročno.</p>
            <div type="subchapter" xml:id="ch4.1-sl">
               <head xml:id="sl-head-8">4.1. Tehnika LDA</head>
               <p xml:id="sl-p-25">LDA vključuje naslednje korake, izvedene v več ponovitvah:<lb/>
               </p>
               <list type="ordered" xml:id="sl-list-1">
                  <item>Algoritem najprej vsem besedam v besedilu naključno dodeli oznako
                     teme.</item>
               </list>
               <table rend="rules" xml:id="sl-table-1">
                  <row>
                     <cell rend="center">
                        <p style="text-align:center;">
                           <hi rend="bold smallcaps">Beseda</hi>
                        </p>
                        <p>
                           <hi rend="bold smallcaps">Dokument</hi>
                        </p>
                     </cell>
                     <cell rend="left">
                        <hi rend="smallcaps">EPIDEMIJA</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="smallcaps">KRIZA</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="smallcaps">DAVEK</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="smallcaps">GOSPODARSTVO</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok1</hi>
                     </cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok2</hi>
                     </cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok3</hi>
                     </cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok4</hi>
                     </cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 2</cell>
                  </row>
               </table>
               <list type="ordered:2" rend="ordered" xml:id="sl-list-2">
                  <item>Algoritem prešteje, kolikokrat se določena tema pojavi v posameznem besedilu
                     (leva tabela) in kolikokrat je določena tema pripisana posamezni besedi (desna
                     tabela).</item>
               </list>
               <table rend="rules" xml:id="sl-table-2">
                  <row>
                     <cell rend="left">
                        <table rend="rules">
                           <row>
                              <cell rend="left"/>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">tema 1</hi>
                              </cell>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">tema 2</hi>
                              </cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">dok1</hi>
                              </cell>
                              <cell rend="left">2</cell>
                              <cell rend="left">2</cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">dok2</hi>
                              </cell>
                              <cell rend="left">3</cell>
                              <cell rend="left">1</cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">dok3</hi>
                              </cell>
                              <cell rend="left">2</cell>
                              <cell rend="left">2</cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">dok4</hi>
                              </cell>
                              <cell rend="left">1</cell>
                              <cell rend="left">3</cell>
                           </row>
                        </table>
                     </cell>
                     <cell rend="left">
                        <table rend="rules">
                           <row>
                              <cell rend="left"/>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">tema 1</hi>
                              </cell>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">tema 2</hi>
                              </cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">epidemija</hi>
                              </cell>
                              <cell rend="left">3</cell>
                              <cell rend="left">1</cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">kriza</hi>
                              </cell>
                              <cell rend="left">2</cell>
                              <cell rend="left">2</cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">davek</hi>
                              </cell>
                              <cell rend="left">1</cell>
                              <cell rend="left">3</cell>
                           </row>
                           <row>
                              <cell rend="left">
                                 <hi rend="bold smallcaps">gospodarstvo</hi>
                              </cell>
                              <cell rend="left">2</cell>
                              <cell rend="left">2</cell>
                           </row>
                        </table>
                     </cell>
                  </row>
               </table>
               <list type="ordered:3" rend="ordered" xml:id="sl-list-3">
                  <item>Nato algoritem za posamezno besedo privzame, da ne pozna več njene
                     teme.</item>
               </list>
               <table rend="rules" xml:id="sl-table-5">
                  <row>
                     <cell rend="left"/>
                     <cell rend="left">
                        <hi rend="bold smallcaps">epidemija</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">kriza</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">davek</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">gospodarstvo</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok1</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold color(FF0000)">?</hi>
                     </cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok2</hi>
                     </cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok3</hi>
                     </cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok4</hi>
                     </cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 2</cell>
                  </row>
               </table>
               <list type="ordered:4" rend="ordered" xml:id="sl-list-4">
                  <item>Za tem posodobi obe tabeli iz 2. koraka, tako da znova določi frekvenco
                     določene teme v posameznih besedilih (leva tabela) in frekvenco določene besede
                     v posameznih temah (desna tabela).</item>
               </list>
               <table rend="rules" xml:id="sl-table-6">
                  <row>
                     <cell rend="left"/>
                     <cell rend="left">
                        <hi rend="bold smallcaps">tema 1</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">tema 2</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok1</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold color(FF0000)">1</hi>
                     </cell>
                     <cell rend="left">2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok2</hi>
                     </cell>
                     <cell rend="left">3</cell>
                     <cell rend="left">1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok3</hi>
                     </cell>
                     <cell rend="left">2</cell>
                     <cell rend="left">2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok4</hi>
                     </cell>
                     <cell rend="left">1</cell>
                     <cell rend="left">3</cell>
                  </row>
               </table>
               <table rend="rules" xml:id="sl-table-7">
                  <row>
                     <cell rend="left"/>
                     <cell rend="left">
                        <hi rend="bold smallcaps">tema 1</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">tema 2</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">epidemija</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold color(FF0000)">2</hi>
                     </cell>
                     <cell rend="left">1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">kriza</hi>
                     </cell>
                     <cell rend="left">2</cell>
                     <cell rend="left">2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">davek</hi>
                     </cell>
                     <cell rend="left">1</cell>
                     <cell rend="left">3</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">gospodarstvo</hi>
                     </cell>
                     <cell rend="left">2</cell>
                     <cell rend="left">2</cell>
                  </row>
               </table>
               <list type="ordered:5" rend="ordered" xml:id="sl-list-5">
                  <item>Izračuna, kako močna je <hi rend="bold">povezava med besedilom in temo</hi>
                     (verjetnost teme v dokumentu: moder pravokotnik) ter <hi rend="bold">temo in
                        izbrano besedo</hi> (verjetnost besede v temi: rdeč pravokotnik).</item>
               </list>
               <figure xml:id="sl-figure-1">
                  <graphic url="https://sidih.si/cdn/2177/Slika0.1_LDA.png" height="239px"/>
               </figure>
               <list type="ordered:6" rend="ordered" xml:id="sl-list-6">
                  <item>Vijolični pravokotnik je zmnožek rdečega in modrega pravokotnika in
                     predstavlja verjetnost, da beseda pripada določeni temi. Na podlagi slednje
                     verjetnosti (oba vijolična kvadrata) nato tehnika določi, kateri temi bo
                     pripadal dokument (zelena zvezda, ki, glede na izračunano verjetnost
                     kombinacije besede in teme, predstavlja naključno dodelitev teme izbranemu dokumentu).<lb/>
                     <figure>
                        <graphic url="https://sidih.si/cdn/2177/Slika0.2_LDA-prob.png"
                           height="239px"/>
                     </figure>
                     <lb/> Na kratko, algoritem na podlagi verjetnosti (vijolična kvadrata) določi
                     novo temo (zelena zvezda). Verjetnostna porazdelitev tem v besedilu se izračuna
                     na podlagi Dirichletove porazdelitve, ki določa, da verjetnost nikoli ni
                     ničelna. To pomeni, da ima vsaka beseda vsaj majhno možnost, da pripada tudi
                     manj pogosti temi, oziroma da je v dokumentu prisotna tudi manj pogosta
                     tema.<lb/>Ko besedi algoritem določi temo, posodobi tudi tabelo
                     besedila-besede. </item>
               </list>
               <table rend="rules" xml:id="sl-table-8">
                  <row>
                     <cell rend="left"/>
                     <cell rend="left">
                        <hi rend="bold smallcaps">epidemija</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">kriza</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">davek</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">gospodarstvo</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok1</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold color(FF0000)">tema 2</hi>
                     </cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok2</hi>
                     </cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok3</hi>
                     </cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok4</hi>
                     </cell>
                     <cell rend="left">tema 1</cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 2</cell>
                     <cell rend="left">tema 2</cell>
                  </row>
               </table>
               <list type="ordered:7" rend="ordered" xml:id="sl-list-7">
                  <item>Glede na novo vrednost iz tabele v 6. koraku algoritem znova posodobi obe
                     tabeli, torej tabeli teme-besedila in besede-teme.<lb/>
                  </item>
               </list>
               <table rend="rules" xml:id="sl-table-9">
                  <row>
                     <cell rend="left"/>
                     <cell rend="left">
                        <hi rend="bold smallcaps">tema 1</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">tema 2</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok1</hi>
                     </cell>
                     <cell rend="left">1</cell>
                     <cell rend="left">
                        <hi rend="bold color(FF0000)">3</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok2</hi>
                     </cell>
                     <cell rend="left">3</cell>
                     <cell rend="left">1</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok3</hi>
                     </cell>
                     <cell rend="left">2</cell>
                     <cell rend="left">2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">dok4</hi>
                     </cell>
                     <cell rend="left">1</cell>
                     <cell rend="left">3</cell>
                  </row>
               </table>
               <table rend="rules" xml:id="sl-table-10">
                  <row>
                     <cell rend="left"/>
                     <cell rend="left">
                        <hi rend="bold smallcaps">tema 1</hi>
                     </cell>
                     <cell rend="left">
                        <hi rend="bold smallcaps">tema 2</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">epidemija</hi>
                     </cell>
                     <cell rend="left">2</cell>
                     <cell rend="left">
                        <hi rend="bold color(FF0000)">2</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">kriza</hi>
                     </cell>
                     <cell rend="left">2</cell>
                     <cell rend="left">2</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">davek</hi>
                     </cell>
                     <cell rend="left">1</cell>
                     <cell rend="left">3</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <hi rend="bold smallcaps">gospodarstvo</hi>
                     </cell>
                     <cell rend="left">2</cell>
                     <cell rend="left">2</cell>
                  </row>
               </table>
               <list type="ordered:8" rend="ordered" xml:id="sl-list-8">
                  <item>Postopek se ponavlja, dokler se dodelitve tem ne nehajo spreminjati. Končni
                     rezultat je tematski model. Temo predstavlja skupina besed, ki se pogosto
                     pojavljajo skupaj v besedilih.</item>
               </list>
               <p xml:id="sl-p-28">Zgoraj smo opisali verzijo LDA z Gibbsovim vzorčenjem. Orange
                  namesto Gibbsovega vzorčenja uporablja metodo variacijske inference. Gibbsovo
                  vzorčenje je veliko bolj natančno, medtem ko je variacijska inferenca hitrejša za
                  večje podatke.</p>
            </div>
            <div type="subchapter" xml:id="ch4.2-sl">
               <head xml:id="sl-head-9">4.2. Značilnosti tehnike LDA</head>
               <p xml:id="sl-p-29">LDA temelji na več predpostavkah. Prva je, da temo zaznamujejo
                  besede, ki se v besedilih pogosto pojavljajo skupaj. To pomeni, da je LDA
                  jezikovno neodvisna tehnika, saj besede združuje v skupine na podlagi njihove
                  pojavitve v besedilu in ne na podlagi njihovega pomena. Isto metodo je torej
                  mogoče uporabiti na podatkih v različnih jezikih. Obenem velja, da je lahko
                  posamezna beseda uvrščena v več tem, vendar običajno z različno verjetnostjo.</p>
               <p xml:id="sl-p-30">Druga predpostavka je, da se teme v korpusu pojavljajo različno
                  pogosto in da so medsebojno neodvisne. LDA ne opredeli morebitne povezave med
                  temami, pokaže pa verjetnost razporeditve tem v besedilu, pri čemer opredeli
                  njihovo pomembnost v določenem besedilu. Posamezno besedilo običajno vsebuje več
                  tem, vendar določena tema najpogosteje izstopa (tj. v glavno skupino besed
                  algoritem razvrsti več besed kot v druge skupine besed oziroma teme).</p>
               <p xml:id="sl-p-31">Tretja predpostavka je, da je število tem vnaprej določeno. To
                  pomeni, da mora raziskovalec vnaprej določiti število tem, v katere naj algoritem
                  razvrsti dokumente. Optimalno število tem za določeno besedilo je tisto, pri
                  katerem je za dobljene skupine besed najlažje opredeliti smiselne teme, ki so še
                  vedno informativne glede na zastavljeni raziskovalni problem. Zato raziskovalci
                  običajno postopek tematskega modeliranja za vsako raziskavo posebej večkrat
                  ponovijo z različnim številom tem, pri čemer ocenjujejo povednost skupin besed, ki
                  jih je iz besedila izluščil algoritem. Nekateri si pomagajo tudi z dodatnimi
                  statističnimi izračuni (prim. <ref target="#Smith.2019.sl">Smith in Graham,
                     2019</ref>). Čeprav se torej ustrezno število tem razlikuje od primera do
                  primera, običajno število tem sega od 5 do 50 (<ref target="#Arun.2010.sl">Arun
                     idr., 2010</ref>), veliko raziskav pa se odloči za 20 tem (<ref
                     target="#Zhao.2015.sl">Zhao idr., 2015</ref>; <ref target="#Gkoumas.2018.sl"
                     >Gkoumas idr., 2018</ref>; <ref target="#Rosa.2021.sl">Rosa idr.,
                  2021</ref>).</p>
               <p xml:id="sl-p-32">Četrta predpostavka je, da vrstni red besed v besedilu ni
                  pomemben. LDA namreč deluje na podlagi t. i. vreče besed, ki ne upošteva jezikovne
                  strukture in povezav med besedami. Ta predpostavka je problematična, saj je vrstni
                  red besed ena ključnih značilnosti realnih besedil. </p>
               <p xml:id="sl-p-33">Na rezultate pa ključno vpliva vrstni red besedil, saj tehnika v
                  začetku besedilom naključno dodeli teme. Če se spremeni vrstni red, se bo tudi
                  začetna dodelitev spremenila. Vrstni red besedil v smislu njihovega časovnega
                  zaporedja prav tako lahko pomembno vpliva na značilnosti besedil (<ref
                     target="#Vayansky.2020.sl">Vayansky in Kumar, 2020</ref>).</p>
            </div>
            <div type="subchapter" xml:id="ch4.3-sl">
               <head xml:id="sl-head-10">4.3. Predobdelava podatkov</head>
               <p xml:id="sl-p-34">Za potrebe tematskega modeliranja morajo biti podatki ustrezno
                  pripravljeni. To največkrat vključuje tokenizacijo (členitev na pojavnice,
                  običajno besede, števila, ločila), lematizacijo (pripis osnovne oblike vsaki
                  pojavnici) in oblikoskladenjsko označevanje (pripis besedne vrste vsaki pojavnici,
                  npr. glagol). Slednje nam omogoča, da tematsko modeliranje izvedemo zgolj na
                  določeni besedni vrsti. Raziskave namreč kažejo, da lematizacija in omejitev
                  korpusa zgolj na samostalnike izboljšata tako hitrost algoritma kot njegove
                  rezultate, in sicer z vidika koherence oziroma smiselne povezanosti besed v
                  posameznih skupinah, zaradi česar jim je lažje pripisati temo (<ref
                     target="#Martin.2015.sl">Martin in Johnson, 2015</ref>). Razlikovanje po
                  oblikoskladnji lahko uporabimo tudi za iskanje odgovorov na različna raziskovalna
                  vprašanja. Tako so na primer <ref target="#Zwaan.2016.sl">Van der Zwaan idr.
                     (2016)</ref> tematsko modeliranje najprej izvedli na samostalnikih in tako
                  pridobili teme, nato pa algoritem pognali še na glagolih, pridevnikih in
                  prislovih, na podlagi česar so nato izluščili stališča parlamentarcev. Pred
                  uporabo metode LDA iz korpusa običajno odstranimo tudi zelo pogoste besede, ki so
                  lahko preveč splošne (npr. zaimki, predlogi) ali preveč specifične za preučevani
                  žanr (npr. pozdravne besede, kot je <hi rend="italic">spoštovani</hi>, v
                  parlamentarnem korpusu), glede na izbrani raziskovalni problem pa lahko odstranimo
                  tudi zelo redke besede, ločila, veliko začetnico ipd. (<ref
                     target="#Smith.2019.sl">Smith in Graham, 2019</ref>).</p>
            </div>
            <div type="subchapter" xml:id="ch4.4-sl">
               <head xml:id="sl-head-11">4.4. Omejitve metode LDA</head>
               <p xml:id="sl-p-35">Kot prvo omejitev lahko izpostavimo dejstvo, da LDA za uspešno
                  delovanje potrebuje daljša besedila, saj temelji na porazdelitvah besed, ki za
                  kratka besedila niso izrazite. Tako na primer LDA ni primerna tehnika za tematsko
                  modeliranje tvitov, uporabniških komentarjev ali poezije. Čeprav jo je mogoče
                  uporabiti tudi za analizo npr. objav na Facebooku (<ref target="#Serrano.2019.sl"
                     >Serrano idr., 2019</ref>), se za tovrstna besedila priporočajo druge metode
                  tematskega modeliranja (<ref target="#Albalawi.2020.sl">Albalawi idr., 2020</ref>;
                     <ref target="#Morstatter.2018.sl">Morstatter idr., 2018</ref>). Čeprav so
                  parlamentarni govori običajno dovolj dolgi za učinkovito uporabo metode LDA, pa
                  lahko nekatere seje vključujejo tudi zelo kratke govore, ki jih je pred uporabo
                  metode LDA dobro odstraniti (glejte <ref target="#ch5.4-sl">poglavje
                  5.4</ref>).</p>
               <p xml:id="sl-p-36">Druga omejitev je povezana s predpostavko, da so besede
                  medsebojno neodvisne, prav tako pa tudi besedila in teme, kar je po eni strani
                  jezikoslovno netočno, po drugi strani pa raziskovalcem onemogoča pregled nad
                  korelacijami med besedami oziroma med besedili. Ta informacija pri mnogih
                  raziskovalnih problemih sicer ni potrebna, zato tehnika LDA zadostuje. Če pa je ta
                  informacija pomembna (npr. če nas zanima razvoj teme skozi daljše časovno
                  obdobje), so na voljo druge metode tematskega modeliranja, npr. dinamično tematsko
                  modeliranje (<ref target="#Müller-Hansen.2021.sl">Müller-Hansen idr., 2021</ref>).
                  Poleg tega LDA ne deluje dobro, če besedilo o neki temi ne govori koherentno,
                  ampak jo omeni zgolj s par besedami. Po drugi strani pa tehnika dobro deluje za
                  daljša, tematsko opredeljena besedila, na primer za novice, akademske članke,
                  politične govore in določena prozna dela.</p>
               <p xml:id="sl-p-37">Naslednja omejitev je vezana na število tem, ki ga mora
                  raziskovalec določiti po lastni presoji in je običajno rezultat preizkušanja. Kot
                  opozarjata <ref target="#Allen.2020.sl">Allen in Murdock (2020)</ref>, bodo pri
                  zelo velikem številu nekatere teme predstavljale zgolj zelo specifičen del enega
                  od besedil v korpusu, zaradi česar je težje iskati tematske povezave med besedili.
                  Kadar pa je število tem postavljeno zelo nizko, jih je običajno lažje
                  interpretirati, vendar so najpogosteje teme zelo splošne in tako precej
                  neinformativne za analizo.</p>
               <p xml:id="sl-p-38">Kot zadnjo omejitev lahko omenimo težavnost interpretacije
                  rezultatov tematskega modeliranja, vključno z načinom navajanja rezultatov v
                  publikacijah. Ker so rezultat izolirane skupine besed, obstaja nevarnost, da
                  raziskovalci v njih vidijo vzorec, ki ga pravzaprav ni, oziroma prepoznajo teme,
                  ki so jih že v izhodišču pričakovali (<ref target="#Shadrova.2021.sl">Shadrova,
                     2021</ref>). Pri interpretaciji je zato pomembno, kakšno število besed upošteva
                  raziskovalec, ko opredeljuje temo. Ta je lahko namreč precej drugačna, če
                  raziskovalec sklepa o temi na podlagi prvih 10 ali prvih 30 besed, ki jih ponudi
                  algoritem (<ref target="#Allen.2020.sl">Allen in Murdock, 2020</ref>). Pri
                  interpretaciji skupin besed in opredeljevanju ter interpretaciji tem je zato nujno
                  potrebno kvalitativno branje oziroma poznavanje izvirnih delov besedila, v katerih
                  se izbrane besede pojavljajo, še posebej za skupinsko delo pa je priporočljivo
                  oblikovati tudi smernice za odločanje.</p>
               <p xml:id="sl-p-39">Tematsko modeliranje po metodi LDA torej ni hitra rešitev, ki bi
                  raziskovalca lahko brez kritične presoje rezultatov privedla do kakovostnih
                  zaključkov. Prav razumevanje omejitev je bistvenega pomena za uspešno uporabo
                  tematskega modeliranja v raziskovalne namene. Kvantitativne, avtomatske metode
                  analize torej lahko pomembno dopolnjujejo raziskovalčeve sposobnosti za analizo,
                  vendar ne morejo nadomestiti človeške interpretacije (<ref
                     target="#Grimmer.2013.sl">Grimmer in Stewart, 2013</ref>). Tematsko modeliranje
                  omogoča pomembno prednost pred kvalitativnim branjem, in sicer možnost obdelave
                  velike količine podatkov, kar raziskovalcem omogoča robustnejše posploševanje na
                  podlagi rezultatov kot pri analizi, izvedeni na majhnem vzorcu (<ref
                     target="#Jacobs.2019.sl">Jacobs in Tschötschel, 2019</ref>). Poleg tega
                  postopek tematskega modeliranja omogoča večjo objektivnost rezultatov (<ref
                     target="#Müller-Hansen.2021.sl">Müller-Hansen idr., 2021</ref>), čeprav zaradi
                  prej omenjenih omejitev, kot je opredelitev tem na podlagi skupine besed, tehnika
                  ni v celoti objektivna. To je obenem tudi prednost te tehnike, saj algoritem ne
                  poda neposrednih odgovorov, ampak raziskovalce sili v upoštevanje konteksta pri
                  oblikovanju končnih rezultatov (<ref target="#Schmidt.2012.sl">Schmidt,
                  2012</ref>). Tematsko modeliranje vnaša tudi večjo sistematizacijo analize in
                  omogoča sorazmerno večjo ponovljivost rezultatov (<ref target="#Jacobs.2019.sl"
                     >Jacobs in Tschötschel, 2019</ref>). Priljubljenost in aktualnost te tehnike za
                  humanistične in družboslovne raziskave se kažeta tudi v velikem številu raziskav,
                  ki tematsko modeliranje uporabljajo v svoji metodologiji (gl. <ref
                     target="#ch4.5-sl">poglavje 4.5</ref>).</p>
            </div>
            <div type="subchapter" xml:id="ch4.5-sl">
               <head xml:id="sl-head-12">4.5. Tematsko modeliranje parlamentarnih razprav</head>
               <p xml:id="sl-p-40">V politologiji in drugih humanističnih in družboslovnih vedah, ki
                  analizirajo velike količine realnih podatkov, se tematsko modeliranje vse bolj
                  uveljavlja kot pomembna analitična tehnika, ki dopolnjuje ustaljene, kvalitativne
                  pristope za analizo. Rezultati tematskega modeliranja namreč lahko služijo kot
                  usmeritev za kvalitativno analizo (npr. identifikacijo relevantnih besedil o
                  najbolj izstopajoči temi) ali pa že predstavljajo del končnih rezultatov. V tem
                  poglavju predstavljamo nekaj primerov uporabe tematskega modeliranja
                  parlamentarnih podatkov.</p>
               <p xml:id="sl-p-41">S tematskim modeliranjem lahko <hi rend="bold">izluščimo
                     vsebinske tematike</hi>, o katerih se razpravlja v parlamentu. <ref
                     target="#Schuler.2020.sl">Schuler (2020)</ref> je na primer z metodo LDA
                  analiziral razprave v vietnamskem parlamentu in rezultate povezal s temami iz
                  novic, tudi pridobljenimi z LDA, ter seznamom področij pod neposrednim
                  upravljanjem Komunistične partije (KP). S tem je raziskal, ali poslanci v
                  avtoritarnih sistemih, kot je vietnamski, izražajo svoja stališča in aktivno
                  razpravljajo glede pomembnih tem. Ugotovil je, da do dejanske razprave pride zgolj
                  pri temah, ki ne pokrivajo področij, ki so v neposrednem upravljanju KP, pri čemer
                  slednja spodbuja takšno razpravo zato, da lahko pritiska na vlado in ji obenem
                  naprti odgovornost za posledice sprejetih ukrepov. Kadar pa tema razprave zadeva
                  eno od področij, ki jo s svojimi odbori neposredno upravlja KP, slednja ne
                  spodbuja javne razprave. Obenem je zanimiva njegova ugotovitev, da se tudi pri
                  temah, ki so odprte za izmenjavo stališč, v razpravo ne vključujejo vsi poslanci,
                  ampak predvsem tisti, ki niso člani KP in so bili za polni delovni čas kot
                  predstavniki ljudstva izvoljeni na lokalni ravni.</p>
               <p xml:id="sl-p-42">Za <hi rend="bold">odkrivanje vsebinskih tematik </hi>v
                  parlamentarnih razpravah sta tematsko modeliranje uporabila tudi <ref
                     target="#Chizhik.2021.sl">Chizhik in Sergeyev (2021)</ref>, ki sta analizirala
                  približno tri desetletja govorov ruskih poslancev, da bi ugotovila, ali obstajajo
                  povezave med dejavnostjo strank v parlamentu in skepticizmom javnosti glede
                  večstrankarskega sistema kot temelja za demokracijo. Ugotovila sta, da stranke
                  ruskega parlamenta svojo pozornost predvsem posvečajo zunanjim zadevam,
                  gospodarstvu in razmerju moči med vejami oblasti, medtem ko se precej manj
                  posvečajo drugim družbenim problemom. Pri tem njihove govore, še posebej to velja
                  za uveljavljene stranke, v veliki meri zaznamuje ideološki in propagandistični
                  diskurz.</p>
               <p xml:id="sl-p-43">Tematsko modeliranje torej omogoča, da pridobimo splošen pregled
                  nad gradivom, ki lahko zadošča, če je naš namen, na primer, opazovati
                  izpostavljenost tematik, o katerih se razpravlja v parlamentu. Tematsko
                  modeliranje pa lahko uporabimo tudi za pridobivanje bolj specifičnih rezultatov.
                  Ker so parlamentarni korpusi običajno bogato označeni z metapodatki, lahko <hi
                     rend="bold">teme raziskujemo v razmerju do drugih spremenljivk</hi> (npr. spol,
                  starost, pripadnost politični stranki, mandat itd.) in tako izluščimo tiste teme,
                  ki najbolj razlikujejo med vrednostmi izbrane spremenljivke. Tako lahko na primer
                  opazujemo, kako aktualna je bila določena tema skozi čas ali pri določeni stranki.
                     <ref target="#Curran.2018.sl">Curran idr. (2018)</ref> so na primer z metodo
                  LDA in analizo kompleksnih mrež razkrili teme razprav v novozelandskem parlamentu
                  in jih povezali s poslanci ter njihovimi strankami, ki so te teme naslavljali v
                  svojih govorih. Na ta način so izluščili prevladujoče teme razprav v posameznih
                  obdobjih in jih interpretirali v povezavi z zunanjimi dogodki (npr. potres leta
                  2011). Poleg tega so na podlagi rezultatov opredelili, koliko zanimanja je
                  določeni temi namenila posamezna stranka. Izkazalo se je, da je Laburistična
                  stranka veliko bolj zavzeto razpravljala o nepremičninski krizi kot takrat
                  vladajoča Nacionalna stranka. Rezultati so pokazali tudi, da je Nacionalna stranka
                  zavzela glavnino razprave, medtem ko se je prispevek manjših strank skozi čas
                  zmanjševal. Zmanjšala pa se je tudi specializacija parlamentarcev za različne
                  teme, kar se kaže v velikem številu tem, ki jih naslavlja večina poslancev.</p>
               <p xml:id="sl-p-44">Ena od možnosti <hi rend="bold">uporabe metapodatkov pri
                     tematskem modeliranju</hi> je predstavljena tudi v raziskavi, ki so jo izvedli
                     <ref target="#deCampos.2021.sl">de Campos idr. (2021)</ref>. Metodo LDA so
                  namreč uporabili za določanje tematskega profila španskih poslancev, ki odraža
                  področja, ki jih ti pokrivajo v parlamentu. Metapodatke sta s pridom uporabila
                  tudi <ref target="#Høyland.2019.sl">Høyland in Søyland (2019)</ref>, ki sta želela
                  ugotoviti, ali je sprememba volilnega sistema leta 1919, ko je norveški politični
                  sistem postal bolj odvisen od strankarske politike in poslanci niso imeli več
                  toliko avtonomije kot pred reformo, vplivala na tematiko parlamentarnih razprav.
                  Pri tem sta uporabila različico metode LDA, in sicer strukturno tematsko
                  modeliranje (STM), ki poleg porazdelitve besed pri izračunu rezultatov sočasno
                  upošteva tudi izbrane metapodatke. Ugotovila sta, da razporeditev tem jasno kaže,
                  da institucionalna ureditev vpliva na delovanje parlamentarcev. Po reformi, ki je
                  poudarila pomen strankarske politike, so postale teme, ki so izrazito kazale
                  ideološke razlike med strankami, pogostejše, medtem ko so poslanci manj govorov
                  namenjali neposredni kritiki drugih poslancev. Obenem so poslanci po reformi
                  pogosteje razpravljali o temah splošnega zanimanja (npr. o izobraževalnem sistemu)
                  in redkeje o temah, ki so neposredno obravnavale težave njihovih volilnih okrajev
                  (npr. o izgradnji infrastrukture v nekem oddaljenem kraju).</p>
               <p xml:id="sl-p-45">S tematskim modeliranjem lahko tudi <hi rend="bold">raziščemo
                     kontekst in nabor tem, s katerimi je povezan določen pojem.</hi>
                  <ref target="#Müller-Hansen.2021.sl">Müller-Hansen idr. (2021)</ref> so uporabili
                  različico tehnike LDA, imenovano dinamično tematsko modeliranje (DTM), ki omogoča
                  analizo tem skozi čas. S to metodo so analizirali sedemdeset let nemških
                  parlamentarnih razprav o premogu, in tako raziskali, kako so se razprave o premogu
                  spreminjale skozi čas<note place="foot" xml:id="ftn4-sl" n="4">Diahrono analizo
                     tem, torej razvoj tem skozi čas, je mogoče analizirati tudi le s tehniko LDA,
                     vendar je pri tem treba za vsako časovno obdobje narediti ločen tematski model,
                     interpretirati dobljene teme in jih nato primerjati med različnimi časovnimi
                     obdobji. Tak pristop zahteva več ročnega, subjektivnega dela, kar lahko
                     negativno vpliva na rezultate. Druga možnost za časovno analizo tem je <hi
                        rend="italic">dinamična nenegativna matrična faktorizacija</hi> (<hi
                        rend="italic">dynamic NMF</hi>) (<ref target="#Gkoumas.2018.sl">Gkoumas
                        idr., 2018</ref>), ki pa tematike med različnimi obdobji poveže zgolj
                     posredno. (<ref target="#Müller-Hansen.2021.sl">Müller-Hansen idr.,
                     2021</ref>)</note>. Razprave iz zgodnjih let korpusa kažejo, da so poslanci
                  premog dojemali kot gonilo gospodarskega razvoja in jamstvo energetske varnosti,
                  medtem ko v zadnjih letih razprave o premogu predvsem govorijo o energetskem
                  prehodu, postopni opustitvi premoga in razmahu obnovljivih virov energije. Obenem
                  so raziskovalci ugotovili, da manjše in mlajše stranke (npr. Zeleni) v nemškem
                  parlamentu pogosteje kot druge stranke govorijo o premogu v kontekstu energetskega
                  prehoda in varovanja okolja.</p>
               <p xml:id="sl-p-46">Namesto izbranega pojma lahko na podlagi rezultatov tematskega
                  modeliranja <hi rend="bold">opazujemo kontekst določene teme oziroma prepletanje
                     tem.</hi>
                  <ref target="#Blätte.2020.sl">Blätte idr. (2020)</ref> so, na primer, želeli
                  izvedeti, kako pogosto se o migracijah razpravlja v kontekstu skupne evropske
                  politike. Z metodo LDA so ustvarili tematski model za parlamentarne razprave
                  Avstrije, Francije, Nemčije in Nizozemske, izbrali tri teme, ki so najbolje
                  predstavljale migracije oziroma evropske zadeve, nato pa izluščili vse govore,
                  kjer sta se ti dve krovni temi križali. Raziskava je pokazala, da so bile razprave
                  o migrantih v dveh večjih državah iz korpusa (Francija, Nemčija) bolj usmerjene
                  navznoter. Še posebej v Nemčiji je evropski vidik skoraj izginil, medtem ko se je
                  v manjših državah iz vzorca (Avstrija, Nizozemska) delež govorov, ki o migracijah
                  razpravljajo z vidika evropskega odziva, povečal.</p>
               <p xml:id="sl-p-47">V tem učnem gradivu se delno naslanjamo na metodologijo, ki so jo
                  uporabili <ref target="#Curran.2018.sl">Curran in sodelavci (2018)</ref> v zgoraj
                  omenjeni raziskavi novozelandskih govorov, pri čemer v naši analizi obravnavamo
                  krajše časovno obdobje, zato podrobnejša delitev po letih ni smiselna. Kot je
                  razvidno iz zgoraj opisanih raziskav, bi lahko analizo nadgradili s strukturnim
                  tematskim modeliranjem, pri čemer bi upoštevali, na primer, strankarsko pripadnost
                  govorcev in opazovali razlike med njimi. Lahko pa bi analizirali tudi celoten
                  korpus ParlaMint-SI in z dinamičnim tematskim modeliranjem opazovali razlike tem
                  skozi čas. Vendar je za primerjavo tem v dveh obdobji, pred in med epidemijo,
                  tehnika LDA povsem ustrezna.</p>
            </div>
         </div>
         <div type="chapter" xml:id="ch5" xml:lang="en" corresp="#ch5-sl">
            <head xml:id="head-23">5. Preparing for the analysis</head>
            <p xml:id="p-54">This chapter begins the empirical part of the tutorial. It will lead us
               from setting up the software, importing and checking the data, to preparing and
               preprocessing the sample for analysis.</p>
            <p xml:id="p-55">For the tasks below, you will need about 1 GB of disk space to download
               and install Orange with Miniconda, 2.3 GB of space for the original ParlaMint files
               (if you wish to work with the original data), and 1.9 GB for all three versions of
               pre-formatted pickle files (if you wish to speed up the analysis). Keep in mind that
               topic modelling is resource-intensive and might get slow on computers with
               insufficient RAM.</p>
            <div type="subchapter" xml:id="ch5.1">
               <head xml:id="head-24">5.1. Orange: setup and use</head>
               <p xml:id="p-56">The analysis will be performed in <ref
                     target="https://orangedatamining.com/">Orange</ref> v3.32.0, a Python-based
                  open-source software for data analysis (<ref target="#Demšar.2013">Demšar et al.,
                     2013</ref>). In Orange, the <hi rend="italic">Text </hi>add-on offers a special
                  tool kit for text mining. Orange is based on visual programming. The analysis is
                  performed through a data analysis workflow, i.e., a series of steps or widgets
                  that the user selects, thereby not requiring any coding knowledge.</p>
               <p xml:id="p-57">First, we download the software from <ref
                     target="https://orangedatamining.com/">orangedatamining.com</ref> onto the
                  computer. We open the downloaded file and follow installer instructions. Once we
                  open the program, we install the <hi rend="italic">Text </hi>add-on (v1.10.0) by
                  clicking the <hi rend="italic">Options </hi>tab and selecting <hi rend="italic"
                     >Add-ons </hi>in the drop-down menu<hi rend="italic">. </hi>In the window that
                  opens, we tick the <hi rend="italic">Text </hi>field, and confirm the add-on
                  installation by clicking the <hi rend="italic">OK</hi> button (<ref
                     target="#figure.1">Figure 1</ref>).</p>
               <figure xml:id="figure.1">
                  <graphic url="https://sidih.si/cdn/2177/Figure1_addon.png"/>
                  <head>Figure 1: Installing the Text add-on.</head>
               </figure>
               <p xml:id="p-58">To complete the installation, we must restart Orange.<note
                     place="foot" xml:id="ftn4" n="4">If you have used Orange before, please clear
                     widget settings under Options <g style="font-family:Wingdings;" n="F0E0"/>
                     Reset widget settings. This will enable you to repeat the analysis as described
                     in the tutorial.</note> When we do so, the left-hand menu will contain the <hi
                     rend="italic">Text Mining</hi> tab with various widgets (e.g., <hi
                     rend="italic">Corpus, Bag of Words</hi>) intended for text analysis (<ref
                     target="#figure.2">Figure 2</ref>). On the right-hand side, there is a white
                  field called <hi rend="italic">canvas</hi>. We will place the <hi rend="italic"
                     >widgets</hi> on the canvas and connect them in an analytical workflow.</p>
               <figure xml:id="figure.2">
                  <graphic url="https://sidih.si/cdn/2177/Figure2_canvas.png"/>
                  <head>Figure 2: Home screen after restarting Orange, having installed the Text
                     add-on.</head>
               </figure>
               <p xml:id="p-59">The widgets can be added on the canvas by dragging them from the
                  menu on the left and dropping them onto the canvas or by right-clicking on the
                  canvas to open a drop-down menu, typing the widget's name, e.g., <hi rend="bold"
                     >Corpus</hi>, and pressing <hi rend="bold">Enter</hi>. A double click on the
                  widget will open a settings window. Every widget has an input on the left, an
                  output on the right, or both. They are marked with a dashed line at the side of
                  the widget. In Orange, analysis always runs from left to right, never in the
                  opposite direction.</p>
               <p xml:id="p-60">Using the same steps as when adding the <hi rend="bold">Corpus
                  </hi>widget, we add the <hi rend="bold">Corpus Viewer </hi>widget. By
                  double-clicking it, an empty window opens: the widget has not yet received any
                  data to analyse. We can send the data to the widget by connecting the two widgets,
                  specifically by using the mouse to connect the right-hand dashed line of the <hi
                     rend="bold">Corpus </hi>widget with the left-hand dashed line of the <hi
                     rend="bold">Corpus Viewer </hi>widget (<ref target="#figure.3">Figure 3</ref>).
                  Then, we double-click <hi rend="bold">Corpus Viewer </hi>again, and this time, the
                  window will display data.<note place="foot" xml:id="ftn5" n="5">The data shown
                     come with the widget.</note>
               </p>
               <figure xml:id="figure.3">
                  <graphic url="https://sidih.si/cdn/2177/Figure3_link.png" height="374px"/>
                  <head>Figure 3: A connection between the widgets.</head>
               </figure>
               <p xml:id="p-61">The tutorial will describe how to build a workflow to perform topic
                  modelling of parliamentary debates and explore the topics with additional
                  visualisations. Although you can <ref
                     target="https://www2.sistory.si/publikacije/material/parlamint/tutorial-eng.ows"
                     >download</ref> the entire workflow, we recommend you follow the individual
                  tutorial steps and create the sequence of widgets by yourselves; this is how you
                  will best understand the separate analysis phases.</p>
            </div>
            <div type="subchapter" xml:id="ch5.2">
               <head xml:id="head-28">5.2. Loading data into Orange</head>
               <p xml:id="p-62">The ParlaMint-GB corpus holds parliamentary speeches from the 2015
                  to 2021 period. Since the empirical part of the tutorial will compare the speeches
                  made before and during the COVID-19 pandemic, the data must first be limited to
                  two comparably long periods before and during the pandemic. The pandemic period
                  included in <ref
                     target="https://www2.sistory.si/publikacije/material/parlamint/ParlaMint-GB.conllu.zip"
                     >the ParlaMint-GB corpus</ref> lasts from November 2019 onwards (see <ref
                     target="#Erjavec.2022">Erjavec et al., 2022</ref>). We wish to choose similarly
                  long periods; hence we will select 2019 for the pre-pandemic and 2020 for the
                  pandemic period.<note place="foot" xml:id="ftn6" n="6">It has been established
                     that the delimited periods are comparable in terms of the quantity of speeches
                     and sessions that they encompass.</note>
               </p>
               <p xml:id="p-63">The analysis will use the British part of the linguistically
                  annotated corpus of parliamentary data ParlaMint 2.1 (see <ref target="#ch3.3"
                     >Chapter 3.3</ref>) which is available in the CoNLL-U format. To load the data,
                  follow Option 1 below. If you are experiencing problems, try Option 2 instead.</p>
               <table rend="rules" xml:id="table-11">
                  <row>
                     <cell rend="left">Option 1: follow the tutorial</cell>
                     <cell rend="left">Option 2: speed up the analysis</cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <figure>
                           <graphic url="https://sidih.si/cdn/2177/Figure0.3.png" height="464px"/>
                        </figure>
                     </cell>
                     <cell rend="left">
                        <figure>
                           <graphic url="https://sidih.si/cdn/2177/Figure0.4.png" height="495px"/>
                        </figure>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">
                        <p>You will get the most comprehensive understanding of the entire process
                           (from the preparation of data to the final results) if you follow along
                           the tutorial. Certain steps might take your computer some time to
                           process, so please be patient.</p>
                        <p>If you decide for this option, download <ref
                              target="https://www2.sistory.si/publikacije/material/parlamint/ParlaMint-GB.conllu.zip"
                              >the CoNLL-U files</ref>
                           <note place="foot" xml:id="ftn7" n="7">The folder will contain
                              linguistically annotated parliamentary speeches in the CoNLL-U format
                              and metadata in the TSV format. Keep all the files in the folder for
                              the import. </note> and continue below.<note place="foot"
                              xml:id="ftn8" n="8">This is the file format you get from the CLARIN.SI
                              repository if you search for the ParlaMint data with added linguistic
                              annotations. The provided link will lead you to a selection of files
                              that are relevant for this tutorial (i.e., only the data from 2019 and
                              2020). The Parla-Mint-GB corpus, however, includes much more data. If,
                              at a later time, you would like to analyse the entire corpus or a
                              different time period, you can get the entire corpus from the <ref
                                 target="http://hdl.handle.net/11356/1431"
                                 >ParlaMint-GB.ana.tgz</ref> folder in the CLARIN.SI repository and
                              make a selection of the data according to your needs.</note>
                        </p>
                     </cell>
                     <cell rend="left">
                        <p>If you are unable to load the CoNLL-U files, download <ref
                              target="https://www2.sistory.si/publikacije/material/parlamint/ParlaMint-GB.pkl"
                              >the .pkl data</ref>, load the data to Orange with the <hi rend="bold"
                              >Corpus </hi>widget and continue with chapter 5.3.</p>
                     </cell>
                  </row>
               </table>
               <p xml:id="p-67">If you are using the CoNLL-U files, add the <hi rend="bold">Import
                     Documents </hi>widget to the canvas to import data into Orange. First, we open
                  the widget with a double click, and in the first line, select the folder in which
                  we have stored the data (<ref target="#figure.4">Figure 4</ref>). It is not
                  necessary to confirm the import; it happens automatically when we select a folder.
                  Below, we tick the <hi rend="italic">Lemma </hi>and <hi rend="italic">POS tags
                  </hi>options, which will import the lemmas and the parts of speech with the
                  speeches. A speech by an individual MP at a specific session will be presented as
                  an individual document. At the bottom of the window, the software will inform us
                  that we have imported 180,565 documents or files.</p>
               <figure xml:id="figure.4">
                  <graphic url="https://sidih.si/cdn/2177/Figure4_import-document.png"/>
                  <head>Figure 4: Import data window.</head>
               </figure>
               <p xml:id="p-68">For a better understanding of the data structure, here are a few
                  characteristics of the CoNLL-U format. CoNLL-U is a type of TSV format in which
                  tab characters separate the values. In natural language processing, it is used to
                  represent linguistically annotated texts as its distribution of texts and
                  annotations in columns allows for a straight-forward computer processing. Each
                  sentence is considered one segment in this format. The text is in a vertical or
                  long format, i.e., one word per line, which enables a clear overview of added
                  linguistic annotations. There are metadata at the beginning of every sentence
                  (e.g., speech ID, sentence ID, and text) (<ref target="#figure.5">Figure
                  5</ref>).</p>
               <figure xml:id="figure.5">
                  <graphic url="https://sidih.si/cdn/2177/Figure5_connlu.png"/>
                  <head>Figure 5: Data in the CoNLL-U format: the first sentence in the file
                     ParlaMint-GB_2019-01-07-commons.conllu.</head>
               </figure>
            </div>
            <div type="subchapter" xml:id="ch5.3" facs="https://sidih.si/cdn/2177/ch5.3.png">
               <head xml:id="head-31">5.3. Data overview</head>
               <p xml:id="p-69">Before we begin the analysis, let us make sure that the data we have
                  uploaded is correct. We can do this in the <hi rend="bold">Corpus Viewer</hi>
                  widget. First, we add it to the canvas and connect it from left to right with the
                  previous widget. Then, we double click <hi rend="bold">Corpus Viewer</hi> to open
                  it and display a list of documents. In our case, these are the individual speeches
                     (<ref target="#figure.6">Figure 6</ref>). By clicking on the list, we can see
                  different speeches. Holding the <hi rend="italic">Shift</hi> key while clicking
                  will display several speeches simultaneously.</p>
               <figure xml:id="figure.6">
                  <graphic url="https://sidih.si/cdn/2177/Figure6_corpus-viewer.png"/>
                  <head>Figure 6: Data overview in the Corpus Viewer widget.</head>
               </figure>
               <p xml:id="p-70">In the top left-hand corner, we can see the basic information on the
                  corpus: the number of <hi rend="italic">tokens, types</hi>
                  <note place="foot" xml:id="ftn9" n="9">The token number is the number of every
                     word, number, and punctuation mark in the corpus, while the type is the number
                     of unique tokens in the corpus.</note> and the number of documents that match
                  the <hi rend="italic">regexp filter</hi> if we use one (<hi rend="italic">matching
                     documents</hi>). As the filter is now empty, all the documents are displayed
                  (180565/180565). The last information, <hi rend="italic">matches</hi>, is the
                  number of documents matching the search query that we can enter in the <hi
                     rend="italic">RegExp Filter</hi>.<note place="foot" xml:id="ftn10" n="10">When
                     specifying a query, you can use <ref
                        target="https://www.sketchengine.eu/guide/regular-expressions/">regular </ref>
                     <ref target="https://www.sketchengine.eu/guide/regular-expressions/"
                        >expressions</ref>, which enable searching for specific words or word forms.
                     The query <hi rend="italic">epidemic*</hi> will, for example, list the word <hi
                        rend="italic">epidemic</hi> in all its forms.</note>
               </p>
               <p xml:id="p-71">The viewer on the right displays numerous metadata<note place="foot"
                     xml:id="ftn11" n="11">Certain metadata might be missing if the original
                     parliamentary records are imperfect. Linguistic annotations have been added
                     automatically. This means that you should allow for some annotation errors,
                     even though the tools used are pretty accurate: 98–99% for lemmatisation,
                     94–97% for morphological tagging and 87–94% for syntactic tagging (<ref
                        target="#Erjavec.2022">Erjavec et al., 2022</ref>).</note> on the speeches
                  and the speakers.<note place="foot" xml:id="ftn12" n="12">While the entire
                     ParlaMint corpus family has the same set of metadata (see <ref>Chapter
                        3.3</ref>), not every corpus includes all metadata.</note> Every speech has
                  data on the <hi rend="italic">name</hi> of the session it belongs to and a unique
                     <hi rend="italic">utterance</hi> designation, the last number of which marks
                  the consecutive number of the speech in the given session. We can read the entire
                  speech under the <hi rend="italic">content</hi> variable. Another important piece
                  of data is the <hi rend="italic">subcorpus</hi> variable; it marks the time the
                  speech was given (<hi rend="italic">reference</hi> stands for the speeches
                  delivered before November 2019, while <hi rend="italic">COVID</hi> stands for
                  those given since).</p>
               <p xml:id="p-72">Next is the data on the speaker: their <hi rend="italic">role</hi>
                  (chairperson or regular speaker), their <hi rend="italic">type</hi> (MP or guest),
                  their affiliation (<hi rend="italic">Speaker party</hi>), their <hi rend="italic"
                     >party status</hi> (opposition or coalition), their <hi rend="italic"
                  >name</hi>, gender, and year of <hi rend="italic">birth</hi>.</p>
            </div>
            <div type="subchapter" xml:id="ch5.4">
               <head xml:id="head-33">5.4. Preparing and preprocessing the subcorpus</head>
               <p xml:id="p-73">As shown in Chapter 3, parliamentary discourse is marked by a clear
                  structure with numerous typical phrases such as “<hi rend="italic">Ms/Mr … has the
                     floor”, “Thank you for the floor, honourable member”, </hi>or <hi rend="italic"
                     >“The agenda is approved”</hi>. Certain expressions that guide the discussion
                  are especially typical of the chairpersons; others are merely parts of polite
                  communication. Due to their nature, such phrases are very common in parliamentary
                  corpora but not of interest for topic analysis. As they would only represent noise
                  in the results, they should be removed from the corpus. Although it is impossible
                  to remove them automatically in their entirety, their number can still be
                  significantly reduced. We can do this by preparing a subcorpus and removing every
                  chairperson’s speech and speeches shorter than 50 words (<ref target="#figure.8"
                     >Figure 8</ref>).</p>
               <cit xml:id="cit-1">
                  <quote>“It is very good to welcome the hon. Member for North West Durham (Laura
                     Pidcock) back to the House.”</quote>
                  <bibl>(John Simon Bercow, House of Commons, 7 January 2019)</bibl>
               </cit>
               <p xml:id="p-74">The decision is based on a manual overview of the corpus, proving
                  that such speeches mainly interject or express thanks. Other related research
                     (<ref target="#Curran.2018">Curran et al., 2018</ref>) has done similar
                  filtering. Although these speeches are not necessarily of a purely procedural
                  nature, their brevity still makes them less appropriate for topic modelling
                  following the LDA method, which requires longer texts to achieve good results (see
                     <ref target="#ch4">Chapter 4</ref>). Along with the too-short speeches, the
                  sample will also exclude speeches from guests of the parliament.</p>
               <div type="subchapter" xml:id="ch5.4.1" facs="https://sidih.si/cdn/2177/ch5.4.1.png">
                  <head xml:id="head-34">5.4.1. Removing unwanted speeches</head>
                  <table rend="rules" xml:id="table-12">
                     <row>
                        <cell rend="left">Option 1: follow the tutorial</cell>
                        <cell rend="left">Option 2: speed up the analysis</cell>
                     </row>
                     <row>
                        <cell rend="left">
                           <figure>
                              <graphic url="https://sidih.si/cdn/2177/Figure0.5.png" height="124px"
                              />
                           </figure>
                        </cell>
                        <cell rend="left">
                           <figure>
                              <graphic url="https://sidih.si/cdn/2177/Figure0.6.png" height="134px"
                              />
                           </figure>
                        </cell>
                     </row>
                     <row>
                        <cell rend="left">Continue with the steps below.</cell>
                        <cell rend="left">If the sampling process is slow, first open a new session
                           in Orange. Then download <ref
                              target="https://www2.sistory.si/publikacije/material/parlamint/ParlaMint-GB-sample.pkl"
                              >ParlaMint-GB-sample.pkl file</ref> and load it with the <hi
                              rend="bold">Corpus</hi> widget. The file contains the sample we will
                           create in the next step. Continue with Chapter 5.4.2.</cell>
                     </row>
                  </table>
                  <p xml:id="p-75">We will need the <hi rend="bold">Statistics</hi> and <hi
                        rend="bold">Select Rows </hi>widgets to create the sample. We place the <hi
                        rend="bold">Statistics</hi> widget on the canvas and connect it with the <hi
                        rend="bold">Import Documents</hi> widget – we do not change the settings;
                     they will instruct the <hi rend="bold">Statistics </hi>widget to perform a <hi
                        rend="italic">word</hi> and <hi rend="italic">character count</hi> in the
                     documents. The <hi rend="bold">Data Table </hi>widget, which we connect to the
                        <hi rend="bold">Statistics </hi>widget, allows us to see the two columns at
                     the far right of the window with the number of words and characters in each
                     speech (Figure 7). Now that the data on the speech length is known, we can use
                     the <hi rend="bold">Select Rows</hi> widget to select only the speeches that
                     match the desired length.</p>
                  <figure xml:id="figure.7">
                     <graphic url="https://sidih.si/cdn/2177/Figure7_data-tabel.png"/>
                     <head>Figure 7: Word count and character count columns are added to the data
                        (far right).</head>
                  </figure>
                  <p xml:id="p-76">First, we add the <hi rend="bold">Select Rows</hi> widget (<ref
                        target="#figure.8">Figure 8</ref>), connect it to the <hi rend="bold"
                        >Statistics </hi>widget, open it, and set three conditions (by clicking the
                        <hi rend="italic">Add condition</hi> button):</p>
                  <list type="unordered" xml:id="list-9">
                     <item>The first criterion will set the speech length threshold – we limit the
                           <hi rend="italic">Word count </hi>variable with the <hi rend="italic">is
                           greater than</hi> option and enter the desired minimal length, in our
                        case 50, which will limit the sample to speeches with 51 words or
                        more;</item>
                     <item>The second criterion will exclude the session chairpersons – we set the
                           <hi rend="italic">Speaker role </hi>variable by selecting the <hi
                           rend="italic">is </hi>and the <hi rend="italic">Regular
                        </hi>parameter;</item>
                     <item>The third criterion will only keep MP speeches in the sample – we set the
                           <hi rend="italic">Speaker type</hi> variable by selecting the <hi
                           rend="italic">is</hi> and the <hi rend="italic">MP</hi> variable, which
                        will exclude the speeches given by the guests.</item>
                  </list>
                  <figure xml:id="figure.8">
                     <graphic url="https://sidih.si/cdn/2177/Figure8_select-rows.png"/>
                     <head>Figure 8: A selection of speeches with more than 50 words given by
                        regular MPs.</head>
                  </figure>
                  <p xml:id="p-77">The data at the bottom of the <hi rend="bold">Select Rows
                     </hi>widget tells us that the number of speeches has dropped to 130,453 (from
                     the previous 180,565; the complete information on the output can be accessed by
                     clicking the numbers at the bottom).</p>
               </div>
               <div type="subchapter" xml:id="ch5.4.2" facs="https://sidih.si/cdn/2177/ch5.4.2.png">
                  <head xml:id="head-37">5.4.2. Removing unwanted words</head>
                  <p xml:id="p-78">To achieve good topic modelling results, we must also preprocess
                     the data (see <ref target="#ch4.3">Chapter 4.3)</ref>. We can do this by
                     filtering in the <hi rend="bold">Preprocess Text</hi> widget, which we insert
                     immediately after the <hi rend="bold">Select Rows</hi> widget. Before
                     connecting the two widgets, we will first set the parameters to ensure smoother
                     operation. Nonetheless, please note that the preprocessing step may take quite
                     some time to complete. To set the parameters, we first open the <hi rend="bold"
                        >Preprocess Text </hi>widget. In it, we will see the default steps for text
                     preprocessing (their order and settings can be modified). As the data has
                     already been tokenized and the words transformed so that they all begin with a
                     lowercase letter (<ref target="#ch5.3">Chapter 5.3</ref>), we can remove the
                     Transformation and Tokenization steps by clicking on the cross in the upper
                     left-hand (Mac OS) or right-hand corner (Windows).<note place="foot"
                        xml:id="ftn13" n="13">If you wish to disable the data updating after every
                        parameter change, uncheck the <hi rend="italic">Apply Automatically
                        </hi>option in the bottom left corner – then click <hi rend="italic">Apply
                        </hi>once you have done all the changes.</note> We are left with the
                     Filtering step, where a few settings need to be changed (<ref
                        target="#figure.9">Figure 9</ref>):</p>
                  <list type="unordered" xml:id="list-10">
                     <item>Clearing the <hi rend="italic">Stopwords</hi> option – as we will only
                        focus on nouns, we will not need this option which excludes function words
                        such as pronouns, conjunctions, and prepositions;</item>
                     <item>Selecting the <hi rend="italic">Document frequency</hi> option and the
                           <hi rend="italic">Absolute</hi> measure, where we set the span from 10 to
                           max<note place="foot" xml:id="ftn14" n="14">Set <hi rend="italic"
                              >max</hi> by removing/deleting the upper threshold.</note> (total
                        number of speeches) – the analysis will therefore exclude any words that
                        appear in fewer than ten speeches, e.g., exclude the extremely rare words
                        that do not influence the forming of specific topics;</item>
                     <item>Selecting the <hi rend="italic">POS tags</hi> option because the data
                        contains part-of-speech tagging (see <ref target="#ch3.3">Chapter
                        3.3</ref>). The default setting of this option includes only nouns and verbs
                        in later analyses. However, as nouns proved to be the most useful part of
                        speech in topic modelling (see <ref target="#Martin.2015">Martin and
                           Johnson, 2015</ref>), we will only keep those and eliminate verbs.</item>
                  </list>
                  <figure xml:id="figure.9">
                     <graphic url="https://sidih.si/cdn/2177/Figure9_preprocess-text.png"/>
                     <head>Figure 9: Setting the Preprocess Text widget.</head>
                  </figure>
                  <p xml:id="p-79">Once we have set the parameters (as seen in <ref
                        target="#figure.9">Figure 9</ref>), we can connect <hi rend="bold"
                        >Preprocess Text</hi> with <hi rend="bold">Select Rows</hi>.</p>
                  <p xml:id="p-80">We can visualise the words that appear most often in the sample
                     with a word cloud. To do so, we connect <hi rend="bold">Word Cloud </hi>to <hi
                        rend="bold">Preprocess Text</hi>. The word cloud will only feature nouns;
                     the size of the word is proportional to its frequency (<ref target="#figure.10"
                        >Figure 10</ref>). The displayed words reflect the parliamentary genre of
                     the data. The list on the left shows that the most frequently used word is <hi
                        rend="italic">people</hi>, which appears 99,103 times. The parliament is
                     voted by the people and works for the people, so such a result is not very
                     surprising.</p>
                  <figure xml:id="figure.10">
                     <graphic url="https://sidih.si/cdn/2177/Figure10_word-cloud.png"/>
                     <head>Figure 10: The most frequent words in the subset after
                        preprocessing.</head>
                  </figure>
                  <p xml:id="p-81">Preprocessing is an important part of processing text data, but
                     every step must be clearly defined. Every decision influences the results,
                     which must be considered during interpretation. Please note that filtering in
                     Orange does not modify the original data. Therefore, the preprocessing step
                     does not erase the original corpus from the <hi rend="bold">Select Rows</hi>
                     widget but only adds information on tokens in the <hi rend="bold">Preprocess
                        Text </hi>widget.</p>
               </div>
            </div>
         </div>
         <div type="chapter" xml:id="ch5-sl" xml:lang="sl" corresp="#ch5">
            <head xml:id="sl-head-13">5. Priprava na analizo</head>
            <p xml:id="sl-p-48">S tem poglavjem se začne praktični del učnega gradiva. Poglavje nas
               bo vodilo vse od namestitve programa ter uvoza in kontrolnega pregleda osnovnih
               podatkov do izdelave vzorca za analizo in predprocesiranja podatkov.</p>
            <p xml:id="sl-p-49">Za prenos in namestitev programa Orange, vključno s programom
               Miniconda, ki je del namestitvenega paketa za Orange, boste potrebovali približno 1
               GB prostora na disku. Za prenos datotek ParlaMint boste potrebovali 2,3 GB prostora.
               Upoštevajte, da je tematsko modeliranje računsko zahteven proces, zato bo morda
               delovanje računalnika upočasnjeno, sploh če uporabljate napravo z malo delovnega
               pomnilnika (RAM).</p>
            <div type="subchapter" xml:id="ch5.1-sl">
               <head xml:id="sl-head-14">5.1. Namestitev in uporaba programa Orange</head>
               <p xml:id="sl-p-50">Analizo bomo izvedli v odprtokodnem in prostodostopnem programu
                     <ref target="https://orangedatamining.com/">
                     <hi rend="underline color(1155CC)">Orange</hi>
                  </ref> v3.32.0, ki temelji na programskem jeziku Python (Demšar idr., 2013).
                  Program je namenjen podatkovni analitiki, razširitev <hi rend="italic">Text </hi>
                  (v1.10.0) pa ponuja poseben nabor orodij za rudarjenje besedil. Orange je osnovan
                  na vizualnem programiranju, kar pomeni, da potek analize določimo tako, da korake
                  analize oziroma tako imenovane gradnike sestavljamo v analitski delotok.</p>
               <p xml:id="sl-p-51">Program najprej s spletne strani <ref
                     target="https://orangedatamining.com/">
                     <hi rend="underline color(0000FF)">orangedatamining.com</hi>
                  </ref> prenesemo na računalnik. Preneseno programsko datoteko odpremo in sledimo
                  navodilom za namestitev. Nato program odpremo in naložimo še razširitev <hi
                     rend="italic">Text</hi>. To storimo tako, da izberemo zavihek <hi rend="italic"
                     >Options </hi>in v spustnem meniju kliknemo <hi rend="italic">Add-ons.</hi>
                  Odpre se okno, kjer obkljukamo polje <hi rend="italic">Text </hi>in namestitev
                  razširitve potrdimo s klikom gumba OK (<ref target="#slika.1">Slika 1</ref>).</p>
               <figure xml:id="slika.1">
                  <graphic url="https://sidih.si/cdn/2177/Slika1_razsiritev.png"/>
                  <head>Slika 1: Namestitev razširitve Text.</head>
               </figure>
               <p xml:id="sl-p-52">Po namestitvi moramo znova zagnati program<note place="foot"
                     xml:id="ftn5-sl" n="5">Če ste Orange že kdaj uporabljali, svetujemo, da
                     ponastavite gradnike, in sicer z možnostjo <hi rend="italic">Options </hi>
                     <g style="font-family:Wingdings;" n="F0E0"/>
                     <hi rend="italic"> Reset widget settings.</hi> Tako boste lažje sledili
                     analizi, kot je opisana v tem učnem gradivu.</note>. Ko se program odpre, se v
                  levem meniju prikaže zavihek <hi rend="italic">Text Mining</hi>, ki vsebuje
                  različne gradnike (npr. <hi rend="italic">Corpus, Bag of Words</hi>), ki so
                  namenjeni analizi besedil (<ref target="#slika.2">Slika 2</ref>). Na desni strani
                  je belo polje, ki ga imenujemo platno (<hi rend="italic">canvas</hi>). Nanj
                  zlagamo gradnike (<hi rend="italic">widgets</hi>), ki jih povezujemo v analitski
                  delotok.</p>
               <figure xml:id="slika.2">
                  <graphic url="https://sidih.si/cdn/2177/Slika2_platno.png"/>
                  <head>Slika 2: Začetni zaslon ob zagonu programa po namestitvi razširitve
                     Text.</head>
               </figure>
               <p xml:id="sl-p-53">Gradnike na platno dodajamo tako, da jih povlečemo iz menija na
                  levi in spustimo na platno, ali pa z desnim klikom na platno odpremo spustni meni,
                  vtipkamo ime gradnika, npr. <hi rend="bold">Corpus</hi>, in ga s tipko <hi
                     rend="bold">Enter </hi>dodamo na platno. Če gradnik dvokliknemo, se odpre okno
                  z nastavitvami. Vsak gradnik ima vhod ali izhod oziroma oboje, kar je označeno s
                  črtkano črto ob strani gradnika. Vhod v gradnik je na levi, izhod pa na desni
                  strani. Analiza v Orangeu vedno poteka od leve proti desni, nikoli obratno.</p>
               <p xml:id="sl-p-54">Z enakim postopkom, kot smo dodali gradnik <hi rend="bold"
                     >Corpus</hi>, dodajmo še gradnik <hi rend="bold">Corpus Viewer</hi>. Če ga
                  dvokliknemo, se odpre prazno okno. Gradnik namreč še ni prejel podatkov za
                  obdelavo. Podatke pošljemo v gradnik tako, da z miško povežemo gradnika med sabo
                  od desne črtkane črte gradnika <hi rend="bold">Corpus </hi>do leve črtkane črte
                  gradnika <hi rend="bold">Corpus Viewer</hi> (<ref target="#slika.3">Slika
                  3</ref>). Ta gradnik z dvoklikom znova odpremo in tokrat pojavno okno prikazuje
                     podatke.<note place="foot" xml:id="ftn6-sl" n="6">Prikazani so prednaloženi
                     podatki.</note>
               </p>
               <figure xml:id="slika.3">
                  <graphic url="https://sidih.si/cdn/2177/Slika3_povezava.png" height="372px"/>
                  <head>Slika 3: Povezava med gradnikoma omogoča prehod podatkov od izhoda prvega
                     gradnika do vhoda naslednjega gradnika.</head>
               </figure>
               <p xml:id="sl-p-55">V učnem gradivu bomo sestavili delotok, s katerim bomo izvedli
                  tematsko modeliranje parlamentarnih govorov in teme dodatno raziskali z
                  vizualizacijami. Celoten delotok si lahko <ref
                     target="https://www2.sistory.si/publikacije/material/parlamint/tutorial-slo.ows"
                     >prenesete</ref>, vendar priporočamo, da sledite postopnim korakom v gradivu in
                  sosledje gradnikov sestavite sami, saj boste tako najbolje razumeli posamezne faze
                  analize.</p>
            </div>
            <div type="subchapter" xml:id="ch5.2-sl">
               <head xml:id="sl-head-18">5.2. Prenos in uvoz podatkov v Orange</head>
               <p xml:id="sl-p-56">Korpus ParlaMint-SI obsega parlamentarne govore med leti 2014 in
                  2020. V praktičnem delu nas bo zanimala primerjava govorov tik pred in med
                  epidemijo COVID-19, zato podatke najprej zamejimo na primerljivo dolgi obdobji
                  pred in med epidemijo. Ker epidemično obdobje, ki je zajeto v korpusu
                  ParlaMint-SI, vključuje devet mesecev (november 2019–julij 2020, <ref
                     target="#Erjavec.2022.sl">Erjavec idr. 2022</ref>), bomo uporabili tudi podobno
                  dolgo obdobje tik pred začetkom pandemije, in sicer od januarja 2019 do oktobra
                     2019.<note place="foot" xml:id="ftn7-sl" n="7">Predhodno smo preverili, da sta
                     tako časovno zamejeni obdobji primerljivi tudi z vidika količine govorov in
                     sej, ki jih vsebujeta.</note>
               </p>
               <p xml:id="sl-p-57">Pri analizi bomo uporabili slovenski del jezikoslovno označenega
                  korpusa parlamentarnih podatkov ParlaMint 2.1 (gl. <ref target="#ch3.3-sl"
                     >poglavje 3.3</ref>). Parlamentarni govori s pripisanimi jezikoslovnimi
                  oznakami so zapisani v <ref target="https://universaldependencies.org/format.html">
                     <hi rend="underline color(0000FF)">formatu CoNLL-U</hi>
                  </ref>. Da bomo lažje začeli, so podatki za potrebe tega učnega gradiva že
                  pripravljeni in si jih <ref
                     target="https://www2.sistory.si/publikacije/material/parlamint/ParlaMint-SI-conllu.zip"
                     >prenesemo</ref> na računalnik.<note place="foot" xml:id="ftn8-sl" n="8">Če bi
                     želeli analizirati celoten korpus ali uporabiti drugačno časovno obdobje, je
                     celoten korpus na voljo v repozitoriju CLARIN.SI v <ref
                        target="http://hdl.handle.net/11356/1431">datoteki s podatki </ref>
                     <ref target="http://hdl.handle.net/11356/1431">
                        <hi rend="italic">ParlaMint-SI.ana.tgz</hi>
                     </ref>.</note>
                  <hi rend="superscript">,</hi>
                  <note place="foot" xml:id="ftn9-sl" n="9">Potrebujemo tako datoteke v formatu
                     CoNLL-U kot tudi tiste v formatu TSV. Datoteke CoNLL-U vsebujejo jezikoslovno
                     označene govore, datoteke TSV pa metapodatke o govorcih in govorih (glejte <ref
                        target="#ch3.3-sl">poglavje 3.3</ref>).</note>
               </p>
               <p xml:id="sl-p-58">Na platno dodamo gradnik <hi rend="bold">Import Documents.</hi> Z
                  dvoklikom odpremo okno za nastavitve in v prvi vrstici določimo mapo, v katero smo
                  shranili podatke (<ref target="#slika.4">Slika 4</ref>). Uvoza ni treba posebej
                  potrjevati, zgodi se samodejno, ko določimo mapo. Malo nižje obkljukamo tudi
                  možnosti <hi rend="italic">Lemma</hi> in <hi rend="italic">POS tags</hi>. Tako
                  bomo poleg govorov uvozili tudi leme in oblikoskladenjske oznake. Govor
                  posameznega poslanca za posamezno sejo bo predstavljen kot posamezen dokument. V
                  spodnjem delu okna nas program obvesti, da smo uvozili 18.476 dokumentov oziroma
                  govorov.</p>
               <figure xml:id="slika.4">
                  <graphic url="https://sidih.si/cdn/2177/Slika4_import-documents.png"/>
                  <head>Slika 4: Okno za uvoz podatkov.</head>
               </figure>
               <p xml:id="sl-p-59">Za boljše razumevanje strukture podatkov si na kratko oglejmo
                  značilnosti formata CoNLL-U. Gre za obliko formata TSV, v katerem so vrednosti
                  ločene s tabulatorjem in ki se na področju obdelave naravnega jezika uporablja za
                  zapisovanje jezikoslovno označenih besedil, saj zaradi razporeditve besedila in
                  oznak po stolpcih omogoča enostavno računalniško obdelavo. V tem formatu vsaka
                  poved predstavlja svoj sklop, besedilo pa je tudi vertikalizirano, kar pomeni, da
                  so besede zapisane ena pod drugo, kar omogoča jasen pregled nad pripisanimi
                  jezikoslovnimi oznakami. Vsaka poved ima na začetku navedene tudi metapodatke
                  (npr. ID govora, ID povedi in besedilo) (<ref target="#slika.5">Slika
                  5</ref>).</p>
               <figure xml:id="slika.5">
                  <graphic url="https://sidih.si/cdn/2177/Slika5_connlu.png"/>
                  <head>Slika 5: Zapis podatkov v formatu CoNLL-U za prvi dve povedi iz dokumenta
                     ParlaMint-SI_2019-01-28-SDZ8-Redna-04.conllu.</head>
               </figure>
            </div>
            <div type="subchapter" xml:id="ch5.3-sl" facs="https://sidih.si/cdn/2177/ch5.3.png">
               <head xml:id="sl-head-21">5.3. Pregled podatkov</head>
               <p xml:id="sl-p-60">Preden začnemo z analizo, se je dobro najprej prepričati, da so
                  naloženi podatki res pravi. To bomo storili z gradnikom <hi rend="bold">Corpus
                     Viewer</hi>, ki ga dodamo na platno in ga od leve proti desni povežemo s
                  prejšnjim gradnikom. <hi rend="bold">Corpus Viewer</hi> odpremo z dvoklikom in
                  prikaže se seznam dokumentov, ki v našem primeru predstavljajo posamezne govore
                     (<ref target="#slika.6">Slika 6</ref>). S klikom na seznam si lahko ogledamo
                  tudi druge govore, če pa med klikanjem pridržimo tipko <hi rend="italic"
                     >Shift</hi>, lahko prikažemo več govorov hkrati.</p>
               <figure xml:id="slika.6">
                  <graphic url="https://sidih.si/cdn/2177/Slika6_corpus-viewer.png"/>
                  <head>Slika 6: Pregled govorov v gradniku Corpus Viewer.</head>
               </figure>
               <p xml:id="sl-p-61">V levem zgornjem kotu vidimo osnovne informacije o korpusu:
                  število pojavnic (<hi rend="italic">tokens</hi>) in različnic (<hi rend="italic"
                     >types</hi>)<note place="foot" xml:id="ftn10-sl" n="10">Število pojavnic
                     označuje število vseh besed, števil in ločil, ki so v korpusu. Število
                     različnic pa je število unikatnih pojavnic v korpusu.</note> ter število
                  govorov (<hi rend="italic">matching documents</hi>), ki ustrezajo iskalnemu filtru
                     (<hi rend="italic">regexp filter</hi>), če bi ga uporabili. Ker je filter
                  trenutno prazen, so prikazani vsi govori (18476/18476). Zadnji podatek (<hi
                     rend="italic">matches</hi>) je število zadetkov iskalnega izraza, ki bi ga
                  lahko vnesli v polje <hi rend="italic">RegExp Filter</hi>.<note place="foot"
                     xml:id="ftn11-sl" n="11">Pri določanju iskalnega izraza lahko uporabimo pravila
                        <ref target="https://www.sketchengine.eu/guide/regular-expressions/"
                        >regularnih izrazov</ref>, ki nam omogočajo iskanje zelo specifičnih
                     zadetkov oziroma hkratno iskanje različnih oblik z enim iskalnim izrazom. Tako
                     lahko npr. z iskalnim izrazom <hi rend="italic">epidemij*</hi> zajamemo vse
                     sklanjatve besede <hi rend="italic">epidemija</hi>.</note>
               </p>
               <p xml:id="sl-p-62">V pregledovalniku na desni strani vidimo številne
                     metapodatke<note place="foot" xml:id="ftn12-sl" n="12">Nekateri metapodatki
                     lahko manjkajo, če so bile izvorne parlamentarne evidence nepopolne.
                     Jezikoslovne oznake so bile pripisane avtomatsko, kar pomeni, da so v korpusu
                     možne napake, vendar so te minimalne, saj so bila uporabljena orodja z visoko
                     natančnostjo: lematizacija 98–99 % pravilnost, oblikoslovne oznake 94–77 %,
                     skladenjske oznake 87–94 % <ref target="#Erjavec.2022.sl">(Erjavec idr.,
                        2022</ref>).</note> o govorih in govorcih, s katerimi je opisana vsebina
                     korpusa.<note place="foot" xml:id="ftn13-sl" n="13">Nabor metapodatkov je enak
                     za celotno družino korpusov ParlaMint (glejte <ref target="#ch3.3-sl">poglavje
                        3.3</ref>), vendar vsi korpusi ne vsebujejo vseh metapodatkov.</note> Vsak
                  govor je označen z imenom seje, ki ji pripada (<hi rend="italic">name</hi>), in
                  unikatno oznako (<hi rend="italic">utterance</hi>), pri čemer zadnja številka
                  izkazuje zaporedno številko govora v dotični seji. Celoten govor si lahko
                  preberemo pod spremenljivko <hi rend="italic">content</hi>. Pomemben je tudi
                  podatek o podkorpusu (<hi rend="italic">Subcorpus</hi>), ki označuje časovno
                  obdobje, v katerem je bil govor podan (<hi rend="italic">Reference</hi> označuje
                  govore pred novembrom 2019, <hi rend="italic">COVID </hi>pa od novembra 2019).</p>
               <p xml:id="sl-p-63">Sledijo podatki o govorcu – njegova vloga (<hi rend="italic"
                     >Speaker role</hi>), ki je lahko ali predsedujoči ali običajni govorec,
                  funkcija (<hi rend="italic">Speaker type</hi>), ki je lahko ali poslanec ali gost,
                  pripadnost politični stranki (<hi rend="italic">Speaker party</hi>), parlamentarni
                  status stranke (<hi rend="italic">Party status</hi>), ki je lahko opozicija ali
                  koalicija, ime govorca (<hi rend="italic">Speaker name</hi>), spol (<hi
                     rend="italic">Speaker gender</hi>) in leto rojstva (<hi rend="italic">Speaker
                     birth</hi>).</p>
            </div>
            <div type="subchapter" xml:id="ch5.4-sl">
               <head xml:id="sl-head-23">5.4. Priprava vzorca in predprocesiranje</head>
               <p xml:id="sl-p-64">Kot smo videli v 3. poglavju, za parlamentarni diskurz velja
                  jasna struktura, ki vključuje številne značilne fraze, npr. <hi rend="italic"
                     >besedo ima poslanec …, hvala za besedo, spoštovana gospa ministrica, potrjujem
                     dnevni red</hi> ipd. Nekatere fraze, ki urejajo potek razprave, so še posebej
                  značilne za predsedujoče parlamentarnim sejam, druge so zgolj del vljudnostnega
                  izražanja. Zaradi svoje narave so take fraze v parlamentarnih korpusih zelo
                  pogoste, vendar za tematsko analizo niso zanimive, temveč bi predstavljale zgolj
                  šum v rezultatih, zato jih želimo izločiti iz vzorca. V celoti jih je sicer
                  nemogoče izločiti na enostaven, avtomatiziran način, vseeno pa lahko njihovo
                  število pomembno omejimo. To bomo storili tako, da bomo pripravili vzorec
                  podatkov, iz katerega bomo izločili vse govore predsedujočih in govore, ki so
                  krajši od 50 besed (<ref target="#slika.8">Slika 8</ref>).</p>
               <cit xml:id="sl-cit-1">
                  <quote>»Hvala lepa. V skladu s poslovnikom bi želel v imenu poslanske skupine 30
                     minut odmora pred glasovanjem«.</quote>
                  <bibl>(Brane Golubović, redna seja, 6. marec 2019)</bibl>
               </cit>
               <p xml:id="sl-p-65">To odločitev smo sprejeli po ročnem pregledu dela korpusa, v
                  katerem se je izkazalo, da so taki govori večinoma zgolj zahvale ali medklici.
                  Podobno filtriranje uporabljajo tudi sorodne raziskave (<ref
                     target="#Curran.2018.sl">Curran idr., 2018</ref>). Čeprav taki govori seveda
                  niso nujno le proceduralne narave, so, zato ker so kratki, v vsakem primeru manj
                  primerni za tematsko modeliranje z metodo LDA, ki za dobre rezultate potrebuje
                  daljša besedila (glejte <ref target="#ch4-sl">4. poglavje</ref>). Poleg tega bomo
                  iz vzorca za analizo izločili tudi vse govore posameznikov in posameznic, ki v
                  parlamentu lahko nastopajo kot gosti.</p>
               <div type="subchapter" xml:id="ch5.4.1-sl"
                  facs="https://sidih.si/cdn/2177/ch5.4.1.png">
                  <head xml:id="sl-head-24">5.4.1. Odstranjevanje neželenih govorov</head>
                  <p xml:id="sl-p-66">Za oblikovanje vzorca potrebujemo gradnika <hi rend="bold"
                        >Statistics </hi>in <hi rend="bold">Select Rows</hi>. Na platno dodamo
                     gradnik <hi rend="bold">Statistics</hi> in ga povežemo z gradnikom <hi
                        rend="bold">Import Documents</hi>, pri čemer ohranimo prednastavitve, na
                     podlagi katerih gradnik prešteje število besed (<hi rend="italic">word count)
                     </hi>in število znakov (<hi rend="italic">character count</hi>) v govorih.
                     Gradnik <hi rend="bold">Statistics</hi> podatkom doda stolpca s številom besed
                     in znakov, kar si lahko ogledamo tako, da dodamo gradnik <hi rend="bold">Data
                        Table</hi>, ga odpremo in se pomaknemo skrajno desno (<ref target="#slika.7"
                        >Slika 7</ref>). Tako dobimo podatek o dolžini govorov, kar nam omogoča, da
                     zdaj z gradnikom <hi rend="bold">Select Rows</hi> izberemo zgolj tiste, ki
                     ustrezajo našim merilom glede dolžine.</p>
                  <figure xml:id="slika.7">
                     <graphic url="https://sidih.si/cdn/2177/Slika7_data-table.png"/>
                     <head>Slika 7: Stolpca skrajno desno prikazujeta podatke o številu besed in
                        znakov, ki so dodani osnovnim podatkom.</head>
                  </figure>
                  <p xml:id="sl-p-67">Ko dodamo gradnik <hi rend="bold">Select Rows</hi> (<ref
                        target="#slika.8">Slika 8</ref>), ga povežemo z gradnikom <hi rend="bold"
                        >Statistics</hi>, odpremo in nastavimo tri pogoje (pogoje dodajamo z gumbom
                        <hi rend="italic">Add condition</hi>):</p>
                  <list type="unordered" xml:id="sl-list-9">
                     <item>s prvim pogojem določimo najmanjšo dolžino govora – spremenljivko <hi
                           rend="italic">Word count</hi> omejimo z možnostjo <hi rend="italic">is
                           greater than </hi>in vpišemo želeno minimalno dolžino, v našem primeru
                        50, s čimer bomo v vzorec vključili zgolj govore, ki imajo 51 besed ali
                        več;</item>
                     <item>z drugim pogojem iz vzorca izločimo predsedujoče sejam – spremenljivko
                           <hi rend="italic">Speaker role</hi> določimo s parametrom <hi
                           rend="italic">is</hi> in parametrom <hi rend="italic"
                        >Regular</hi>;</item>
                     <item>s tretjim pogojem v vzorcu ohranimo zgolj govore poslancev –
                        spremenljivko <hi rend="italic">Speaker type</hi> določimo s parametrom <hi
                           rend="italic">is</hi> in parametrom <hi rend="italic">MP</hi>, s čimer
                        izločimo govore gostov.</item>
                  </list>
                  <figure xml:id="slika.8">
                     <graphic url="https://sidih.si/cdn/2177/Slika8_select-rows.png"/>
                     <head>Slika 8: Izbor govorov z več kot petdeset besedami, ki so jih izrekli
                        redni poslanci.</head>
                  </figure>
                  <p xml:id="sl-p-68">Na spodnjem robu gradnika <hi rend="bold">Select Rows
                     </hi>vidimo, da se je število govorov skrčilo na 6861 (s prejšnjih 18.476;
                     podrobne podatke dobimo, če kliknemo številke na spodnjem robu).</p>
               </div>
               <div type="subchapter" xml:id="ch5.4.2-sl"
                  facs="https://sidih.si/cdn/2177/ch5.4.2.png">
                  <head xml:id="sl-head-27">5.4.2. Odstranjevanje neželenih besed</head>
                  <p xml:id="sl-p-69">Za dobre rezultate tematskega modeliranja je pomembna tudi
                     predobdelava podatkov (glejte <ref target="#ch4.3-sl">poglavje 4.3.</ref>). To
                     storimo s filtriranjem v gradniku <hi rend="bold">Preprocess Text</hi>, ki ga
                     dodamo na platno, vendar ga še ne povežemo. Najprej bomo nastavili vse
                     parametre, saj se bo tako postopek izvedel bolj gladko. Kljub temu upoštevajte,
                     da je ta korak računsko zahteven in zato lahko tudi precej zamuden. Ko torej
                     odpremo gradnik <hi rend="bold">Preprocess Text</hi>, se prikažejo privzeti
                     izbrani koraki za predobdelavo besedila, katerih vrstni red in nastavitve je
                     mogoče poljubno spreminjati. Naši podatki so že tokenizirani in besede
                     transformirane v zapis z malo začetnico (prim. poglavje 5.3). Zato koraka <hi
                        rend="italic">Transformation </hi>in <hi rend="italic">Tokenization
                     </hi>odstranimo s klikom križca levo zgoraj (Mac OS) oziroma desno zgoraj
                        (Windows).<note place="foot" xml:id="ftn14-sl" n="14">Če želimo onemogočiti
                        posodobitev ob vsaki spremembi parametra, odznačimo možnost <hi
                           rend="italic">Apply Automatically </hi>levo spodaj, nato pa, ko smo
                        vnesli vse želene nastavitve, kliknemo <hi rend="italic">Apply</hi>.</note>
                     Ostane korak <hi rend="italic">Filtering</hi>, pri katerem bomo spremenili
                     nekaj nastavitev (<ref target="#slika.9">Slika 9</ref>):</p>
                  <list type="unordered" xml:id="sl-list-10">
                     <item>izključimo možnost <hi rend="italic">Stopwords</hi> – te možnosti, ki je
                        namenjena odstranitvi nepolnopomenskih besed, kot so zaimki, vezniki,
                        predlogi ipd., ne potrebujemo, ker se bomo osredotočili zgolj na
                        samostalnike;</item>
                     <item>obkljukamo možnost <hi rend="italic">Document frequency </hi>in kot mero
                        izberemo absolutno vrednost (<hi rend="italic">Absolute)</hi>, pri kateri
                        nastavimo razpon od 10 do 6861 (število vseh govorov) – tako bomo pri
                        analizi prezrli besede, ki se pojavijo v manj kot desetih govorih, kar
                        pomeni, da bomo iz analize izločili zelo redke besede, ki ne vplivajo na
                        oblikovanje specifičnih tem;</item>
                     <item>obkljukamo tudi možnost <hi rend="italic">POS tags</hi>, kar lahko
                        storimo, ker so naši podatki že oblikoskladenjsko označeni (glejte <ref
                           target="#ch3.3-sl">poglavje 3.3</ref>) – ta možnost je privzeto
                        nastavljena tako, da pri poznejših analizah upošteva zgolj samostalnike (<hi
                           rend="italic">noun</hi>) in glagole (<hi rend="italic">verb</hi>), a ker
                        so se samostalniki izkazali kot najkoristnejši pri tematskem modeliranju
                           (<ref target="#Martin.2015.sl">Martin in Johnson, 2015</ref>), za analizo
                        ohranimo zgolj to besedno vrsto, glagole (verb) pa izbrišemo.</item>
                  </list>
                  <p xml:id="sl-p-70">Sedaj <hi rend="bold">Preprocess Text</hi> povežemo z
                     gradnikom <hi rend="bold">Select Rows</hi>.</p>
                  <figure xml:id="slika.9">
                     <graphic url="https://sidih.si/cdn/2177/Slika9_preprocess-text.png"/>
                     <head>Slika 9: Nastavitve gradnika Preprocess Text.</head>
                  </figure>
                  <p xml:id="sl-p-71">Najpogostejše besede našega vzorca lahko preverimo v oblaku
                     besed. Izdelamo ga z gradnikom <hi rend="bold">Word Cloud</hi>, ki ga pripnemo
                     na gradnik <hi rend="bold">Preprocess Text.</hi> V oblaku najdemo zgolj
                     samostalnike, pri čemer je velikost besede v oblaku sorazmerna z njeno
                     frekvenco (<ref target="#slika.10">Slika 10</ref>). Prikazane besede zelo jasno
                     odražajo parlamentarni žanr besedil. Na seznamu na levi vidimo, da je
                     najpogostejša beseda <hi rend="italic">zakon</hi>, ki se v korpusu pojavi
                     19.362-krat. Ker je parlament glavno zakonodajno telo v državi, tak rezultat
                     seveda ni presenetljiv.</p>
                  <figure xml:id="slika.10">
                     <graphic url="https://sidih.si/cdn/2177/Slika10_word-cloud.png"/>
                     <head>Slika 10: Najpogostejše besede oblikovanega vzorca podatkov po
                        predprocesiranju.</head>
                  </figure>
                  <p xml:id="sl-p-72">Predprocesiranje je pomemben del obdelave besedilnih podatkov,
                     vendar je potrebno vsak korak jasno utemeljiti. Vsaka odločitev namreč vpliva
                     na končne rezultate, kar je potrebno upoštevati tudi pri interpretaciji.
                     Omenimo še, da v Orangeu filtriranje ne spreminja izhodiščnih podatkov. Po
                     predprocesiranju imamo torej še vedno na voljo izhodiščni korpus iz gradnika
                        <hi rend="bold">Select Rows</hi> ter dodano informacijo o pojavnicah iz
                     gradnika <hi rend="bold">Preprocess Text</hi>.</p>
               </div>
            </div>
         </div>
         <div type="chapter" xml:id="ch6" xml:lang="en" corresp="#ch6-sl">
            <head xml:id="head-40">6. Analysis of parliamentary speeches</head>
            <p xml:id="p-82">This chapter is divided into three practical tasks in which we use
               topic modelling and visualizations to explore the content of parliamentary debates
               before and during the COVID pandemic. We will answer the following questions:</p>
            <list type="unordered" xml:id="list-11">
               <item>Task 1: Which topics are characteristic of the corpus?</item>
               <item>Task 2: Which topics did MPs debate on the most?</item>
               <item>Task 3: Which topics were more frequent before and during the pandemic?</item>
            </list>
            <div type="subchapter" xml:id="ch6.1">
               <head xml:id="head-41">6.1. Topics of parliamentary speeches</head>
               <p xml:id="p-83">In this chapter, we will first prepare a numeric description of the
                  corpus, which is necessary for the LDA methods. Next, we will extract the topics
                  and name them. In the end, we will observe how these topics are distributed in the
                  corpus and how we can find the speech on a given topic.</p>
               <div type="subchapter" xml:id="ch6.1.1" facs="https://sidih.si/cdn/2177/ch6.1.1.png">
                  <head xml:id="head-42">6.1.1. Computing document vectors</head>
                  <p xml:id="p-84">Before we can begin topic modelling, we need preprocessed data
                     and a vector representation of speeches. We have already preprocessed the
                     corpus (see <ref target="#ch5.4">Chapter 5.4</ref>). To compute the vector
                     representation of the speeches, we will use the <hi rend="bold">Bag of
                        Words</hi> widget, which constructs a numeric description of the speeches.
                     Using this description, one can compute word distributions for topics or, in
                     other words, perform topic modelling. The numeric description, which we
                     retrieve with bag of words, contains words in columns, with their values
                     representing the number of times a word appears in a given speech. Each speech
                     is thus characterised with a vector, which represents the content of the
                     speech. The more frequent the word, the more prominent the vector of the speech
                     is in the direction of the word.</p>
                  <p xml:id="p-85">However, not all words are equal. Some words in the corpus are
                     procedural or genre-specific (see <ref target="#ch5.4">Chapter 5.4</ref>),
                     stopwords (i.e., pronouns, articles) or not specific for a given speech. The
                     word <hi rend="italic">thank</hi>, for example, appears in thematically
                     heterogeneous speeches, as many MPs thank the speaker before them. Hence the
                     word is not thematically informative. We would like to weigh the words so that
                     the words specific to a given speech have a higher weight than those that
                     frequently appear across the entire corpus. This type of weighting is called
                     TF-IDF or<hi rend="italic"> term frequency-inverse document frequency</hi>
                        (<ref target="#Jones.1972">Jones, 1972</ref>) and can be selected in the <hi
                        rend="bold">Bag of Words</hi> widget.</p>
                  <p xml:id="p-86">We add <hi rend="bold">Bag of Words</hi> directly to <hi
                        rend="bold">Preprocess Text</hi> and set the parameters to keep the <hi
                        rend="italic">Count</hi> under <hi rend="italic">Term Frequency</hi> and
                     select <hi rend="italic">IDF</hi> under <hi rend="italic">Document
                        Frequency</hi> (<ref target="#figure.11">Figure 11</ref>).</p>
                  <figure xml:id="figure.11">
                     <graphic url="https://sidih.si/cdn/2177/Figure11_bag-of-words.png"
                        height="562px"/>
                     <head>Figure 11: Setting the bag-of-words parameters.</head>
                  </figure>
               </div>
               <div type="subchapter" xml:id="ch6.1.2" facs="https://sidih.si/cdn/2177/ch6.1.2.png">
                  <head xml:id="head-44">6.1.2. Topic modelling</head>
                  <p xml:id="p-87">Now that we have the vector representation of speeches, we can
                     begin with topic modelling. If the <hi rend="bold">Bag of Words </hi>process
                     completed successfully, continue with <hi rend="italic">Option 1.</hi> However,
                     if the computing is taking too long, follow the instructions under <hi
                        rend="italic">Option 2.</hi>
                  </p>
                  <table rend="rules" xml:id="table-13">
                     <row>
                        <cell rend="left">Option 1: follow the tutorial</cell>
                        <cell rend="left">Option 2: speed up the analysis</cell>
                     </row>
                     <row>
                        <cell rend="left">
                           <figure>
                              <graphic url="https://sidih.si/cdn/2177/Figure0.7.png" height="232px"
                              />
                           </figure>
                        </cell>
                        <cell rend="left">
                           <figure>
                              <graphic url="https://sidih.si/cdn/2177/Figure0.8.png" height="148px"
                              />
                           </figure>
                        </cell>
                     </row>
                     <row>
                        <cell rend="left">Add <hi rend="bold">Topic Modelling </hi>to the canvas and
                           connect it to <hi rend="bold">Bag of Words.</hi> From here, continue as
                           described below.</cell>
                        <cell rend="left">
                           <p>If the computation is taking too long, first open a new session in
                              Orange. Then download <ref
                                 target="https://www2.sistory.si/publikacije/material/parlamint/ParlaMint-GB-bow.pkl"
                                 >ParlaMint-GB-bow.pkl</ref> and load the data into Orange with the
                                 <hi rend="bold">Corpus </hi>widget. The file contains a
                              pre-constructed bag-of-words matrix.</p>
                           <p>Now add the <hi rend="bold">Topic Modelling</hi> widget and connect it
                              directly to the <hi rend="bold">Corpus. </hi>Continue as described
                              below.</p>
                        </cell>
                     </row>
                  </table>
                  <p xml:id="p-90">Open the <hi rend="bold">Topic Modelling</hi> widget and select
                     the LDA method. Let us set the <hi rend="italic">Number of topics</hi> to 20.
                     The number of topics is up to the researcher, but related work shows that with
                     larger corpora, 20 is a good choice (see <ref target="#ch4">Chapter 4</ref>).
                     On the right, we see twenty groups of words that characterize the topics in the
                     corpus (<ref target="#figure.12">Figure 12</ref>). Some topics are easy to
                     name, while others appear a little tricky. In the following chapter, we will
                     further explore the topics which will help us to define the topics better.</p>
                  <figure xml:id="figure.12">
                     <graphic url="https://sidih.si/cdn/2177/Figure12_topic-modelling.png"/>
                     <head>Figure 12: LDA results for twenty topics.</head>
                  </figure>
                  <p xml:id="p-91">It is important to note that LDA is a stochastic method, which
                     means that it returns different results at each run as it is based on a random
                     initial topic assignment. In Orange, we bypass this characteristic by setting a
                     fixed starting point, which enables the reproducibility of the results.</p>
                  <note rend="bluebox" xml:id="note-16">
                     <p>Try it yourself: use a different number of topics, say 5 or 10. Does a
                        smaller number of topics give better results? What about setting a large
                        number of topics, say 50?</p>
                  </note>
               </div>
               <div type="subchapter" xml:id="ch6.1.3" facs="https://sidih.si/cdn/2177/ch6.1.3.png">
                  <head xml:id="head-46">6.1.3. Topic definition</head>
                  <p xml:id="p-93">LDA returns the ten words most related to each topic.<note
                        place="foot" xml:id="ftn15" n="15">It is possible to get a different result
                        with LDA than seen in the tutorial. LDA is a generative model, which
                        initiates randomly. You should always be able to get the same results on
                        your computer, but the results can differ between different versions of
                        Orange and different operating systems.</note> However, these words are
                     sometimes not informative enough to enable defining a topic. Hence, we use <hi
                        rend="bold">LDAvis</hi> (<ref target="#Sievert.2014">Sievert and Shirley,
                        2014</ref>) to help us define the themes. The main advantage of this
                     visualisation is that it scores words based on how <hi rend="italic">specific a
                        word is in the topic</hi> vs <hi rend="italic">in the corpus</hi>. The value
                     of the lambda parameter, which can be set in the widget with the <hi
                        rend="italic">Relevance</hi> slider, can be between 0 and 1, where 1
                     displays words based on how specific they are to the topic (as shown in the <hi
                        rend="bold">Topic Modelling</hi> widget) and 0 displays words based on how
                     frequent they are in the corpus. The exclusivity of the word in the corpus is
                     called <hi rend="italic">lift</hi>, which represents the ratio between the
                     frequency of the word in the topic and the frequency of the word in the
                     corpus.</p>
                  <p xml:id="p-94">Connect <hi rend="bold">LDAvis</hi> to <hi rend="bold">Topic
                        Modelling</hi> and ensure that the right data are sent to the input. The
                     LDAvis widget needs a table of word frequency per topic, which is present in
                     the <hi rend="italic">All Topics</hi> output. The output can be edited by
                     clicking on the connection between the widgets and connecting the <hi
                        rend="italic">All Topics</hi> signal to <hi rend="italic">Topics</hi> (<ref
                        target="#figure.13">Figure 13</ref>).</p>
                  <figure xml:id="figure.13">
                     <graphic url="https://sidih.si/cdn/2177/Figure13_edit-links.png" height="572px"/>
                     <head>Figure 13: Setting correct input data for the LDAvis widget.</head>
                  </figure>
                  <p xml:id="p-95">By default, <hi rend="bold">LDAvis</hi> shows words in balanced
                     order with the same proportion of exclusivity of the word in the topic and the
                     exclusivity of the word in the corpus, which usually gives good results.</p>
                  <p xml:id="p-96">The balanced relevance setting gives a different, more
                     informative set of words than seen in the <hi rend="bold">Topic Modelling</hi>
                     widget (<ref target="#figure.14">Figure 14</ref>). It is evident that Topic 2
                     talks about furlough and essential workers, Topic 4 about Brexit, and Topic 9
                     about different tiers of responses to the pandemic.</p>
                  <figure xml:id="figure.14">
                     <graphic url="https://sidih.si/cdn/2177/Figure14_ldavis.png"/>
                     <head>Figure 14: Visualisation of word frequency in the topic (red) to word
                        frequency in the corpus (grey) for Topic 2.</head>
                  </figure>
                  <note rend="bluebox" xml:id="note-18">
                     <p>Try it yourself: move the slider left and right. Which setting gives the
                        best set of words to define the topic?</p>
                  </note>
                  <figure xml:id="figure-22">
                     <graphic url="https://sidih.si/cdn/2177/Figure0.9.png" height="166px"/>
                  </figure>
                  <p xml:id="p-98">In this way, we can inspect all the topics. For an easier
                     interpretation of the results, we can replace the generic topic names (i.e.,
                     Topic 1) with meaningful labels (i.e., T1: UK &amp; nation). To do this, we
                     connect <hi rend="bold">Topic Modelling</hi> with <hi rend="bold">Select
                        Columns</hi> and the latter with <hi rend="bold">Edit Domain.</hi>
                  </p>
                  <p xml:id="p-99">First, let's open <hi rend="bold">Select Columns</hi>, where we
                     see the entire variable list, including word frequencies, which we created with
                        <hi rend="bold">Bag of Words</hi> for topic modelling. These variables are
                     no longer needed, so we remove them by selecting all the variables using Ctrl+A
                     in Windows or Cmd+A in MacOS in the <hi rend="italic">Features</hi> section and
                     drag-and-drop them to the left side, where all the variables we would like to
                     ignore are placed. We enter <hi rend="italic">Topic</hi> in the filter on the
                     left side, which lists only variables containing the name <hi rend="italic"
                        >Topic</hi> (i.e., Topic 1, Topic 2). Next, we select them and transfer them
                     back to the right side, where all the variables we would like to include in the
                     analysis are placed (<ref target="#figure.15">Figure 15</ref>).</p>
                  <figure xml:id="figure.15">
                     <graphic url="https://sidih.si/cdn/2177/Figure15_select-columns.png"/>
                     <head>Figure 15: The list of variables in Select Columns.</head>
                  </figure>
                  <p xml:id="p-100">Then we open <hi rend="bold">Edit Domain,</hi> in which we will
                     name the topics. From the list on the left, we select the first topic and set
                     its name in the <hi rend="italic">Name</hi> field on the right, i.e., <hi
                        rend="italic">T1: UK &amp; nation</hi> (<ref target="#figure.16">Figure
                        16</ref>). Naming the topics can help interpret the visualizations, which we
                     will use later to explore the topics.</p>
                  <figure xml:id="figure.16">
                     <graphic url="https://sidih.si/cdn/2177/Figure16_edit-domain.png"/>
                     <head>Figure 16: Renaming of topics in the Edit Domain widget.</head>
                  </figure>
                  <p xml:id="p-101">Once the topics are named, we get a list of topics MPs debated
                     between January 2019 and December 2020. Unsurprisingly, we find some
                     epidemic-specific topics on the list, such as <hi rend="italic">virus and
                        politics</hi> and <hi rend="italic">vaccination</hi>. Others, such as <hi
                        rend="italic">UK &amp; nation</hi> and <hi rend="italic">media freedom</hi>,
                     might be more difficult to name if we are unfamiliar with the concurrent
                     events. Roughly, the topics cover the ministry areas, such as security, trade,
                     economy, higher education, transport, and crime. At the same time, looking at
                     the list of missing topics, which one would generally expect to see covered, is
                     telling (i.e., health and social care). The fact that certain topics are
                     missing from the list does not mean the MPs did not debate them, but it does
                     show they were not talked about as much, or that they were debated only in
                     combination with other topics (i.e., the pandemic).</p>
                  <p xml:id="p-102">Such a list of topics enables a quick overview of the themes
                     that characterised parliamentary debates at a given time. However, these
                     results do not reveal additional information, such as which topic was debated
                     the most, how the topics are related to one another and what the topical
                     differences between different periods are. To answer these questions, we have
                     to analyse the results further, which we will do in the following chapters.
                     However, we will inspect how the topics are distributed in the corpus before
                     doing so. In this way, we can better understand the context of speeches and, if
                     necessary, adjust the names of the topics. At the same time, it is a great way
                     to retrieve the speeches where a certain topic is prevalent.</p>
                  <note rend="bluebox" xml:id="note-19">
                     <p>Try it yourself: name all the topics with a suitable label. Some topics will
                        be harder to define. You can use <hi rend="bold">Corpus Viewer</hi> to find
                        a word from the topic and explore its context.</p>
                  </note>
               </div>
               <div type="subchapter" xml:id="ch6.1.4" facs="https://sidih.si/cdn/2177/ch6.1.4.png">
                  <head xml:id="head-51">6.1.4. Distribution of topics in a corpus</head>
                  <p xml:id="p-104">Due to the nature of topic modelling (see <ref target="#ch4"
                        >Chapter 4</ref>), the speeches are characterised by more than a single
                     topic, but topics will have different frequencies in different documents. Topic
                     frequency or the likelihood of the topic in the speech is given between 0 and
                     1, where 1 means the topic fully characterizes the speech and 0 means the topic
                     does not characterize it. Since we deal with values on the same scale and want
                     to compare topic frequency, the most suitable visualization is the heat map.
                     Connect the <hi rend="bold">Heat Map</hi> widget with <hi rend="bold">Edit
                        Domain.</hi>
                  </p>
                  <p xml:id="p-105">Colour represents the value in the visualisation: high values
                     are displayed in yellow and white (or any other colour on the right side of the
                     colour scale). In contrast, low values are displayed in blue (or any other
                     colour on the left side of the scale). Each column represents a topic, and each
                     row a speech. In the visualization, the speeches are displayed in the same
                     order they were read initially, making the diagram quite difficult to
                     interpret. A couple of settings can fix this.</p>
                  <p xml:id="p-106">First, we will join speeches with similar topic distributions.
                     We are dealing with many speeches (130,453), so the visualization is extremely
                     tall. We can represent very similar speeches with a single line and make the
                     visualisation more compact. To do this, use <hi rend="italic">Merge by
                        k-means</hi>, which uses the k-means method to join similar speeches. The
                     default value is 50, but we will increase it to 500 because we have many
                     speeches and do not want to lose too many details.</p>
                  <p xml:id="p-107">Visualization is now more organised, but it would be even more
                     informative if similar rows lay close to each other. Note that each row is no
                     longer a single speech but a group of similar speeches. Rows can be further
                     organised with another clustering technique, which we set in the <hi
                        rend="italic">Clustering </hi>section. Set the <hi rend="italic">Rows</hi>
                     option to <hi rend="italic">Clustering (opt. ordering)</hi>.</p>
                  <figure xml:id="figure.17">
                     <graphic url="https://sidih.si/cdn/2177/Figure17_heat-map.png"/>
                     <head>Figure 17: A heat map of topic frequency. The selected branch of the
                        dendrogram contains topics with a highly expressed T8: constituency-related
                        issues topic.</head>
                  </figure>
                  <p xml:id="p-108">We see a much nicer diagram (<ref target="#figure.17">Figure
                        17</ref>) with a dendrogram on the left side. A dendrogram is a tree-like
                     structure of speech similarity, which shows connections between groups and
                     enables an easy speech selection. In the previous chapter, we learned that the
                     interpretation of certain topics is not quite clear, for example, <hi
                        rend="italic">constituency-related issues</hi>. The diagram enables
                     selecting speeches for a highly expressed topic, which can be inspected
                     further.</p>
                  <p xml:id="p-109">We have selected <hi rend="italic">T8: constituency-related
                        issues</hi> for further observation. Speeches are selected by clicking on a
                     branch in the dendrogram, where the topic is most expressed (yellow or green
                     colour). Clicking will send the selected subgroup to the output of the widget.
                     Now add <hi rend="bold">Corpus Viewer</hi> to <hi rend="bold">Heat Map</hi> to
                     read a couple of speeches.</p>
                  <p xml:id="p-110">The speeches deal with various topics concerning MPs’
                     constituents, from access to health care to discrimination against minorities.
                     In this way, we have clarified the topic label and selected a subset of
                     speeches on a given topic, which we can use for downstream analyses.</p>
                  <p xml:id="p-111">When interpreting the results of topic modelling, we need to
                     consider that a speech is not characterised by a single topic but a mixture of
                     them, which we can see for the topic <hi rend="italic">T4: trade</hi>. If we
                     select the speeches and give them a careful read, we will see that they touch
                     upon various topics, including the new taxation of foreign goods after Brexit.
                     The topic is also evident from the diagram, where certain topics with high
                     values of <hi rend="italic">T4</hi> also have high values of <hi rend="italic"
                        >T3: legislative</hi>. These two topics thus overlap in certain points as
                     already evident from the heat map. The visualisation is great for investigating
                     topic overlap, which is crucial if we are interested in selecting speeches on a
                     given topic for further analysis.</p>
                  <note rend="bluebox" xml:id="note-20">
                     <p>Try it yourself: select speeches about the virus and politics and explore
                        them.</p>
                  </note>
               </div>
            </div>
            <div type="subchapter" xml:id="ch6.2" facs="https://sidih.si/cdn/2177/ch6.2.png">
               <head xml:id="head-53">6.2. Topic map</head>
               <p xml:id="p-113">Now we know the distribution of topics by speech. We have learned
                  that several topics characterise a speech, so we would like to know how the topics
                  are related to one another. Besides, we would like to know which topics are the
                  most prevalent in our corpus. To answer these two questions, we will use a topic
                  map, where the topics will be positioned based on their similarity to one another
                  and marked by their frequency.</p>
               <p xml:id="p-114">We will construct the map with <hi rend="bold">MDS</hi>, which is
                  short for <hi rend="italic">multidimensional scaling</hi>. The visualisation tries
                  to find a projection in a 2-dimensional space such that related topics lie close
                  to one another and those unrelated are far apart. MDS computes topic relatedness
                  based on the importance of words in the topic. High relatedness means a very
                  similar word distribution, where some words can be even shared among the
                  topics.</p>
               <p xml:id="p-115">We set the connection between <hi rend="bold">Topic Modelling</hi>
                  and <hi rend="bold">MDS</hi> by connecting <hi rend="italic">All Topics</hi> to
                     <hi rend="italic">Data</hi>. In the beginning, we will see only grey points in
                  space. A point represents a topic. For easier interpretation, we will label the
                  points. We do this by setting <hi rend="italic">Labels</hi> to <hi rend="italic"
                     >Topics</hi>. Each point will be marked with a topic name – not the one we gave
                  them in <hi rend="bold">Edit Domain</hi>, but the original names. Thus, we need to
                  use a manually created list of topics for interpretation (<ref target="#table.1"
                     >Table 1</ref>).</p>
               <table xml:id="table.1" rend="rules">
                  <head>Table 1: A list of topics with the original and assigned label.</head>
                  <row>
                     <cell rend="center">
                        <hi rend="bold">Topic name</hi>
                     </cell>
                     <cell rend="center">
                        <hi rend="bold">Assigned label</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 1</cell>
                     <cell rend="left">T1: UK &amp; nation</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 2</cell>
                     <cell rend="left">T2: security</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 3</cell>
                     <cell rend="left">T3: legislative</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 4</cell>
                     <cell rend="left">T4: trade</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 5</cell>
                     <cell rend="left">T5: procedural</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 6</cell>
                     <cell rend="left">T6: business &amp; industry</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 7</cell>
                     <cell rend="left">T7: virus and politics</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 8</cell>
                     <cell rend="left">T8: constituency-related issues</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 9</cell>
                     <cell rend="left">T9: pandemic and energy transition</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 10</cell>
                     <cell rend="left">T10: economy</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 11</cell>
                     <cell rend="left">T11: sports</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 12</cell>
                     <cell rend="left">T12: child well-being</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 13</cell>
                     <cell rend="left">T13: climate change</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 14</cell>
                     <cell rend="left">T14: vaccination</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 15</cell>
                     <cell rend="left">T15: higher education</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 16</cell>
                     <cell rend="left">T16: media freedom</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 17</cell>
                     <cell rend="left">T17: schools in pandemic</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 18</cell>
                     <cell rend="left">T18: transport</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 19</cell>
                     <cell rend="left">T19: crime</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 20</cell>
                     <cell rend="left">T20: housing</cell>
                  </row>
               </table>
               <p xml:id="p-116">We will also set the size of the points to match the frequency of
                  the topic (which is the sum of topic probability in all the speeches, weighted by
                  the length of the speech). Set the <hi rend="italic">Size</hi> option to <hi
                     rend="italic">Marginal Topic Probability</hi>. To make things even clearer, set
                  the <hi rend="italic">Color</hi> to <hi rend="italic">Marginal Topic
                     Probability</hi>.</p>
               <figure xml:id="figure.18">
                  <graphic url="https://sidih.si/cdn/2177/Figure18_mds.png"/>
                  <head>Figure 18: Displaying topic relatedness in MDS.</head>
               </figure>
               <p xml:id="p-117">Thematic map displays topic relatedness with the position of the
                  points, while the size and the colour show how frequent the topic is (<ref
                     target="#figure.18">Figure 18</ref>). When topics are related, but the points
                  lie far apart due to the limitations of the 2-dimensional display, the relatedness
                  is marked with a line between the points. The most frequent topics are <hi
                     rend="italic">T3: legislative</hi> and <hi rend="italic">T8:
                     constituency-related issues</hi>, while narrower topics such as <hi
                     rend="italic">T11: sports</hi>, <hi rend="italic">T13: climate change</hi> and
                     <hi rend="italic">T14: vaccination</hi> are the least frequent.</p>
               <p xml:id="p-118">The high frequency of Topic 3 (<hi rend="italic">legislative</hi>)
                  is unsurprising, as the parliament is the main legislative body of the state. It
                  is placed close to Topic 5 (<hi rend="italic">procedural</hi>), which means
                  legislative speeches contain a lot of procedural words. It is also close to Topic
                  7 (<hi rend="italic">virus and politics</hi>), which shows that the government had
                  to adopt certain legislative measures to combat the pandemic. Topic 7 is also
                  close to Topic 8 (<hi rend="italic">constituency-related issues</hi>), which could
                  mean there was a debate on translating pandemic measures into a local
                  environment.</p>
               <figure xml:id="figure-27">
                  <graphic url="https://sidih.si/cdn/2177/Figure0.10.png" height="160px"/>
               </figure>
               <p xml:id="p-119">In short, topics that lie close to each other or are connected with
                  a line are related. However, sometimes it is not easy to understand how the two
                  topics are related — for example, Topic 1 (<hi rend="italic">UK &amp; nation</hi>)
                  and Topic 16 (<hi rend="italic">media freedom</hi>). To better understand this
                  connection, we can review the speeches with a high frequency of both topics.</p>
               <p xml:id="p-120">First, we will create a subcorpus with a strong presence of topics
                     <hi rend="italic">T1: UK &amp; nation</hi> and <hi rend="italic">T16: media
                     freedom</hi>. We do this with the <hi rend="bold">Select Rows</hi> widget,
                  which we will connect to <hi rend="bold">Topic Modelling</hi>. We have to set two
                  conditions in the <hi rend="bold">Select Rows </hi>widget: <hi rend="italic">Topic
                     1 is greater than 0.4,</hi> and <hi rend="italic">Topic 16 is greater than
                     0.4</hi> (<ref target="#figure.19">Figure 19</ref>). We will select the
                  speeches where the two topics are present with over 40-percent probability.<note
                     place="foot" xml:id="ftn16" n="16">The threshold of 40 percent is selected
                     because it is the lowest value which returns at least a couple of documents.
                     One should be aware that the threshold is low, which means the speeches do not
                     have a very high likelihood of the two topics. The value can be adjusted
                     freely.</note>
               </p>
               <figure xml:id="figure.19">
                  <graphic url="https://sidih.si/cdn/2177/Figure19_select-rows.png"/>
                  <head>Figure 19: Setting the threshold in the Select Rows widget.</head>
               </figure>
               <p xml:id="p-121">
                  <hi rend="bold">Select Rows</hi> is then connected to <hi rend="bold">Corpus
                     Viewer</hi>, which displays the selected 26 speeches at the intersection of
                  nation and media (<ref target="#figure.20">Figure 20</ref>). It is clear from the
                  speeches that they refer to internal matters of organisation of the two Houses of
                  the Parliament and the specific roles given to the MPs.</p>
               <figure xml:id="figure.20">
                  <graphic url="https://sidih.si/cdn/2177/Figure20_corpus-viewer.png"/>
                  <head>Figure 20: Overview of the selected speeches in the Corpus Viewer
                     widget.</head>
               </figure>
               <note rend="bluebox" xml:id="note-22">
                  <p>Try it yourself: Explore the Topics 3 and 5 in the same way.</p>
               </note>
            </div>
            <div type="subchapter" xml:id="ch6.3" facs="https://sidih.si/cdn/2177/ch6.3.png">
               <head xml:id="head-58">6.3. Topics before and during the pandemic</head>
               <p xml:id="p-123">We identified the topics which stand out the most in our corpus,
                  but now we would like to investigate which topics are the most characteristic of
                  the pre-pandemic and the pandemic periods. The differences between the two periods
                  (already labelled in the data with <hi rend="italic">Reference</hi> and <hi
                     rend="italic">COVID</hi>) can be explored with <hi rend="bold">Box Plot</hi>.
                  The visualisation, also known as a box-and-whisker plot, shows the distribution of
                  the variable and enables an easy comparison of topic probability by <ref
                     target="https://en.wikipedia.org/wiki/Categorical_variable">categorical
                     variables</ref> (i.e., gender, date, party).</p>
               <p xml:id="p-124">Connect <hi rend="bold">Box Plot</hi> to <hi rend="bold">Edit
                     Domain</hi>, which will keep our assigned topic labels. As we wish to compare
                  two periods, select the <hi rend="italic">Subcorpus</hi> variable in the
                  lower-left section of the widget. In the upper left section, select <hi
                     rend="italic">T1: UK &amp; nation</hi>. On the right side, we will see two box
                  plots, the upper for the pandemic period (<hi rend="italic">COVID</hi>) and the
                  lower for the pre-pandemic period (<hi rend="italic">Reference</hi>) (<ref
                     target="#figure.21">Figure 21</ref>). The visualisation shows that the debates
                  on the UK nation were more frequent before the pandemic than during the pandemic.
                  At the same time, the test result below the plot shows that the difference is
                  statistically significant, as its p-value is below 0.05. We can conclude that
                  historical topics were more frequent before the pandemic based on this
                  information.</p>
               <figure xml:id="figure.21">
                  <graphic url="https://sidih.si/cdn/2177/Figure21_box-plot1.png"/>
                  <head>Figure 21: Box plot for topic T1: UK &amp; nation before and during the
                     pandemic.</head>
               </figure>
               <figure xml:id="figure-31">
                  <graphic url="https://sidih.si/cdn/2177/Figure0.11.png" height="288px"/>
               </figure>
               <p xml:id="p-125">We could inspect the distribution for every topic separately, but
                  this would be quite laborious. Since we are not focusing on a single topic but
                  would like to understand which topics show the most difference between the two
                  periods, we will use the <hi rend="italic">Order by relevance to subgroups</hi>
                  option in the <hi rend="italic">Variable</hi> section. This option will sort the
                  variables based on the results of the statistical test. At the top, we will see
                  those variables that show the greatest difference for the selected categories,
                  which we defined in the <hi rend="italic">Subgroups</hi> section (the <hi
                     rend="italic">Subcorpus</hi> variable).</p>
               <p xml:id="p-126">At the top of the list, we will see the variables such as <hi
                     rend="italic">category</hi>, <hi rend="italic">From, To, </hi>and <hi
                     rend="italic">Term.</hi> These variables show the greatest differences between
                     <hi rend="italic">Reference</hi> and <hi rend="italic">COVID</hi> subcorpora.
                  The difference is unsurprising since these variables are time-related, which was
                  also a criterion for forming the two subcorpora (see Chapter 5.3). We are more
                  interested in the variables following these four.</p>
               <p xml:id="p-127">At the top are the topics <hi rend="italic">T7: virus and
                     politics</hi> (<ref target="#figure.22">Figure 22</ref>) and <hi rend="italic"
                     >T17: schools in a pandemic</hi>. Once we select one of them, the visualisation
                  on the right shows that the MPs talked more about the virus and politics in the
                  pre-pandemic period and more about the school in the, unsurprisingly, pandemic
                  period. The Student's t-test (57.184, p&lt;0.05) below the plot shows that the
                  difference between the two periods is significant and that the topic is more
                  prominent in the given period. The result for Topic 17 is unsurprising, but the
                  result for Topic 7 is a little strange. One would expect the speeches on the virus
                  to be more prominent during the pandemic. Looking at the speeches in <hi
                     rend="bold">Corpus Viewer</hi>, this is indeed the case – all the speeches
                  containing the word »virus« come from the <hi rend="italic">COVID</hi> period. We
                  see that these speeches talk about the virus in the context of the EU response to
                  the pandemic (making it likely that the virus under consideration is indeed the
                  coronavirus and not some other pathogen). However, the significance of the
                  pre-pandemic period in this case is due to a large portion of speeches belonging
                  to the pre-pandemic period. Skimming through the speeches, we can see that the
                  topic consists of speeches covering a range of EU-related issues linked to Brexit
                  which was in the spotlight before the COVID outbreak.</p>
               <figure xml:id="figure.22">
                  <graphic url="https://sidih.si/cdn/2177/Figure22_box-plot2.png"/>
                  <head>Figure 22: Box plot for topic T7: virus and politics.</head>
               </figure>
               <p xml:id="p-128">The results show the usefulness of topic modelling, but they also
                  point out how vital it is to understand the corpus and explore the speeches with
                  close reading.</p>
               <p xml:id="p-129">The topics can be further explored with <hi rend="bold">Select
                     Rows</hi> and <hi rend="bold">Corpus Viewer</hi>. Connect <hi rend="bold"
                     >Select Rows</hi> to<hi rend="bold"> Edit Domain.</hi> In <hi rend="bold"
                     >Select Rows</hi>, set <hi rend="italic">T7: virus and politics is greater than
                     0.98</hi>, by which we will output only the speeches with more than 98%
                  likelihood of T7. The selected speeches can be inspected in <hi rend="bold">Corpus
                     Viewer</hi> or with <hi rend="bold">Word Cloud.</hi>
               </p>
               <p xml:id="p-130">
                  <hi rend="bold">Corpus Viewer</hi> enables us to explore the context of a given
                  word. Let’s say we are interested in learning more about the lemma »vote«, which
                  is characteristic of Topic 7 (see <ref target="#ch6.1.2">Chapter 6.1.2</ref>). We
                  have already selected speeches with a high frequency of Topic 7, which outputs 62
                  speeches. We would like to see which out of those contain the lemma »vote«. We can
                  enter the lemma in the filter at the top of the widget and press <hi rend="italic"
                     >Enter</hi>. The widget will display the speeches where the lemma »vote«
                  appears – there are 36 such speeches. Indeed, we can see that the speeches refer
                  to the relationship with the EU (<ref target="#figure.23">Figure 23</ref>).</p>
               <figure xml:id="figure.23">
                  <graphic url="https://sidih.si/cdn/2177/Figure23_corpus-viewer.png"/>
                  <head>Figure 23: Corpus Viewer with speeches containing the word "vote".</head>
               </figure>
               <p xml:id="p-131">An alternative option is to display the most frequent lemmas for
                  the topic in a <hi rend="bold">Word Cloud</hi>. Word cloud would give an in-depth
                  look into the concepts discussed in this topic (<ref target="#figure.24">Figure
                     24</ref>). </p>
               <figure xml:id="figure.24">
                  <graphic url="https://sidih.si/cdn/2177/Figure24_word-cloud.png"/>
                  <head>Figure 24: Word cloud of the most frequent words in Topic 7.</head>
               </figure>
               <p xml:id="p-132">The speeches mostly refer to <hi rend="italic">deals, voting,
                     government, people,</hi> and <hi rend="italic">extension</hi>. Considering that
                  the lemma <hi rend="italic">referendum</hi> is also quite prominent, these
                  speeches probably refer to Brexit. While almost exclusively present in this topic,
                  it seems like the word virus is generally quite infrequent in these speeches. The
                  results indicate <hi rend="italic">virus</hi> has to be interpreted in the context
                  of other words characterising Topic 7. It is vital to compare the frequency of
                  characteristic words for the topic and the frequency of words in the corpus (like
                  we did in <ref target="#ch6.1.3">Chapter 6.1.3</ref>) to ensure accurate topic
                  interpretation.</p>
               <note rend="bluebox" xml:id="note-23">
                  <p>Try it yourself: In the same way we compared the subcorpora <hi rend="italic"
                        >Reference</hi> and <hi rend="italic">COVID</hi>, compare the distribution
                     of topics in opposition and coalition speeches.</p>
               </note>
            </div>
         </div>
         <div type="chapter" xml:id="ch6-sl" xml:lang="sl" corresp="#ch6">
            <head xml:id="sl-head-30">6. Analiza parlamentarnih govorov</head>
            <p xml:id="sl-p-73">To poglavje je razdeljeno na tri praktične naloge, v katerih s
               tematskim modeliranjem in nekaterimi vizualizacijami raziščemo vsebino parlamentarnih
               razprav pred in med epidemijo. Pri tem bomo odgovorili na naslednja vprašanja:</p>
            <list type="unordered" xml:id="sl-list-11">
               <item>v 1. nalogi: Katere teme zaznamujejo naše podatke?</item>
               <item>v 2. nalogi: O katerih temah so poslanci največ razpravljali?</item>
               <item>v 3. nalogi: Katere teme so izstopale med epidemijo v primerjavi s
                  predepidemičnim obdobjem?</item>
            </list>
            <div type="subchapter" xml:id="ch6.1-sl">
               <head xml:id="sl-head-31">6.1. Teme parlamentarnih razprav</head>
               <p xml:id="sl-p-74">V tem poglavju bomo za vzorec podatkov najprej pripravili
                  številski opis, ki je potreben za izvedbo metode LDA, nato bomo teme izluščili in
                  jih poimenovali, na koncu pa bomo preverili še, kako so teme razporejene po
                  dokumentih in kako lahko poiščemo govore na izbrano temo.</p>
               <div type="subchapter" xml:id="ch6.1.1-sl"
                  facs="https://sidih.si/cdn/2177/ch6.1.1.png">
                  <head xml:id="sl-head-32">6.1.1. Ustvarjanje besedilnih vektorjev</head>
                  <p xml:id="sl-p-75">Preden lahko izvedemo tematsko modeliranje, potrebujemo
                     predprocesirane podatke in vektorsko reprezentacijo govorov. Predprocesiranje
                     podatkov smo že opravili (glejte <ref target="#ch5.4-sl">poglavje 5.4</ref>),
                     vektorsko reprezentacijo pa izvedemo z gradnikom <hi rend="bold">Bag of
                        Words</hi>, ki naredi številski opis govorov, na podlagi katerega je nato
                     mogoče izračunati porazdelitev besed po temah oziroma izvesti tematsko
                     modeliranje govorov. Številski opis, ki ga pridobimo s tehniko vreče besed,
                     predstavljajo besede v stolpcih, vrednosti pa izkazujejo število pojavitev
                     posamezne besede v danem govoru. Vsak govor je tako predstavljen s svojim
                     vektorjem, ki predstavlja njegovo vsebino. Pogostejša kot je neka beseda v
                     govoru, bolj vektor tega govora kaže v smeri te besede.</p>
                  <p xml:id="sl-p-76">Vendar pa niso vse besede enakovredne. Nekatere besede v
                     korpusu so lahko izrazito proceduralne in žanrsko specifične (glejte <ref
                        target="#ch5.4-sl">poglavje 5.4</ref>), nepolnomenske (npr. zaimki, vezniki)
                     ali pa preprosto nespecifične za izbrani govor. Beseda <hi rend="italic"
                        >hvala</hi> se, na primer, pojavi v tematsko zelo heterogenih govorih, saj
                     se večina poslancev zahvali za predajo besede, zato tematsko gledano ni
                     informativna. Besede v našem vzorcu zato želimo obtežiti tako, da bodo imele
                     večjo težo take, ki so izrazito specifične za posamezni govor, nižjo težo pa
                     take, ki se pogosto pojavljajo v vseh govorih. Taka obtežitev se imenuje
                     TF-IDF, kar je angleška kratica za <hi rend="italic">term frequency-inverse
                        document frequency</hi> oziroma <hi rend="italic">frekvenca izraza–inverzna
                        frekvenca dokumenta</hi> (<ref target="#Jones.1972.sl">Jones, 1972</ref>),
                     in je na voljo kot izbirna možnost v gradniku <hi rend="bold">Bag of
                     Words</hi>.</p>
                  <p xml:id="sl-p-77">Gradnik <hi rend="bold">Bag of Words </hi>dodamo takoj za
                     gradnikom <hi rend="bold">Preprocess Text</hi> in ga nastavimo tako, da
                     ohranimo možnost preprostega štetja besed (<hi rend="italic">Count</hi>) v prvi
                     vrstici (<hi rend="italic">Term Frequency</hi>), v drugi vrstici (<hi
                        rend="italic">Document Frequency</hi>) pa izberemo IDF (<ref
                        target="#slika.11">Slika 11</ref>).</p>
                  <figure xml:id="slika.11">
                     <graphic url="https://sidih.si/cdn/2177/Slika11_bag-of-words.png"
                        height="562px"/>
                     <head>Slika 11: Nastavitve gradnika Bag of Words.</head>
                  </figure>
               </div>
               <div type="subchapter" xml:id="ch6.1.2-sl"
                  facs="https://sidih.si/cdn/2177/ch6.1.2.png">
                  <head xml:id="sl-head-34">6.1.2. Luščenje tem</head>
                  <p xml:id="sl-p-78">Sedaj, ko smo pripravili vektorsko reprezentacijo govorov,
                     lahko začnemo z luščenjem tematik. To bomo storili z gradnikom <hi rend="bold"
                        >Topic Modelling</hi>, ki ga povežemo z <hi rend="bold">Bag of Words </hi>in
                     nastavimo tako, da izberemo metodo LDA (<hi rend="italic">Latent Dirichlet
                        Allocation</hi>) in določimo 20 tem (<hi rend="italic">Number of
                     topics</hi>). Izbira števila tem je sicer poljubna, vendar sorodne raziskave
                     kažejo, da se pri večjih korpusih najbolje obnese 20 tem (glejte <ref
                        target="#ch4-sl">4. poglavje</ref>). Na desni se izpiše dvajset skupin
                     besed, ki zaznamujejo teme našega vzorca (<ref target="#slika.12">Slika
                        12</ref>). Nekatere teme je enostavno poimenovati že na prvi pogled, medtem
                     ko pri drugih krovna tematika ni povsem jasna. V naslednjem koraku bomo zato
                     izvedli dodatno analizo, na podlagi katere bomo lažje opredelili teme.</p>
                  <figure xml:id="slika.12">
                     <graphic url="https://sidih.si/cdn/2177/Slika12_topic-modelling.png"/>
                     <head>Slika 12: Rezultat tematskega modeliranja s tehniko LDA za dvajset
                        tem.</head>
                  </figure>
                  <p xml:id="sl-p-79">Pri tem koraku velja omeniti še, da je tehnika LDA
                     stohastična, kar pomeni, da ob vsakem izračunu vrne drugačne rezultate, saj
                     temelji na naključnem določanju izhodiščnih tem. To značilnost metode, ki
                     omejuje ponovljivost raziskav, v programu Orange zaobidemo z uporabo enotne
                     začetne točke, kar omogoča, da uporabniki za iste podatke dobijo enake
                     rezultate.</p>
                  <note rend="bluebox" xml:id="sl-note-16">
                     <p>Poskusite sami: uporabite različna števila tem, npr. 5 in 10. Ali z manjšim
                        številom tem dobite boljše rezultate? Kaj pa se zgodi ob uporabi precej
                        večjega števila tem, npr. 50?</p>
                  </note>
               </div>
               <div type="subchapter" xml:id="ch6.1.3-sl"
                  facs="https://sidih.si/cdn/2177/ch6.1.3.png">
                  <head xml:id="sl-head-36">6.1.3. Opredelitev tem</head>
                  <p xml:id="sl-p-81">LDA za vsako temo vrne 10 besed, ki so najpogosteje povezane z
                        njo.<note place="foot" xml:id="ftn15-sl" n="15">Možno je, da dobite nekoliko
                        drugačne rezultate, kot so navedeni v gradivu. LDA je namreč generativni
                        model, ki deluje naključno. Na svojem računalniku bi morali vedno znova
                        dobiti enake rezultate, medtem ko se rezultati lahko razlikujejo med
                        različicami programa Orange ter med operacijskimi sistemi.</note> A kot smo
                     videli, te besede niso nujno dovolj informativne, da bi omogočale opredelitev
                     tematike. Zato si pri opredeljevanju lahko pomagamo z gradnikom <hi rend="bold"
                        >LDAvis</hi> (<ref target="#Sievert.2014.sl">Sievert in Shirley,
                     2014</ref>). Bistvena prednost te vizualizacije je, da besede oceni na podlagi
                     relevantnosti, ki predstavlja razmerje med <hi rend="italic">specifičnostjo
                        besede v določeni temi</hi> in <hi rend="italic">specifičnostjo besede v
                        celotnem korpusu</hi>. Vrednost parametra lambda, ki ga v gradniku
                     nastavljamo z drsnikom <hi rend="italic">Relevance</hi>, lahko izbiramo med 0
                     in 1, pri čemer 1 prikaže besede glede na specifičnost besede v temi (kot jih
                     vidimo v gradniku <hi rend="bold">Topic Modelling</hi>), 0 pa glede na njihovo
                     pogostost v celotnem korpusu. Specifičnost besede v celotnem korpusu imenujemo
                     tudi dvig (<hi rend="italic">lift</hi>), ki predstavlja razmerje med
                     verjetnostjo besede v temi in verjetnostjo besede v korpusu.</p>
                  <p xml:id="sl-p-82">Gradnik <hi rend="bold">LDAvis</hi> torej povežemo z gradnikom
                        <hi rend="bold">Topic Modelling</hi>. Pri tem moramo paziti, da v LDAvis
                     podamo prave vhodne podatke. Gradnik namreč potrebuje tabelo zastopanosti besed
                     v temah, ki je dostopna v signalu <hi rend="italic">All Topics</hi>. Povezavo
                     uredimo tako, da dvakrat kliknemo povezavo med gradnikoma, nato pa povežemo
                     signala <hi rend="italic">All Topics </hi>in <hi rend="italic">Topics</hi>
                        (<ref target="#slika.13">Slika 13</ref>)<hi rend="italic">.</hi>
                  </p>
                  <figure xml:id="slika.13">
                     <graphic url="https://sidih.si/cdn/2177/Slika13_edit-links.png" height="572px"/>
                     <head>Slika 13: Določitev ustreznih vhodnih podatkov za gradnik LDAvis.</head>
                  </figure>
                  <p xml:id="sl-p-83">
                     <hi rend="bold">LDAvis</hi> privzeto prikaže besede, razvrščene uravnoteženo,
                     torej z enakim razmerjem med specifičnostjo besede v temi in specifičnostjo
                     besede v korpusu, kar v praksi običajno da dobre rezultate.</p>
                  <p xml:id="sl-p-84">Z nastavljeno relevantnostjo dobimo drugačen, bolj
                     informativen nabor besed, kot smo ga lahko videli v osnovnem gradniku <hi
                        rend="bold">Topic Modelling</hi> (<ref target="#slika.14">Slika 14</ref>).
                     Zdaj je očitno, da tema 8 govori o upravljanju prostora, tema 16 o političnih
                     sporih in medijskem poročanju, tema 18 je mešanica tem o kulturi, športu in
                     znanosti.</p>
                  <figure xml:id="slika.14">
                     <graphic url="https://sidih.si/cdn/2177/Slika14_ldavis-topic8.png"/>
                     <head>Slika 14: Prikaz pogostosti besed v temi (rdeča) in v celotnem vzorcu
                        (siva) za prvo temo.</head>
                  </figure>
                  <note rend="bluebox" xml:id="sl-note-18">
                     <p>Poskusite sami: poljubno premaknite drsnik relevantnosti v desno in levo.
                        Pri kateri nastavitvi je za skupine besed najlažje opredeliti temo?</p>
                  </note>
                  <figure xml:id="sl-figure-16">
                     <graphic url="https://sidih.si/cdn/2177/Slika0.3.png" height="202px"/>
                  </figure>
                  <p xml:id="sl-p-86">Tako pregledamo vse teme. Za boljšo preglednost rezultatov
                     lahko nadomestimo generična poimenovanja tem (npr. Topic 1) z ustreznimi
                     pomenskimi oznakami (npr. T1: prevoz otrok). Za ta korak moramo na gradnik <hi
                        rend="bold">Topic Modelling </hi>najprej pripeti gradnik <hi rend="bold"
                        >Select Columns, </hi>nanj pa še <hi rend="bold">Edit Domain. </hi>
                  </p>
                  <p xml:id="sl-p-87">Najprej odpremo gradnik <hi rend="bold">Select Columns</hi>,
                     kjer vidimo celoten nabor spremenljivk, vključno s frekvencami besed, ki smo
                     jih za potrebe tematskega modeliranja ustvarili z gradnikom <hi rend="bold">Bag
                        of Words</hi>. Frekvenc besed ne potrebujemo več, zato jih odstranimo tako,
                     da v razdelku <hi rend="italic">Features</hi> na desni s tipkama Ctrl+A (Cmd+A)
                     izberemo vse spremenljivke in jih prenesemo na levo stran, ki je namenjena
                     spremenljivkam, ki jih želimo prezreti. Na levi strani v filter vpišemo <hi
                        rend="italic">Topic</hi>, s čimer poiščemo spremenljivke, ki označujejo teme
                        (<hi rend="italic">Topic 1</hi>, <hi rend="italic">Topic 2 </hi>itd.), jih
                     izberemo in prenesemo nazaj na desno stran, ki je namenjena spremenljivkam, ki
                     jih želimo obdržati v tabeli (<ref target="#slika.15">Slika 15</ref>).</p>
                  <figure xml:id="slika.15">
                     <graphic url="https://sidih.si/cdn/2177/Slika15_select-columns.png"/>
                     <head>Slika 15: Urejen izbor spremenljivk v gradniku Select Columns.</head>
                  </figure>
                  <p xml:id="sl-p-88">Nato odpremo gradnik <hi rend="bold">Edit Domain</hi>, v
                     katerem bomo izvedli dejansko preimenovanje. S seznama na levi izberemo prvo
                     temo in na desni strani v polju <hi rend="italic">Name </hi>določimo njeno ime,
                     npr. <hi rend="italic">T1: prevoz otrok</hi> (<ref target="#slika.16">Slika
                        16</ref>). Poimenovanje tem nam pomaga pri interpretaciji vizualizacij, s
                     katerimi bomo teme raziskali v nadaljevanju.</p>
                  <figure xml:id="slika.16">
                     <graphic url="https://sidih.si/cdn/2177/Slika16_edit-domain.png"/>
                     <head>Slika 16: Preimenovanje prve teme v gradniku Edit Domain.</head>
                  </figure>
                  <p xml:id="sl-p-89">Ko poimenujemo vse teme, dobimo seznam tem, o katerih so
                     razpravljali poslanci od januarja 2019 do julija 2020. Ni presenetljivo, da na
                     seznamu tem najdemo <hi rend="italic">epidemiološke ukrepe</hi> in <hi
                        rend="italic">zdravstvo, </hi>medtem ko je morda nekatere druge teme, npr.
                        <hi rend="italic">prevoz otrok, davek na vozila</hi> ali <hi rend="italic"
                        >šport in kultura</hi>, težje umestiti v prostor in čas, če nam aktualno
                     dogajanje tistega časa ni znano. V grobem vidimo, da teme pokrivajo področja
                     večine ministrstev, med drugim pravosodje, notranje zadeve, finance, zdravje,
                     socialne zadeve in infrastrukturo. Obenem pa je za razumevanje takratnih
                     prednostnih nalog tak seznam zanimiv tudi z vidika manjkajočih področij, ki bi
                     jih sicer lahko pričakovali na seznamu tem parlamentarnih razprav, saj jih
                     pokrivajo specifična ministrstva (npr. zunanje zadeve). Dejstvo, da npr.
                     zunanjih zadev ni na seznamu tem, sicer ne pomeni, da poslanci o tej temi sploh
                     niso razpravljali, nakazuje pa, da o njej ni bilo toliko razprave, da bi se
                     uvrstila med 20 najizrazitejših tem za naš vzorec.</p>
                  <p xml:id="sl-p-90">Tak seznam tem nam torej omogoča hiter pregled nad temami, ki
                     so zaznamovale parlamentarno razpravo v preiskovanem obdobju, vendar pa ne
                     razkriva dodatnih informacij, npr. o kateri temi je bilo največ razprave, kako
                     so teme med sabo povezane oziroma kako so razporejene po obdobjih. Za odgovore
                     na ta vprašanja je treba rezultate tematskega modeliranja dodatno analizirati,
                     kar bomo storili v naslednjih poglavjih. Pred tem pa si bomo ogledali še, kako
                     so teme razporejene po govorih. Na ta način lahko preverimo kontekst govorov in
                     po potrebi prilagodimo poimenovanja tem, obenem pa je to eden od načinov, kako
                     izluščimo govore, v katerih izbrana tema prevladuje.</p>
                  <note rend="bluebox" xml:id="sl-note-19">
                     <p>Poskusite sami: poimenujte vse teme z ustrezno nadpomenko. Nekatere teme bo
                        težje opredeliti. Pri teh si lahko pomagate z gradnikom <hi rend="bold"
                           >Corpus Viewer</hi>, s katerim poiščete ustrezno besedo in raziščete njen
                        kontekst.</p>
                  </note>
               </div>
               <div type="subchapter" xml:id="ch6.1.4-sl"
                  facs="https://sidih.si/cdn/2177/ch6.1.4.png">
                  <head xml:id="sl-head-41">6.1.4. Zastopanost tem po govorih</head>
                  <p xml:id="sl-p-92">Zaradi zakonitosti tematskega modeliranja (glejte <ref
                        target="#ch4-sl">4. poglavje</ref>) govore običajno zaznamuje več kot ena
                     tema, vendar so teme različno močno zastopane. Zastopanost oziroma verjetnost
                     tem po govorih je izražena v razponu od 0 do 1, pri čemer 1 pomeni, da je tema
                     v največji meri prisotna v govoru, 0 pa, da tema sploh ni prisotna. V praksi
                     najpogosteje srečamo vmesne vrednosti. Ker imamo torej opravka z vrednostmi v
                     istem razponu in ker želimo primerjati zastopanost tem med sabo, je
                     najprimernejša vizualizacija toplotni diagram. Ustvarimo ga tako, da gradnik
                        <hi rend="bold">Heat Map</hi> povežemo z gradnikom <hi rend="bold">Edit
                        Domain</hi>.</p>
                  <p xml:id="sl-p-93">V diagramu je vrednost ponazorjena z barvo: visoke vrednosti
                     so označene z rumeno in belo (oziroma drugo barvo na desnem robu lestvice),
                     nizke vrednost pa z modro (oziroma drugo barvo na levem robu lestvice). Vsak
                     stolpec v diagramu predstavlja posamezno temo, vsaka vrstica pa govor. Govori
                     so v diagramu razvrščeni v takem vrstnem redu, kot smo jih naložili v program,
                     zaradi česar je trenutno diagram precej nepregleden, vendar lahko to z nekaj
                     nastavitvami popravimo.</p>
                  <p xml:id="sl-p-94">Najprej bomo govore, ki imajo podobno izražene teme, združili
                     med sabo. Opravka imamo namreč z velikim številom govorov (6861), zato se
                     vizualizacija raztegne v višino. V tem primeru lahko podobne govore predstavimo
                     z eno vrstico in tako poskrbimo za kompaktnejšo postavitev. To storimo z
                     možnostjo <hi rend="italic">Merge by k-means</hi>, ki s postopkom metode
                     k-voditeljev združi podobne govore med sabo. Prednastavljena vrednost je 50, mi
                     pa jo bomo povečali na 150, saj je naših govorov veliko in ne želimo izgubiti
                     preveč podrobnosti.</p>
                  <p xml:id="sl-p-95">Vizualizacija je tako že bolj pregledna, vendar bi bila še
                     bolj informativna, če bi bile podobne vrstice blizu ena drugi. Pozor, sedaj
                     vrstice niso več posamezni govori, temveč skupine podobnih govorov. Vrstice
                     organiziramo s še enim postopkom odkrivanja gruč, in sicer s hierarhičnim
                     razvrščanjem v skupine, ki ga nastavimo v razdelku <hi rend="italic"
                        >Clustering, </hi>kjer pri možnosti<hi rend="italic"> Rows</hi> izberemo <hi
                        rend="italic">Clustering (opt. ordering</hi>).</p>
                  <p xml:id="sl-p-96">Izriše se precej lažje berljiv diagram (<ref
                        target="#slika.17">Slika 17</ref>), ki ima na levi strani dendrogram oziroma
                     drevesno strukturo podobnosti govorov, ki kaže povezave med gručami, obenem pa
                     je priročen za natančno izbiro želene skupine govorov. V prejšnjem poglavju smo
                     ugotovili, da krovna tematika za določeno temo ali pa interpretacija nekaterih
                     tem, npr. <hi rend="italic">šport in kultura</hi>, ni popolnoma jasna. S tem
                     diagramom lahko enostavno izberemo želene govore in podrobneje analiziramo
                     njihovo vsebino.</p>
                  <figure xml:id="slika.17">
                     <graphic url="https://sidih.si/cdn/2177/Slika17_heat-map-topic18.png"/>
                     <head>Slika 17: Toplotni diagram zastopanosti tematik v govorih z izbrano vejo
                        dendrograma, ki združuje govore z močno izraženo temo T18: šport in
                        kultura.</head>
                  </figure>
                  <p xml:id="sl-p-97">Kot primer bomo izbrali temo <hi rend="italic">T18: šport in
                        kultura</hi>, ki jo predstavlja izbrana gruča v diagramu. Govore označimo
                     tako, da izberemo vejo dendrograma, kjer je tema najbolj izrazita (rumene ali
                     zelene barve) . Tako bo ta podmnožica govorov na voljo na izhodu gradnika. Zdaj
                     na gradnik <hi rend="bold">Heat Map</hi> pripnemo gradnik <hi rend="bold"
                        >Corpus Viewer</hi> in si v njem preberemo izbrane govore.</p>
                  <p xml:id="sl-p-98">Ugotovimo lahko, da govori obravnavajo različne teme, npr.
                     izdajo potrdil o opravljenih izobraževanjih, založniško dejavnost ter
                     financiranje vrhunskih športnikov. Na tak način smo torej potrdili poimenovanje
                     teme (ki je sicer nabor več podtem), obenem pa smo iz celotnega vzorca podatkov
                     izluščili zgolj govore na izbrano temo, ki jih nato lahko uporabimo za
                     nadaljnje analize.</p>
                  <p xml:id="sl-p-99">Pri interpretaciji tematskega modeliranja je nujno upoštevati,
                     da govora ne zaznamuje zgolj ena tema, temveč je v vsakem govoru prisotnih več
                     tem z različno verjetnostjo, kar lahko opazimo tudi pri temi <hi rend="italic"
                        >T11: proračun</hi>. Če govore izberemo in jih pozorno preberemo, opazimo,
                     da govori obravnavajo različne pristope k rebalansu proračuna, od povečanja
                     sredstev za Urad za Slovence v zamejstvu in po svetu do financiranja domov za
                     ostarele. Pravzaprav je to razvidno že iz diagrama, kjer vidimo, da je v
                     nekaterih govorih v izbrani gruči precej močno izražena tudi tema <hi
                        rend="italic">T10: domovi za ostarele</hi>. Toplotni diagram torej odlično
                     pokaže tudi primere tematskih presekov, kar je pomembno upoštevati, če to
                     metodo uporabljamo zgolj za izbiro govor na določeno temo, ki jo želimo
                     podrobneje raziskati. Na presek tem lahko kliknemo v diagramu in preberemo
                     govore, ki se dotikajo obeh tem hkrati. Presek govorov o proračunu in domovih
                     za ostarele predstavljajo govori o znižanju oskrbnine ter o uveljavitvi Zakona
                     o dolgotrajni oskrbi.</p>
                  <note rend="bluebox" xml:id="sl-note-20">
                     <p>Poskusite sami: izberite govore, ki govorijo o epidemiji, in jih
                        preglejte.</p>
                  </note>
               </div>
            </div>
            <div type="subchapter" xml:id="ch6.2-sl" facs="https://sidih.si/cdn/2177/ch6.2.png">
               <head xml:id="sl-head-43">6.2. Najizrazitejše teme in povezave med njimi</head>
               <p xml:id="sl-p-101">Sedaj poznamo razporeditev tem po govorih. Videli smo, da govore
                  zaznamuje več tem hkrati, zato nas zanima, kako so te teme v posameznih govorih
                  med seboj povezane. Poleg tega nas zanima, katere teme v našem vzorcu najbolj
                  izstopajo. Na obe vprašanji najlažje odgovorimo s tematsko karto, na kateri so
                  teme razporejene glede na njihovo zastopanost in razmerja do drugih tem.</p>
               <p xml:id="sl-p-102">Tematsko karto bomo izdelali z gradnikom <hi rend="bold"
                     >MDS</hi>. MDS je kratica za <hi rend="italic">multidimensional scaling</hi>
                  oziroma večrazsežnostno lestvičenje. Ta vizualizacija na podlagi vhodnih podatkov
                  poskuša najti tak prikaz v ravnini, da povezane teme ležijo skupaj, nepovezane pa
                  narazen. Pri postopku MDS se povezanost med temami izračuna glede na pomembnost
                  besed v temah. Visoka povezanost med temami tako odraža zelo podobno porazdelitev
                  besed med temami, pri čemer so lahko nekatere besede med temami celo deljene.</p>
               <p xml:id="sl-p-103">Povezavo med gradnikoma <hi rend="bold">Topic Modelling</hi> in
                     <hi rend="bold">MDS </hi>nastavimo tako, da povežemo <hi rend="italic">All
                     Topics </hi>v <hi rend="italic">Data</hi>. Na začetku vidimo zgolj sive točke v
                  ravnini, ki predstavljajo teme. Za lažjo interpretacijo bomo točkam dodali oznake.
                  To storimo tako, da pri možnosti <hi rend="italic">Labels</hi> izberemo
                  spremenljivko <hi rend="italic">Topics</hi>. Kot lahko vidimo, so točkam pripisane
                  zgolj prvotne oznake tem, ne pa tudi poimenovanja, ki smo jih dodali, zato si
                  moramo pri interpretaciji pomagati s seznamom tem, ki ga pripravimo ročno (<ref
                     target="#tabela.1">Tabela 1</ref>).</p>
               <table xml:id="tabela.1" rend="rules">
                  <head>Tabela 1: Seznam tem z izvirno in preimenovano oznako.</head>
                  <row>
                     <cell rend="center">
                        <hi rend="bold">Izvirno</hi>
                     </cell>
                     <cell rend="center">
                        <hi rend="bold">Preimenovano</hi>
                     </cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 1</cell>
                     <cell rend="left">T1: prevoz otrok</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 2</cell>
                     <cell rend="left">T2: nasilje nad živalmi</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 3</cell>
                     <cell rend="left">T3: stanovanjska politika</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 4</cell>
                     <cell rend="left">T4: davek na vozila</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 5</cell>
                     <cell rend="left">T5: trgovine ob nedeljah</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 6</cell>
                     <cell rend="left">T6: zdravstvo</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 7</cell>
                     <cell rend="left">T7: vojska</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 8</cell>
                     <cell rend="left">T8: upravljanje prostora</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 9</cell>
                     <cell rend="left">T9: epidemija in mediji</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 10</cell>
                     <cell rend="left">T10: domovi za starejše</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 11</cell>
                     <cell rend="left">T11: proračun</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 12</cell>
                     <cell rend="left">T12: sodstvo in financiranje šolstva</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 13</cell>
                     <cell rend="left">T13: promet</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 14</cell>
                     <cell rend="left">T14: epidemija in zdravstvo</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 15</cell>
                     <cell rend="left">T15: proceduralno</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 16</cell>
                     <cell rend="left">T16: politika in mediji</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 17</cell>
                     <cell rend="left">T17: banke</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 18</cell>
                     <cell rend="left">T18: šport in kultura</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 19</cell>
                     <cell rend="left">T19: pokojnine</cell>
                  </row>
                  <row>
                     <cell rend="left">Topic 20</cell>
                     <cell rend="left">T20: obvladovanje epidemije</cell>
                  </row>
               </table>
               <p xml:id="sl-p-104">Nastavili bomo tudi velikost točk, in sicer tako, da bo
                  ustrezala zastopanosti teme (ki je vsota verjetnosti teme v govorih, utežena z
                  dolžino govorov). Možnost <hi rend="italic">Size</hi> nastavimo na <hi
                     rend="italic">Marginal Topic Probability</hi>. Za boljšo preglednost pa pri
                  možnosti <hi rend="italic">Color </hi>prav tako izberemo <hi rend="italic"
                     >Marginal Topic Probability.</hi>
               </p>
               <figure xml:id="slika.18">
                  <graphic url="https://sidih.si/cdn/2177/Slika18_mds.png"/>
                  <head>Slika 18: Prikaz podobnosti tem v vizualizaciji MDS.</head>
               </figure>
               <p xml:id="sl-p-105">Tematska karta s položajem točk kaže podobnost tem, velikost in
                  barva točk pa njihovo zastopanost v našem vzorcu govorov (<ref target="#slika.18"
                     >Slika 18</ref>). Kadar so si teme podobne, vendar točke zaradi omejitev
                  dvodimenzionalne vizualizacije ležijo daleč narazen, je ta podobnost izražena s
                  premico, ki povezuje ti dve točki. Vidimo, da sta najbolj zastopani obsežni temi
                  15 (<hi rend="italic">proceduralno</hi>) in 11 (<hi rend="italic">proračun</hi>),
                  najmanj pa tematsko ozke teme 1 (<hi rend="italic">prevoz otrok</hi>), 3 (<hi
                     rend="italic">stanovanjska politika</hi>) in 20 (<hi rend="italic">obvladovanje
                     epidemije</hi>). </p>
               <p xml:id="sl-p-106">Močna zastopanost teme 11 (<hi rend="italic">proračun</hi>) ni
                  presenetljiva, saj je posledica pogostih razprav o rebalansu proračuna kot
                  odgovoru na epidemiološke razmere (Vlada Republike Slovenije, 2020). Blizu nje
                  ležita tudi temi 10 (<hi rend="italic">domovi za starejše</hi>) in 19 (<hi
                     rend="italic">pokojnine</hi>), kar kaže, da se je o domovih za starejše in
                  pokojninah razpravljalo tudi v kontekstu razporejanja davkoplačevalskega denarja.
                  Ti dve temi (<hi rend="italic">T10</hi> in <hi rend="italic">T19</hi>) sta si
                  blizu tudi ena drugi, kar pa zopet ni presenetljivo, saj obe govorita o starejši
                  populaciji.</p>
               <figure xml:id="sl-figure-21">
                  <graphic url="https://sidih.si/cdn/2177/Slika0.4.png" height="198px"/>
               </figure>
               <p xml:id="sl-p-107">Blizu teme, ki zaznamuje razprave o proračunu, ležita tudi temi
                  9 (<hi rend="italic">epidemija in mediji</hi>) in 16 (<hi rend="italic">politika
                     in mediji</hi>), ki sta obenem povezani med sabo. Te povezave (med temama 9 in
                  16) ni težko potrditi, če smo vsaj malo seznanjeni z dogajanjem v času epidemije,
                  ko so mediji odigrali ključno vlogo pri obveščanju javnosti o najnovejših ukrepih,
                  obenem pa so bili pod hudimi pritiski politike. Zgolj na podlagi vizualizacije pa
                  je težje interpretirati povezavo med temama 16 (<hi rend="italic">politika in
                     mediji</hi>) in 11 (<hi rend="italic">proračun</hi>). Da bi lažje razumeli, na
                  kakšen način sta ti dve temi povezani, si lahko ogledamo govore, ki izkazujeta
                  podobno zastopanost obeh tem.</p>
               <p xml:id="sl-p-108">Govore na preseku obeh tem si ogledamo tako, da najprej
                  ustvarimo podmnožico govorov, ki imajo močno izraženi obe temi, torej <hi
                     rend="italic">T16: politika in mediji</hi> in <hi rend="italic">T11:
                     proračun</hi>. To storimo z gradnikom <hi rend="bold">Select Rows</hi>, ki ga
                  povežemo z gradnikom <hi rend="bold">Topic Modelling</hi>. V gradniku nastavimo
                  dva pogoja, in sicer <hi rend="italic">Topic 16 is greater than 0.3</hi> in <hi
                     rend="italic">Topic 11 is greater than 0.3</hi> (<ref target="#slika.19">Slika
                     19</ref>). Tako bomo izbrali zgolj govore, v katerih sta temi 16 in 11 izraženi
                  z več kot 30-odstotno verjetnostjo.<note place="foot" xml:id="ftn16-sl" n="16"
                     >Mejo pri 30 odstotkih smo izbrali, ker je to najnižja vrednost, ki vrne vsaj
                     nekaj dokumentov. Pri tem se je treba zavedati, da je meja precej nizka, torej
                     dokumenti izkazujejo nizko zastopanost teme. Vrednost lahko poljubno
                     prilagajate.</note>
               </p>
               <figure xml:id="slika.19">
                  <graphic url="https://sidih.si/cdn/2177/Slika19_select-rows.png" height="598px"/>
                  <head>Slika 19: Nastavitev mej za prisotnost tem v grandiku Select Rows.</head>
               </figure>
               <p xml:id="sl-p-109">
                  <hi rend="bold">Select Rows</hi> nato povežemo v gradnik <hi rend="bold">Corpus
                     Viewer</hi>, v katerem preberemo izbranih šest govorov, ki predstavljajo presek
                  tem o proračunu ter politiki in medijih (<ref target="#slika.20">Slika 20</ref>).
                  Iz govorov je razvidno, da gre pri tem za strankarska prerekanja o rebalansu
                  proračuna.</p>
               <figure xml:id="slika.20">
                  <graphic url="https://sidih.si/cdn/2177/Slika20_corpus-viewer.png"/>
                  <head>Slika 20: Pregled izbranih dokumentov v gradniku Corpus Viewer.</head>
               </figure>
               <note rend="bluebox" xml:id="sl-note-22">
                  <p>Poskusite sami: Na enak način raziščite, kako sta povezani tema 9 in tema
                     11.</p>
               </note>
            </div>
            <div type="subchapter" xml:id="ch6.3-sl" facs="https://sidih.si/cdn/2177/ch6.3-sl.png">
               <head xml:id="sl-head-48">6.3. Teme pred in med epidemijo</head>
               <p xml:id="sl-p-111">Ugotovili smo, katere teme v našem vzorcu najbolj izstopajo,
                  zdaj pa nas zanima, katere teme so najbolj značilne za obdobje pred epidemijo in
                  med njo. Razliko med obdobjema (ki sta označena kot podkorpusa <hi rend="italic"
                     >Reference </hi>in <hi rend="italic">COVID</hi>) bomo raziskali v gradniku <hi
                     rend="bold">Box Plot</hi>. Ta vizualizacija, v slovenščini znana tudi kot
                  škatla z brki, kaže porazdelitve spremenljivk ter omogoča njihovo enostavno
                  primerjavo po <ref target="https://en.wikipedia.org/wiki/Categorical_variable">
                     <hi rend="underline color(1155CC)">kategoričnih spremenljivkah</hi>
                  </ref> (npr. spol, datum, stranka).</p>
               <p xml:id="sl-p-112">
                  <hi rend="bold">Box Plot</hi> povežemo z gradnikom <hi rend="bold">Edit
                     Domain</hi>, saj bodo tako med rezultati že poimenovane teme. Ker želimo
                  obdobji primerjati med sabo, v spodnjem razdelku na levi strani izberemo
                  spremenljivko <hi rend="italic">Subcorpus</hi>, v zgornjem razdelku pa kar temo
                     <hi rend="italic">T1: prevoz otrok</hi>. Na desni se prikažeta dve škatli z
                  brki, zgornja za obdobje med epidemijo (<hi rend="italic">COVID</hi>), spodnja pa
                  za obdobje pred epidemijo (<hi rend="italic">Reference</hi>) (<ref
                     target="#slika.21">Slika 21</ref>). Iz vizualizacije lahko razberemo, da so
                  bile razprave na temo sodstva pogostejše pred epidemijo kot pa med njo. Obenem nam
                  rezultat statističnega testa, ki je naveden pod vizualizacijo, potrjuje, da gre za
                  statistično značilno razliko, njegova vrednost p je namreč nižja od 0,05. Na
                  podlagi tega lahko zaključimo, da je bila tema o sodstvu bolj značilna za
                  predepidemično obdobje.</p>
               <figure xml:id="slika.21">
                  <graphic url="https://sidih.si/cdn/2177/Slika21_box-plot.png"/>
                  <head>Slika 21: Škatli z brki za temo T1: prevoz otrok za obdobje pred in med
                     epidemijo.</head>
               </figure>
               <figure xml:id="sl-figure-25">
                  <graphic url="https://sidih.si/cdn/2177/Slika0.5.png" height="378px"/>
               </figure>
               <p xml:id="sl-p-113">Na tak način bi lahko pregledali porazdelitev za vsako temo
                  posebej, vendar bi bilo to precej časovno zamudno. Ker trenutno nismo osredotočeni
                  na eno samo temo, ampak bi radi ugotovili, pri katerih temah se kažejo največje
                  razlike med obdobjema, si bomo pomagali z možnostjo <hi rend="italic">Order by
                     relevance to subgroups</hi> pod razdelkom <hi rend="italic">Variable. </hi>Tako
                  bomo samodejno razvrstili spremenljivke glede na njihovo vrednost statističnega
                  testa. Na vrhu bodo torej prikazane tiste spremenljivke, ki za izbrano razdelitev,
                  ki smo jo določili v razdelku <hi rend="italic">Subgroups</hi> (v našem primeru
                     <hi rend="italic">Subcorpus</hi>), izkazujejo največje razlike.</p>
               <p xml:id="sl-p-114">Povsem na vrh razdelka <hi rend="italic">Variable </hi>so
                  uvrščene spremenljivke, kot so <hi rend="italic">Title, From, To </hi>in <hi
                     rend="italic">Meeting</hi>. Gre torej za spremenljivke, ki izkazujejo izrazito
                  različno porazdelitev med podkorpusoma <hi rend="italic">Reference </hi>in <hi
                     rend="italic">COVID</hi>, vendar to ni presenetljivo, saj so vse te
                  spremenljivke časovno zamejene, kar je bil tudi kriterij za oblikovanje obeh
                  podkorpusov (glejte <ref target="#ch3.3-sl">poglavje 3.3</ref>). Za naše potrebe
                  je zanimiv vrstni red tem, ki sledijo tem prvim spremenljivkam.</p>
               <p xml:id="sl-p-115">Najvišje na seznamu sta temi <hi rend="italic">T12: sodstvo in
                     financiranje šolstva</hi> (<ref target="#slika.22">Slika 22</ref>) in <hi
                     rend="italic">T20: obvladovanje epidemije</hi>. Ko ju izberemo, vizualizacija
                  na desni pokaže, da so poslanci o sodstvu govorili več pred epidemijo, o
                  obvladovanju epidemije pa, nepresenetljivo, med epidemijo. Rezultat študentovega
                  t-testa (13,824, p&lt;0,05), naveden pod vizualizacijo, obenem potrjuje, da gre za
                  statistično pomembno razliko med obdobjema in da sta torej temi pogostejši v
                  določenem času. Glede na okoliščine tak rezultat ni presenetljiv, kaže pa na
                  zanesljivost metode za podobne raziskave. Sledita temi <hi rend="italic">T14:
                     epidemija in zdravstvo </hi>in <hi rend="italic">T2: nasilje nad živalmi</hi>
                  (prva izkazuje večjo pogostost v epidemičnem, druga pa v predepidemičnem času).
                  Tudi tukaj se kaže statistično značilna razlika pri zastopanosti posamezne teme
                  med obdobjema.</p>
               <figure xml:id="slika.22">
                  <graphic url="https://sidih.si/cdn/2177/Slika22_box-plot2.png"/>
                  <head>Slika 22: Škatli z brki za temo T12: sodstvo in financiranje šolstva.</head>
               </figure>
               <p xml:id="sl-p-116">Dejstvo, da sta temi o epidemiji bolj izraziti v COVID
                  podkorpusu, pravzaprav ni presenetljivo. Bolj kot kaj drugega to potrjuje
                  uporabnost tematskega modeliranja za podobne raziskave.</p>
               <p xml:id="sl-p-117">Teme lahko podrobneje raziščemo s pomočjo gradnikov <hi
                     rend="bold">Select Rows</hi> in <hi rend="bold">Corpus Viewer</hi>. <hi
                     rend="bold">Select Rows</hi> povežemo na <hi rend="bold">Edit Domain</hi>. V
                     <hi rend="bold">Select Rows</hi> izberemo spremenljivko »T14: epidemija in
                  zdravstvo« in nastavimo pogoj <hi rend="italic">is greater than 0.7</hi>, s čimer
                  bomo izbrali tiste govore, ki imajo zastopanost teme višjo kot 0,7 (več kot 70 %
                  verjetnost, da je tema prisotna v govoru). Izbrane govore nato lahko pogledamo v
                  gradniku <hi rend="bold">Word Cloud</hi>.</p>
               <figure xml:id="slika.23">
                  <graphic url="https://sidih.si/cdn/2177/Slika23_word-cloud.png"/>
                  <head>Slika 23: Oblak najpogostejših besed za temo 14.</head>
               </figure>
               <p xml:id="sl-p-118">Vidimo, da je govora zlasti o <hi rend="italic">pogodbah</hi> za
                     <hi rend="italic">nabavo opreme</hi>, delu <hi rend="italic">vlade</hi> in <hi
                     rend="italic">ministrov</hi> v času epidemije, vlogi <hi rend="italic"
                     >podjetij</hi> za nakup opreme, na primer <hi rend="italic">ventilatorjev</hi>,
                  ter o <hi rend="italic">Zavodu</hi> za blagovne rezerve (<ref target="#slika.23"
                     >Slika 23</ref>). Veliko poudarka pri reševanju epidemije je zlasti na dobavi
                  opreme, birokratski odgovornosti za nakup ter vlogi države pri zagotavljanju
                  dobave. Ministrstvo za zdravje je že 3. 2. 2020 pričelo z ugotavljanjem zalog
                  zaščitne in medicinske opreme, med drugim tudi ventilatorjev (<ref
                     target="#RS_RS.2021.sl">RS RS, 2021</ref>), 2. 4. 2020 pa je Državni zbor za
                  seji sprejel Zakon o interventnih ukrepih za zajezitev epidemije COVID-19 in
                  omilitev njenih posledic za državljane in gospodarstvo (<ref
                     target="#DZ_RS.2020.sl">DZ RS, 2020</ref>).</p>
               <note rend="bluebox" xml:id="sl-note-23">
                  <p>Poskusite sami: Na enak način, kot smo primerjali podkorpusa Reference in
                     COVID, primerjajte med sabo tematsko porazdelitev v govorih opozicije in
                     koalicije.</p>
               </note>
            </div>
         </div>
         <div type="chapter" xml:id="ch7" xml:lang="en" corresp="#ch7-sl">
            <head xml:id="head-63">7. Conclusion</head>
            <p xml:id="p-134">Parliamentary corpora, which contain the records of parliamentary
               debates, provide an important source for researching politics and its impact on
               society. These corpora usually hold rich metadata on the speakers and speeches and
               include multi-layered linguistic annotations that enable researchers to explore
               various research questions. Due to the size of such corpora, text mining methods,
               such as topic modelling, which enables topic extraction, prove to be extremely useful
               in researching their content. In this tutorial, we present the LDA method, one of the
               most popular methods for topic modelling. The analysis based on this method is
               performed in Orange, an open-source software for visual programming, which allows
               advanced data processing without code. The analysis in this tutorial was made on the
               ParlaMint-GB corpus that contains British parliamentary records.</p>
            <figure xml:id="figure.25">
               <graphic url="https://sidih.si/cdn/2177/Figure25_final-workflow.png" height="406px"/>
               <head>Figure 25: The final workflow.</head>
            </figure>
            <p xml:id="p-135">The tutorial is designed for self-study and breaks down the analytical
               process into simple steps illustrated by numerous screenshots for easy progress (<ref
                  target="#figure.25">Figure 25</ref>). It also includes instructions for additional
               individual work, which helps consolidate the acquired knowledge and encourages users
               to use the software independently. While special emphasis is given to the
               presentation of the key characteristics of the analysed data, the tutorial also
               describes the specificities and limitations of the method used, thus promoting a
               critical approach to data analysis.</p>
            <p xml:id="p-136">Although the tutorial bases its analysis on the British parliamentary
               data, it is easy to extend the research to other text genres and other languages.
               Since the presented method is not language-specific, it can be used on any of the
               ParlaMint corpora. The value of the tutorial for students and researchers in the
               social sciences and humanities, therefore, reaches far beyond the specific research
               problems explored in this tutorial.</p>
         </div>
         <div type="chapter" xml:id="ch7-sl" xml:lang="sl" corresp="#ch7">
            <head xml:id="sl-head-52">7. Zaključek</head>
            <p xml:id="sl-p-120">Parlamentarni korpusi, ki vsebujejo zapise parlamentarnih sej, so
               pomemben vir za raziskovanje političnega in družbenega dogajanja. Običajno vsebujejo
               številne metapodatke o govorcih in govorih, pogosto pa so tudi bogato jezikoslovno
               označeni, kar raziskovalcem omogoča oblikovanje najrazličnejših raziskovalnih
               vprašanj. Zaradi velikega obsega so za raziskovanje vsebine parlamentarnih korpusov
               izrazito primerne metode rudarjenja besedil, med katere uvrščamo tudi tematsko
               modeliranje, ki omogoča luščenje vsebinskih tematik iz korpusa. V tem učnem gradivu
               smo tako prikazali uporabo tehnike LDA, ki je ena od najbolj priljubljenih tehnik za
               tematsko modeliranje. Analizo smo izvedli v prostodostopnem programu za vizualno
               programiranje Orange, ki omogoča napredno obdelavo podatkov tudi tistim, ki niso
               vešči pisanja programske kode. Za potrebe analize smo uporabili korpus ParlaMint-SI,
               ki vsebuje slovenske parlamentarne razprave.</p>
            <figure xml:id="slika.24">
               <graphic url="https://sidih.si/cdn/2177/Slika24_entire-workflow.png"/>
               <head>Slika 24: Prikaz celotnega delotoka iz učnega gradiva.</head>
            </figure>
            <p xml:id="sl-p-121">Učno gradivo je zasnovano za samostojno učenje in vsebuje enostavne
               opise korakov, ki so pospremljeni s številnimi posnetki zaslona za lažje sledenje
                  (<ref target="#slika.24">Slika 24</ref>). Poleg tega so dodana navodila za dodatno
               samostojno delo, kar pomaga utrjevati znanje in spodbuja k samostojni rabi programa
               Orange. V učnem gradivu je posebna pozornost namenjena predstavitvi bistvenih
               značilnosti obravnavanih podatkov, opisane pa so tudi zakonitosti in omejitve metode,
               kar uporabnike spodbuja k primerno kritični uporabi metode in ustrezni interpretaciji
               rezultatov.</p>
            <p xml:id="sl-p-122">V učnem gradivu smo za potrebe analize sicer uporabili slovenske
               parlamentarne podatke, vendar je analizo enostavno razširiti ne le na druge jezike,
               ampak tudi na druge primerne besedilne žanre. Družina korpusov ParlaMint namreč
               združuje številne primerljive parlamentarne korpuse, predstavljena metoda tematskega
               modeliranja pa ni jezikovnospecifična, zato jo lahko uporabimo na katerem koli
               jeziku. Vzporedno s slovenskim učnim gradivom smo pripravili tudi gradivo z govori
               britanskega parlamenta, ki ga lahko vzamete za primerjavo. Vrednost učnega gradiva za
               študente in raziskovalce na področju družboslovja in humanistike torej vsekakor sega
               prek specifičnih raziskovalnih vprašanj, obravnavanih v tem učnem gradivu.</p>
         </div>
      </body>
      <back>
         <div type="appendix" xml:id="acknw" xml:lang="en" corresp="#acknw-sl">
            <head xml:id="head-65">8. Acknowledgements</head>
            <p xml:id="p-137">The work described in this paper was funded by the Slovenian Research
               Agency research programme P6-0436: Digital Humanities: resources, tools, and methods
               (2022- 2027), the Social Sciences &amp; Humanities Open Cloud (SSHOC) project (<ref
                  target="https://www.sshopencloud.eu/">https://www.sshopencloud.eu/</ref>), the
               CLARIN ERIC ParlaMint project (<ref target="https://www.clarin.eu/parlamint"
                  >https://www.clarin.eu/parlamint</ref>) and the DARIAH-SI research infrastructure.
               We would also like to thank Çağrı Çöltekin, Marta Kołczyńska, Jiřina Popelikova,
               Mladen Zobec and Jure Skubic for their thorough reviews and thoughtful comments.</p>
         </div>
         <div type="appendix" xml:id="acknw-sl" xml:lang="sl" corresp="#acknw">
            <head xml:id="sl-head-54">8. Zahvala</head>
            <p xml:id="sl-p-123">Delo, opisano v pričujočem gradivu, je financirala Slovenska
               raziskovalna agencija, raziskovalni program P6-0436: Digitalna humanistka: viri,
               orodja, metode (2022-2027), projekt Social Sciences &amp; Humanities Open Cloud
               (SSHOC) (<ref target="https://www.sshopencloud.eu/"
                  >https://www.sshopencloud.eu/</ref>), projekt CLARIN ERIC ParlaMint (<ref
                  target="https://www.clarin.eu/parlamint">https://www.clarin.eu/parlamint</ref>) in
               raziskovalna infrastruktura DARIAH-SI. Posebna zahvala gre tudi Çağrıju Çöltekinu,
               Marti Kołczyński, Jiřini Popelikovi, Mladenu Zobcu in Juretu Skubicu za strokovno
               recenzijo in testiranje učnega gradiva ter vse njihove koristne komentarje.</p>
         </div>
         <div type="bibliogr" xml:id="bibl" xml:lang="en" corresp="#bibl-sl">
            <head xml:id="head-66">9. References</head>
            <listBibl xml:id="listBibl-1">
               <bibl xml:id="Abercrombie.2020">Abercrombie, G., &amp; Batista-Navarro, R. (2020).
                  Sentiment and position-taking analysis of parliamentary debates: A systematic
                  literature review. <hi rend="italic">Journal of Computational Social Science</hi>,
                     <hi rend="italic">3</hi>(1), 245–270.</bibl>
               <bibl xml:id="Albalawi.2020">Albalawi, R., Yeap, T. H., &amp; Benyoucef, M. (2020).
                  Using topic modeling methods for short-text data: A comparative analysis. <hi
                     rend="italic">Frontiers in Artificial Intelligence</hi>, <hi rend="italic"
                     >3</hi>, 42.</bibl>
               <bibl xml:id="Allen.2020">Allen, C., &amp; Murdock, J. (2020). <hi rend="italic">LDA
                     topic modeling: Contexts for the history &amp; philosophy of
                  science</hi>.</bibl>
               <bibl xml:id="Arun.2010">Arun, R., Suresh, V., Veni Madhavan, C., &amp; Murthy, N.
                  (2010). <hi rend="italic">On finding the natural number of topics with latent
                     dirichlet allocation: Some observations</hi>. 391–402.</bibl>
               <bibl xml:id="Bayley.2004">Bayley, P. (2004). <hi rend="italic">Cross-cultural
                     perspectives on parliamentary discourse</hi> (Vol. 10). John Benjamins
                  Publishing.</bibl>
               <bibl xml:id="Bergmann.2018">Bergmann, H., Geese, L., Koss, C., &amp; Schwemmer, C.
                  (2018). <hi rend="italic">Using legislative speech to unveil conflict between
                     coalition parties</hi> [Preprint]. SocArXiv. <ref
                     target="https://doi.org/10.31235/osf.io/pgnwa"
                     >https://doi.org/10.31235/osf.io/pgnwa</ref>.</bibl>
               <bibl xml:id="Blätte.2020">Blätte, A., Gehlhar, S., &amp; Leonhardt, C. (2020). <hi
                     rend="italic">The Europeanization of Parliamentary Debates on Migration in
                     Austria, France, Germany, and the Netherlands</hi>. 66–74.</bibl>
               <bibl xml:id="Blei.2003">Blei, D. M., Ng, A. Y., &amp; Jordan, M. I. (2003). Latent
                  dirichlet allocation. <hi rend="italic">Journal of Machine Learning Research</hi>,
                     <hi rend="italic">3</hi>(Jan), 993–1022.</bibl>
               <bibl xml:id="Chizhik.2021">Chizhik, A. V., &amp; Sergeyev, D. A. (2021). <hi
                     rend="italic">Exploring the Parliamentary Discourse of the Russian Federation
                     Using Topic Modeling Approach</hi>. 403–416.</bibl>
               <bibl xml:id="Curran.2018">Curran, B., Higham, K., Ortiz, E., &amp; Vasques Filho, D.
                  (2018). Look who’s talking: Two-mode networks as representations of a topic model
                  of New Zealand parliamentary speeches. <hi rend="italic">PLOS ONE</hi>, <hi
                     rend="italic">13</hi>(6), e0199072. <ref
                     target="https://doi.org/10.1371/journal.pone.0199072"
                     >https://doi.org/10.1371/journal.pone.0199072</ref>.</bibl>
               <bibl xml:id="deCampos.2021">de Campos, L. M., Fernandez-Luna, J. M., Huete, J. F.,
                  &amp; Redondo-Expósito, L. (2021). LDA-based term profiles for expert finding in a
                  political setting. <hi rend="italic">Journal of Intelligent Information
                     Systems</hi>, <hi rend="italic">56</hi>(3), 529–559.</bibl>
               <bibl xml:id="Demšar.2013">Demšar, J., Curk, T., Erjavec, A., Gorup, Č., Hočevar, T.,
                  Milutinovič, M., Možina, M., Polajnar, M., Toplak, M., &amp; Starič, A. (2013).
                  Orange: Data mining toolbox in Python. <hi rend="italic">The Journal of Machine
                     Learning Research</hi>, <hi rend="italic">14</hi>(1), 2349–2353.</bibl>
               <bibl xml:id="Erjavec.2021">Erjavec, T. et al. (2021). <hi rend="italic"
                     >Linguistically annotated multilingual comparable corpora of parliamentary
                     debates ParlaMint.ana 2.1</hi> (v2.1) [Computer software]. Slovenian language
                  resource repository CLARIN.SI. <ref target="http://hdl.handle.net/11356/1431"
                     >http://hdl.handle.net/11356/1431</ref>
               </bibl>
               <bibl xml:id="Erjavec.2022">Erjavec, T., Ogrodniczuk, M., Osenova, P., &amp; et al.
                  (2022). The ParlaMint corpora of parliamentary proceedings. <hi rend="italic">Lang
                     Resources &amp; Evaluation</hi>. <ref
                     target="https://doi.org/10.1007/s10579-021-09574-0"
                     >https://doi.org/10.1007/s10579-021-09574-0</ref>. </bibl>
               <bibl xml:id="Erjavec.2019">Erjavec, T., &amp; Pancur, A. (2019). Parla-CLARIN: TEI
                  guidelines for corpora of parliamentary proceedings. <hi rend="italic">Book of
                     Abstracts of the TEI2019: What Is Text, Really</hi>.</bibl>
               <bibl xml:id="Fišer.2021">Fišer, D., &amp; Pahor de Maiti, K. (2021). »Prvič, sem
                  političarka in ne politik, drugič pa…«. <hi rend="italic">Contributions to
                     Contemporary History</hi>, <hi rend="italic">61</hi>(1). <ref
                     target="https://doi.org/10.51663/pnz.61.1.07"
                     >https://doi.org/10.51663/pnz.61.1.07</ref>. </bibl>
               <bibl xml:id="Gkoumas.2018">Gkoumas, D., Pontiki, M., Papanikolaou, K., &amp;
                  Papageorgiou, H. (2018). <hi rend="italic">Exploring the Political Agenda of the
                     Greek Parliament Plenary Sessions</hi> (D. Fišer, M. Eskevich, &amp; F. de
                  Jong, Eds.).</bibl>
               <bibl xml:id="Grimmer.2013">Grimmer, J., &amp; Stewart, B. M. (2013). Text as data:
                  The promise and pitfalls of automatic content analysis methods for political
                  texts. <hi rend="italic">Political Analysis</hi>, <hi rend="italic">21</hi>(3),
                  267–297.</bibl>
               <bibl xml:id="Høyland.2019">Høyland, B., &amp; Søyland, M. G. (2019). Electoral
                  reform and parliamentary debates. <hi rend="italic">Legislative Studies
                     Quarterly</hi>, <hi rend="italic">44</hi>(4), 593–615.</bibl>
               <bibl xml:id="Ilie.2010">Ilie, C. (2010). <hi rend="italic">European parliaments
                     under scrutiny: Discourse strategies and interaction practices</hi> (Vol. 38).
                  John Benjamins Publishing.</bibl>
               <bibl xml:id="Jacobs.2019">Jacobs, T., &amp; Tschötschel, R. (2019). Topic models
                  meet discourse analysis: A quantitative tool for a qualitative approach. <hi
                     rend="italic">International Journal of Social Research Methodology</hi>, <hi
                     rend="italic">22</hi>(5), 469–485.</bibl>
               <bibl xml:id="Jones.1972">Jones, K. S. (1972). A statistical interpretation of term
                  specificity and its application in retrieval. <hi rend="italic">Journal of
                     Documentation</hi>.</bibl>
               <bibl xml:id="Kilroy.2021">Kilroy, D. (2021). All the king’s men? A demographic study
                  of opinion in the first English Parliament of James I, 1604–10. <hi rend="italic"
                     >Parliaments, Estates and Representation</hi>, <hi rend="italic">41</hi>(1),
                  1–23.</bibl>
               <bibl xml:id="Martin.2015">Martin, F., &amp; Johnson, M. (2015). <hi rend="italic"
                     >More efficient topic modelling through a noun only approach</hi>.
                  111–115.</bibl>
               <bibl xml:id="Meeks.2012">Meeks, E., &amp; Weingart, S. B. (2012). The digital
                  humanities contribution to topic modeling. <hi rend="italic">Journal of Digital
                     Humanities</hi>, <hi rend="italic">2</hi>(1), 1–6.</bibl>
               <bibl xml:id="Mollin.2007">Mollin, S. (2007). The Hansard hazard: Gauging the
                  accuracy of British parliamentary transcripts. <hi rend="italic">Corpora</hi>, <hi
                     rend="italic">2</hi>(2), 187–210.</bibl>
               <bibl xml:id="Morstatter.2018">Morstatter, F., Shao, Y., Galstyan, A., &amp;
                  Karunasekera, S. (2018). <hi rend="italic">From alt-right to alt-rechts: Twitter
                     analysis of the 2017 German federal election</hi>. 621–628.</bibl>
               <bibl xml:id="Müller-Hansen.2021">Müller-Hansen, F., Callaghan, M. W., Lee, Y. T.,
                  Leipprand, A., Flachsland, C., &amp; Minx, J. C. (2021). Who cares about coal?
                  Analyzing 70 years of German parliamentary debates on coal with dynamic topic
                  modeling. <hi rend="italic">Energy Research &amp; Social Science</hi>, <hi
                     rend="italic">72</hi>, 101869.</bibl>
               <bibl xml:id="Norton.2002">Norton, P. (2002). <hi rend="italic">Parliaments and
                     citizens in Western Europe</hi> (Vol. 3). Psychology Press.</bibl>
               <bibl xml:id="Pančur.2016">Pančur, A., &amp; Šorn, M. (2016). Digitalni pristop k
                  parlamentarni zgodovini: Uporaba gradiva Državnega zbora v digitalni humanistiki.
                     <hi rend="italic">Četrt stoletja Republike Slovenije - izzivi, dileme,
                     pričakovanja</hi>, 115–126.</bibl>
               <bibl xml:id="Petukhova.2015">Petukhova, V., Malchanau, A., &amp; Bunt, H. (2015).
                     <hi rend="italic">Modelling argumentation in parliamentary debates</hi> (M.
                  Baldoni &amp; et al., Eds.). Springer.</bibl>
               <bibl xml:id="Piersma.2014">Piersma, H., Tames, I., Buitinck, L., Van Doornik, J.,
                  &amp; Marx, M. (2014). War in parliament: What a digital approach can add to the
                  study of parliamentary history. <hi rend="italic">Digital Humanities
                     Quarterly</hi>, <hi rend="italic">8</hi>(1).</bibl>
               <bibl xml:id="Pritchard.2000">Pritchard, J. K., Stephens, M., &amp; Donnelly, P.
                  (2000). Inference of population structure using multilocus genotype data. <hi
                     rend="italic">Genetics</hi>, <hi rend="italic">155</hi>(2), 945–959.</bibl>
               <bibl xml:id="Proksch.2010">Proksch, S.-O., &amp; Slapin, J. B. (2010). Position
                  taking in European Parliament speeches. <hi rend="italic">British Journal of
                     Political Science</hi>, <hi rend="italic">40</hi>(3), 587–611.</bibl>
               <bibl xml:id="Rheault.2016">Rheault, L., Beelen, K., Cochrane, C., &amp; Hirst, G.
                  (2016). Measuring emotion in parliamentary debates with automated textual
                  analysis. <hi rend="italic">PloS One</hi>, <hi rend="italic">11</hi>(12),
                  e0168843.</bibl>
               <bibl xml:id="Rheault.2020">Rheault, L., &amp; Cochrane, C. (2020). Word embeddings
                  for the analysis of ideological placement in parliamentary corpora. <hi
                     rend="italic">Political Analysis</hi>, <hi rend="italic">28</hi>(1),
                  112–133.</bibl>
               <bibl xml:id="Rosa.2021">Rosa, A. B., Gudowsky, N., &amp; Repo, P. (2021).
                  Sensemaking and lens-shaping: Identifying citizen contributions to foresight
                  through comparative topic modelling. <hi rend="italic">Futures</hi>, <hi
                     rend="italic">129</hi>, 102733.</bibl>
               <bibl xml:id="Rudkowsky.">Rudkowsky, E., Haselmayer, M., Wastian, M., Jenny, M.,
                  Emrich, Š., &amp; Sedlmair, M. (n.d.). <hi rend="italic">Supervised Sentiment
                     Analysis of Parliamentary Speeches and News Reports</hi>.</bibl>
               <bibl xml:id="Schmidt.2012">Schmidt, B. M. (2012). Words alone: Dismantling topic
                  models in the humanities. <hi rend="italic">Journal of Digital Humanities</hi>,
                     <hi rend="italic">2</hi>(1), 49–65.</bibl>
               <bibl xml:id="Schuler.2020">Schuler, P. (2020). Position taking or position ducking?
                  A theory of public debate in single-party legislatures. <hi rend="italic"
                     >Comparative Political Studies</hi>, <hi rend="italic">53</hi>(9),
                  1493–1524.</bibl>
               <bibl xml:id="Serrano.2019">Serrano, J. C. M., Shahrezaye, M., Papakyriakopoulos, O.,
                  &amp; Hegelich, S. (2019). <hi rend="italic">The rise of Germany’s AfD: A social
                     media analysis</hi>. 214–223.</bibl>
               <bibl xml:id="Shadrova.2021">Shadrova, A. (2021). Topic models do not model topics:
                  Epistemological remarks and steps towards best practices. <hi rend="italic"
                     >Journal of Data Mining &amp; Digital Humanities</hi>, <hi rend="italic"
                     >2021</hi>.</bibl>
               <bibl xml:id="Sieberer.2011">Sieberer, U., Müller, W. C., &amp; Heller, M. I. (2011).
                  Reforming the rules of the parliamentary game: Measuring and explaining changes in
                  parliamentary rules in Austria, Germany, and Switzerland, 1945–2010. <hi
                     rend="italic">West European Politics</hi>, <hi rend="italic">34</hi>(5),
                  948–975.</bibl>
               <bibl xml:id="Sievert.2014">Sievert, C., &amp; Shirley, K. (2014). <hi rend="italic"
                     >LDAvis: A method for visualizing and interpreting topics</hi>. 63–70.</bibl>
               <bibl xml:id="Smith.2019">Smith, N., &amp; Graham, T. (2019). Mapping the
                  anti-vaccination movement on Facebook. <hi rend="italic">Information,
                     Communication &amp; Society</hi>, <hi rend="italic">22</hi>(9),
                  1310–1327.</bibl>
               <bibl xml:id="Truan.2021">Truan, N., &amp; Romary, L. (2021). Building, Encoding, and
                  Annotating a Corpus of Parliamentary Debates in XML-TEI: A Cross-Linguistic
                  Account. <hi rend="italic">Journal of the Text Encoding Initiative</hi>.</bibl>
               <bibl xml:id="Zwaan.2016">van der Zwaan, J. M., Marx, M., &amp; Kamps, J. (2016). <hi
                     rend="italic">Validating Cross-Perspective Topic Modeling for Extracting
                     Political Parties’ Positions from Parliamentary Proceedings.</hi> 28–36.</bibl>
               <bibl xml:id="Vayansky.2020">Vayansky, I., &amp; Kumar, S. A. (2020). A review of
                  topic modeling methods. <hi rend="italic">Information Systems</hi>, <hi
                     rend="italic">94</hi>, 101582.</bibl>
               <bibl xml:id="Wiedemann.2016">Wiedemann, G. (2016). <hi rend="italic">Text mining for
                     qualitative data analysis in the social sciences</hi> (Vol. 1).
                  Springer.</bibl>
               <bibl xml:id="Zhao.2015">Zhao, W., Chen, J. J., Perkins, R., Liu, Z., Ge, W., Ding,
                  Y., &amp; Zou, W. (2015). <hi rend="italic">A heuristic approach to determine an
                     appropriate number of topics in topic modeling</hi>. <hi rend="italic"
                  >16</hi>(13), 1–10.</bibl>
            </listBibl>
         </div>
         <div type="bibliogr" xml:id="bibl-sl" xml:lang="sl" corresp="#bibl">
            <head xml:id="sl-head-55">9. Reference</head>
            <listBibl xml:id="sl-listBibl-1">
               <bibl xml:id="Abercrombie.2020.sl">Abercrombie, G., &amp; Batista-Navarro, R. (2020).
                  Sentiment and position-taking analysis of parliamentary debates: A systematic
                  literature review. <hi rend="italic">Journal of Computational Social Science</hi>,
                     <hi rend="italic">3</hi>(1), 245–270.</bibl>
               <bibl xml:id="Albalawi.2020.sl">Albalawi, R., Yeap, T. H., &amp; Benyoucef, M.
                  (2020). Using topic modeling methods for short-text data: A comparative analysis.
                     <hi rend="italic">Frontiers in Artificial Intelligence</hi>, <hi rend="italic"
                     >3</hi>, 42.</bibl>
               <bibl xml:id="Allen.2020.sl">Allen, C., &amp; Murdock, J. (2020). LDA topic
                  modelling: Context for the history &amp; philosophy of science [Preprint].
                  http://philsci-archive.pitt.edu/17261/</bibl>
               <bibl xml:id="Arun.2010.sl">Arun, R., Suresh, V., Veni Madhavan, C., &amp; Murthy, N.
                  (2010). <hi rend="italic">On finding the natural number of topics with latent
                     dirichlet allocation: Some observations</hi>. 391–402.</bibl>
               <bibl xml:id="Bayley.2004.sl">Bayley, P. (2004). <hi rend="italic">Cross-cultural
                     perspectives on parliamentary discourse</hi> (Vol. 10). John Benjamins
                  Publishing.</bibl>
               <bibl xml:id="Bergmann.2018.sl">Bergmann, H., Geese, L., Koss, C., &amp; Schwemmer,
                  C. (2018). <hi rend="italic">Using legislative speech to unveil conflict between
                     coalition parties</hi> [Preprint]. SocArXiv.
                  https://doi.org/10.31235/osf.io/pgnwa</bibl>
               <bibl xml:id="Blätte.2020.sl">Blätte, A., Gehlhar, S., &amp; Leonhardt, C. (2020).
                     <hi rend="italic">The Europeanization of Parliamentary Debates on Migration in
                     Austria, France, Germany, and the Netherlands</hi>. 66–74.</bibl>
               <bibl xml:id="Blei.2003.sl">Blei, D. M., Ng, A. Y., &amp; Jordan, M. I. (2003).
                  Latent dirichlet allocation. <hi rend="italic">Journal of Machine Learning
                     Research</hi>, <hi rend="italic">3</hi>(Jan), 993–1022.</bibl>
               <bibl xml:id="Brezovšek.2012.sl">Brezovšek, M., Haček, M., Ferfila, B., &amp; Zajc,
                  D. (2012). <hi rend="italic">Politični sistem Republike Slovenije</hi>. Fakulteta
                  za družbene vede.</bibl>
               <bibl xml:id="Chizhik.2021.sl">Chizhik, A. V., &amp; Sergeyev, D. A. (2021). <hi
                     rend="italic">Exploring the Parliamentary Discourse of the Russian Federation
                     Using Topic Modeling Approach</hi>. 403–416.</bibl>
               <bibl xml:id="Curran.2018.sl">Curran, B., Higham, K., Ortiz, E., &amp; Vasques Filho,
                  D. (2018). Look who’s talking: Two-mode networks as representations of a topic
                  model of New Zealand parliamentary speeches. <hi rend="italic">PLOS ONE</hi>, <hi
                     rend="italic">13</hi>(6), e0199072.
                  https://doi.org/10.1371/journal.pone.0199072</bibl>
               <bibl xml:id="deCampos.2021.sl">de Campos, L. M., Fernandez-Luna, J. M., Huete, J.
                  F., &amp; Redondo-Expósito, L. (2021). LDA-based term profiles for expert finding
                  in a political setting. <hi rend="italic">Journal of Intelligent Information
                     Systems</hi>, <hi rend="italic">56</hi>(3), 529–559.</bibl>
               <bibl xml:id="Demšar.2013.sl">Demšar, J., Curk, T., Erjavec, A., Gorup, Č., Hočevar,
                  T., Milutinovič, M., Možina, M., Polajnar, M., Toplak, M., &amp; Starič, A.
                  (2013). Orange: Data mining toolbox in Python. <hi rend="italic">The Journal of
                     Machine Learning Research</hi>, <hi rend="italic">14</hi>(1), 2349–2353.</bibl>
               <bibl xml:id="DZ_RS.2020.sl">DZ RS (Državni zbor Republike Slovenija) (2020).
                  ZIUZEOP: Zakon o interventnih ukrepih za zajezitev epidemije COVID-19 in omilitev
                  njenih posledic za državljane in gospodarstvo (Uradni list RS, št. 49/20, 61/20,
                  67/20, 80/20 - ZIUOOPE, 101/20 - skl. US, 152/20 - ZZUOOP, 175/20 - ZIUOPDVE,
                  203/20 - ZIUPOPDVE, 15/21 - ZDUOP).
                  http://www.pisrs.si/Pis.web/pregledPredpisa?id=ZAKO8190 </bibl>
               <bibl xml:id="Erjavec.2021.sl">Erjavec, T., et al. (2021). <hi rend="italic"
                     >Multilingual comparable corpora of parliamentary debates ParlaMint 2.1</hi>,
                  Slovenian language resource repository CLARIN.SI, ISSN 2820-4042, <ref
                     target="http://hdl.handle.net/11356/1432"
                     >http://hdl.handle.net/11356/1432</ref>.</bibl>
               <bibl xml:id="Erjavec.2022.sl">Erjavec, T., Ogrodniczuk, M., Osenova, P., &amp; et
                  al. (2022). The ParlaMint corpora of parliamentary proceedings. <hi rend="italic"
                     >Lang Resources &amp; Evaluation</hi>.
                  https://doi.org/10.1007/s10579-021-09574-0</bibl>
               <bibl xml:id="Erjavec.2019.sl">Erjavec, T., &amp; Pančur, A. (2019). Parla-CLARIN:
                  TEI guidelines for corpora of parliamentary proceedings. <hi rend="italic">Book of
                     Abstracts of the TEI2019: What Is Text, Really</hi>.</bibl>
               <bibl xml:id="Fišer.2021.sl">Fišer, D., &amp; Pahor de Maiti, K. (2021). » Prvič, sem
                  političarka in ne politik, drugič pa…«. <hi rend="italic">Contributions to
                     Contemporary History</hi>, <hi rend="italic">61</hi>(1).
                  https://doi.org/10.51663/pnz.61.1.07</bibl>
               <bibl xml:id="Gkoumas.2018.sl">Gkoumas, D., Pontiki, M., Papanikolaou, K., &amp;
                  Papageorgiou, H. (2018). <hi rend="italic">Exploring the Political Agenda of the
                     Greek Parliament Plenary Sessions</hi> (D. Fišer, M. Eskevich, &amp; F. de
                  Jong, Eds.).</bibl>
               <bibl xml:id="Grimmer.2013.sl">Grimmer, J., &amp; Stewart, B. M. (2013). Text as
                  data: The promise and pitfalls of automatic content analysis methods for political
                  texts. <hi rend="italic">Political Analysis</hi>, <hi rend="italic">21</hi>(3),
                  267–297.</bibl>
               <bibl xml:id="Høyland.2019.sl">Høyland, B., &amp; Søyland, M. G. (2019). Electoral
                  reform and parliamentary debates. <hi rend="italic">Legislative Studies
                     Quarterly</hi>, <hi rend="italic">44</hi>(4), 593–615.</bibl>
               <bibl xml:id="Ilie.2010.sl">Ilie, C. (2010). <hi rend="italic">European parliaments
                     under scrutiny: Discourse strategies and interaction practices</hi> (Vol. 38).
                  John Benjamins Publishing.</bibl>
               <bibl xml:id="Jacobs.2019.sl">Jacobs, T., &amp; Tschötschel, R. (2019). Topic models
                  meet discourse analysis: A quantitative tool for a qualitative approach. <hi
                     rend="italic">International Journal of Social Research Methodology</hi>, <hi
                     rend="italic">22</hi>(5), 469–485.</bibl>
               <bibl xml:id="Jones.1972.sl">Jones, K. S. (1972). A statistical interpretation of
                  term specificity and its application in retrieval. <hi rend="italic">Journal of
                     Documentation</hi>.</bibl>
               <bibl xml:id="Kilroy.2021.sl">Kilroy, D. (2021). All the king’s men? A demographic
                  study of opinion in the first English Parliament of James I, 1604–10. <hi
                     rend="italic">Parliaments, Estates and Representation</hi>, <hi rend="italic"
                     >41</hi>(1), 1–23.</bibl>
               <bibl xml:id="Martin.2015.sl">Martin, F., &amp; Johnson, M. (2015). <hi rend="italic"
                     >More efficient topic modelling through a noun only approach</hi>.
                  111–115.</bibl>
               <bibl xml:id="Meeks.2012.sl">Meeks, E., &amp; Weingart, S. B. (2012). The digital
                  humanities contribution to topic modeling. <hi rend="italic">Journal of Digital
                     Humanities</hi>, <hi rend="italic">2</hi>(1), 1–6.</bibl>
               <bibl xml:id="Mollin.2007.sl">Mollin, S. (2007). The Hansard hazard: Gauging the
                  accuracy of British parliamentary transcripts. <hi rend="italic">Corpora</hi>, <hi
                     rend="italic">2</hi>(2), 187–210.</bibl>
               <bibl xml:id="Morstatter.2018.sl">Morstatter, F., Shao, Y., Galstyan, A., &amp;
                  Karunasekera, S. (2018). <hi rend="italic">From alt-right to alt-rechts: Twitter
                     analysis of the 2017 German federal election</hi>. 621–628.</bibl>
               <bibl xml:id="Müller-Hansen.2021.sl">Müller-Hansen, F., Callaghan, M. W., Lee, Y. T.,
                  Leipprand, A., Flachsland, C., &amp; Minx, J. C. (2021). Who cares about coal?
                  Analyzing 70 years of German parliamentary debates on coal with dynamic topic
                  modeling. <hi rend="italic">Energy Research &amp; Social Science</hi>, <hi
                     rend="italic">72</hi>, 101869.</bibl>
               <bibl xml:id="Norton.2002.sl">Norton, P. (2002). <hi rend="italic">Parliaments and
                     citizens in Western Europe</hi> (Vol. 3). Psychology Press.</bibl>
               <bibl xml:id="Pančur.2016.sl">Pančur, A., &amp; Šorn, M. (2016). Digitalni pristop k
                  parlamentarni zgodovini: Uporaba gradiva Državnega zbora v digitalni humanistiki.
                     <hi rend="italic">Četrt stoletja Republike Slovenije - izzivi, dileme,
                     pričakovanja</hi>, 115–126.</bibl>
               <bibl xml:id="Petukhova.2015.sl">Petukhova, V., Malchanau, A., &amp; Bunt, H. (2015).
                     <hi rend="italic">Modelling argumentation in parliamentary debates</hi> (M.
                  Baldoni &amp; et al., Eds.). Springer.</bibl>
               <bibl xml:id="Piersma.2014.sl">Piersma, H., Tames, I., Buitinck, L., Van Doornik, J.,
                  &amp; Marx, M. (2014). War in parliament: What a digital approach can add to the
                  study of parliamentary history. <hi rend="italic">Digital Humanities
                     Quarterly</hi>, <hi rend="italic">8</hi>(1).</bibl>
               <bibl xml:id="Pritchard.2000.sl">Pritchard, J. K., Stephens, M., &amp; Donnelly, P.
                  (2000). Inference of population structure using multilocus genotype data. <hi
                     rend="italic">Genetics</hi>, <hi rend="italic">155</hi>(2), 945–959.</bibl>
               <bibl xml:id="Proksch.2010.sl">Proksch, S.-O., &amp; Slapin, J. B. (2010). Position
                  taking in European Parliament speeches. <hi rend="italic">British Journal of
                     Political Science</hi>, <hi rend="italic">40</hi>(3), 587–611.</bibl>
               <bibl xml:id="RS_RS.2021.sl">RS RS (Računsko sodišče Republike Slovenije) (2021).
                  Revizijsko poročilo: Učinkovitost nabav zaščitne in medicinske opreme za
                  obvladovanje širjenja virusa SARS-CoV-2, 17. 3. 2021.
                  https://www.rs-rs.si/fileadmin/user_upload/Datoteke/Revizije/2021/ZascitnaOprema/ZascitnaOprema2020_RSP_RevizijskoP.pdf.</bibl>
               <bibl xml:id="Rheault.2016.sl">Rheault, L., Beelen, K., Cochrane, C., &amp; Hirst, G.
                  (2016). Measuring emotion in parliamentary debates with automated textual
                  analysis. <hi rend="italic">PloS One</hi>, <hi rend="italic">11</hi>(12),
                  e0168843.</bibl>
               <bibl xml:id="Rheault.2020.sl">Rheault, L., &amp; Cochrane, C. (2020). Word
                  embeddings for the analysis of ideological placement in parliamentary corpora. <hi
                     rend="italic">Political Analysis</hi>, <hi rend="italic">28</hi>(1),
                  112–133.</bibl>
               <bibl xml:id="Rosa.2021.sl">Rosa, A. B., Gudowsky, N., &amp; Repo, P. (2021).
                  Sensemaking and lens-shaping: Identifying citizen contributions to foresight
                  through comparative topic modelling. <hi rend="italic">Futures</hi>, <hi
                     rend="italic">129</hi>, 102733.</bibl>
               <bibl xml:id="Rudkowsky..sl">Rudkowsky, E., Haselmayer, M., Wastian, M., Jenny, M.,
                  Emrich, Š., &amp; Sedlmair, M. (n.d.). <hi rend="italic">Supervised Sentiment
                     Analysis of Parliamentary Speeches and News Reports</hi>.</bibl>
               <bibl xml:id="Schmidt.2012.sl">Schmidt, B. M. (2012). Words alone: Dismantling topic
                  models in the humanities. <hi rend="italic">Journal of Digital Humanities</hi>,
                     <hi rend="italic">2</hi>(1), 49–65.</bibl>
               <bibl xml:id="Schuler.2020.sl">Schuler, P. (2020). Position taking or position
                  ducking? A theory of public debate in single-party legislatures. <hi rend="italic"
                     >Comparative Political Studies</hi>, <hi rend="italic">53</hi>(9),
                  1493–1524.</bibl>
               <bibl xml:id="Serrano.2019.sl">Serrano, J. C. M., Shahrezaye, M., Papakyriakopoulos,
                  O., &amp; Hegelich, S. (2019). <hi rend="italic">The rise of Germany’s AfD: A
                     social media analysis</hi>. 214–223.</bibl>
               <bibl xml:id="Shadrova.2021.sl">Shadrova, A. (2021). Topic models do not model
                  topics: Epistemological remarks and steps towards best practices. <hi
                     rend="italic">Journal of Data Mining &amp; Digital Humanities</hi>, <hi
                     rend="italic">2021</hi>.</bibl>
               <bibl xml:id="Sieberer.2011.sl">Sieberer, U., Müller, W. C., &amp; Heller, M. I.
                  (2011). Reforming the rules of the parliamentary game: Measuring and explaining
                  changes in parliamentary rules in Austria, Germany, and Switzerland, 1945–2010.
                     <hi rend="italic">West European Politics</hi>, <hi rend="italic">34</hi>(5),
                  948–975.</bibl>
               <bibl xml:id="Sievert.2014.sl">Sievert, C., &amp; Shirley, K. (2014). <hi
                     rend="italic">LDAvis: A method for visualizing and interpreting topics</hi>.
                  63–70.</bibl>
               <bibl xml:id="Smith.2019.sl">Smith, N., &amp; Graham, T. (2019). Mapping the
                  anti-vaccination movement on Facebook. <hi rend="italic">Information,
                     Communication &amp; Society</hi>, <hi rend="italic">22</hi>(9),
                  1310–1327.</bibl>
               <bibl xml:id="Truan.2021.sl">Truan, N., &amp; Romary, L. (2021). Building, Encoding,
                  and Annotating a Corpus of Parliamentary Debates in XML-TEI: A Cross-Linguistic
                  Account. <hi rend="italic">Journal of the Text Encoding Initiative</hi>.</bibl>
               <bibl xml:id="Zwaan.2016.sl">van der Zwaan, J. M., Marx, M., &amp; Kamps, J. (2016).
                     <hi rend="italic">Validating Cross-Perspective Topic Modeling for Extracting
                     Political Parties’ Positions from Parliamentary Proceedings.</hi> 28–36.</bibl>
               <bibl xml:id="Vayansky.2020.sl">Vayansky, I., &amp; Kumar, S. A. (2020). A review of
                  topic modeling methods. <hi rend="italic">Information Systems</hi>, <hi
                     rend="italic">94</hi>, 101582.</bibl>
               <bibl xml:id="VladaRS.2020.sl">Vlada Republike Slovenije (2020). Obrazložitev
                  splošnega dela predloga rebalansa proračuna Republike Slovenije za leto 2020.
                  https://www.gov.si/assets/ministrstva/MF/Proracun-direktorat/Drzavni-proracun/Sprejeti-proracun/Rebalans-2020/Obr-splosni-del-in-politike/REB20_obrsplosnidel.pdf.</bibl>
               <bibl xml:id="Wiedemann.2016.sl">Wiedemann, G. (2016). <hi rend="italic">Text mining
                     for qualitative data analysis in the social sciences</hi> (Vol. 1).
                  Springer.</bibl>
               <bibl xml:id="Zhao.2015.sl">Zhao, W., Chen, J. J., Perkins, R., Liu, Z., Ge, W.,
                  Ding, Y., &amp; Zou, W. (2015). <hi rend="italic">A heuristic approach to
                     determine an appropriate number of topics in topic modeling</hi>. <hi
                     rend="italic">16</hi>(13), 1–10.</bibl>
            </listBibl>
         </div>
         <div type="summary" xml:id="summary" xml:lang="en" corresp="#summary-sl">
            <head xml:id="head-67">Abstract</head>
            <p xml:id="p-138">In democratic countries, a parliament is a central representative and
               legislative institution. Digital transcripts of parliamentary sessions are a unique
               research source as they reflect the political, societal, and cultural atmosphere of a
               certain period. The transcripts are typically available in the form of parliamentary
               corpora.</p>
            <p xml:id="p-139">In this tutorial, we will analyse the transcripts of parliamentary
               debates ParlaMint, for which we will employ advanced automatic analytical techniques,
               specifically topic modelling. The aim of the tutorial is to introduce researchers in
               the humanities and social sciences to text mining, showing the value of such
               approaches for research in these scientific fields. The tutorial breaks down the
               particularities of parliamentary discourse and topic modelling by answering concrete
               research questions.</p>
         </div>
         <div type="summary" xml:id="summary-sl" xml:lang="sl" corresp="#summary">
            <head xml:id="sl-head-56">Povzetek</head>
            <p xml:id="sl-p-124">V demokratičnih državah parlament deluje kot osrednje predstavniško
               in zakonodajno telo. Digitalni zapisi parlamentarnih razprav omogočajo raziskovanje
               političnega, družbenega in kulturnega vzdušje določenega časa. Ti zapisi so
               raziskovalcem tipično na voljo v obliki korpusov.</p>
            <p xml:id="sl-p-125">V tem učnem gradivu bomo analizirali zapise parlamentarnih debat
               ParlaMint, pri čemer bomo uporabili napredne avtomatske analitične tehnike oz.
               točneje tematsko modeliranje. Namen učnega gradiva je raziskovalke in raziskovalce s
               področja humanistike in družboslovja vpeljati v svet rudarjenja besedil ter prikazati
               vrednost tovrstnih pristopov za družboslovne in humanistične raziskave. Učno gradivo
               razlaga posebnosti parlamentarnega diskurza in uporabo tematskega modeliranja za
               reševanje konkretnih raziskovalnih vprašanj.</p>
         </div>
      </back>
   </text>
</TEI>
