<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (2)--><title>6. Analysis of parliamentary speeches</title><meta http-equiv="x-ua-compatible" content="ie=edge" /><meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="description" content="" /><meta name="keywords" content="" /><meta name="author" content="Ajda Pretnar Žagar , Kristina Pahor de Maiti and Darja Fišer" /><meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets" /><meta charset="utf-8" /><link href="https://www2.sistory.si/publikacije/themes/foundation/6/css/foundation.min.css" rel="stylesheet" type="text/css" /><link href="https://www2.sistory.si/publikacije/themes/css/foundation/6/sistory.css" rel="stylesheet" type="text/css" /><link href="https://cdnjs.cloudflare.com/ajax/libs/foundicons/3.0.0/foundation-icons.min.css" rel="stylesheet" type="text/css" /><link href="https://www2.sistory.si/publikacije/themes/plugin/TipueSearch/6.1/tipuesearch/css/normalize.css" rel="stylesheet" type="text/css" /><link href="https://www2.sistory.si/publikacije/themes/css/plugin/TipueSearch/6.1/my-tipuesearch.css" rel="stylesheet" type="text/css" /><link href="https://www2.sistory.si/publikacije/themes/plugin/ImageViewer/1.1.3/imageviewer.css" rel="stylesheet" type="text/css" /><style>
         .selflink:hover { opacity: 0.5;}
         .keywordlink:hover { opacity: 0.5;}
         .numberParagraphLink {text-decoration: none;}
         .numberParagraph:hover {color: black;}
      </style><script src="https://www2.sistory.si/publikacije/themes/foundation/6/js/vendor/jquery.js"></script><script src="https://www2.sistory.si/publikacije/themes/plugin/ImageViewer/1.1.3/imageviewer.js"></script></head><body id="TOP" itemscope="itemscope" itemtype="http://www.tei-c.org/ns/1.0/" itemprop="TEI"><script src="tipuesearch_content.js"></script><script src="https://www2.sistory.si/publikacije/themes/plugin/TipueSearch/6.1/tipuesearch/tipuesearch_set.js"></script><script src="https://www2.sistory.si/publikacije/themes/plugin/TipueSearch/6.1/tipuesearch/tipuesearch.min.js"></script><div class="column row"><header xmlns:html="http://www.w3.org/1999/xhtml"><div class="hide-for-large"><div id="header-bar"><div class="title-bar" data-responsive-toggle="publication-menu" data-hide-for="large"><button class="menu-icon" type="button" data-toggle=""></button><div class="title-bar-title">Menu</div><div class="title-bar-right"><a class="title-bar-title" href="https://sidih.si/20.500.12325/120"><i class="fi-home" style="color:white;"></i></a></div><div id="publication-menu" class="hide-for-large"><ul class="vertical menu" data-drilldown="" data-options="backButton: &lt;li class=&#34;js-drilldown-back&#34;&gt;&lt;a tabindex=&#34;0&#34;&gt;Back&lt;/a&gt;&lt;/li&gt;;"><li><a href="index.html">Cover Page</a></li><li><a href="cip.html">Colophon</a></li><li><a href="toc.html">TOC</a></li><li class="active"><a href="preface1.html">Chapters</a><ul class="vertical menu"><li><a href="preface1.html">1. Introduction</a></li><li><a href="preface2.html">2. Tutorial overview and instructions</a></li><li><a href="ch3.html">3. Parliamentary debates</a><ul class="vertical menu"><li><a href="ch3.html#ch3.1">3.1. Characteristics of parliamentary debates</a></li><li><a href="ch3.html#ch3.2">3.2. Parliamentary corpora</a></li><li><a href="ch3.html#ch3.3">3.3. The ParlaMint corpus</a></li></ul></li><li><a href="ch4.html">4. Topic modelling</a><ul class="vertical menu"><li><a href="ch4.html#ch4.1">4.1. The LDA method</a></li><li><a href="ch4.html#ch4.2">4.2. Characteristics of the LDA method</a></li><li><a href="ch4.html#ch4.3">4.3. Data preprocessing</a></li><li><a href="ch4.html#ch4.4">4.4. Limitations of LDA</a></li><li><a href="ch4.html#ch4.5">4.5. Topic modelling of parliamentary debates</a></li></ul></li><li><a href="ch5.html">5. Preparing for the analysis</a><ul class="vertical menu"><li><a href="ch5.html#ch5.1">5.1. Orange: setup and use</a></li><li><a href="ch5.html#ch5.2">5.2. Loading data into Orange</a></li><li><a href="ch5.html#ch5.3">5.3. Data overview</a></li><li><a href="ch5.html#ch5.4">5.4. Preparing and preprocessing the subcorpus</a><ul class="vertical menu"><li><a href="ch5.html#ch5.4.1">5.4.1. Removing unwanted speeches</a></li><li><a href="ch5.html#ch5.4.2">5.4.2. Removing unwanted words</a></li></ul></li></ul></li><li class="active"><a href="ch6.html">6. Analysis of parliamentary speeches</a><ul class="vertical menu"><li><a href="ch6.html#ch6.1">6.1. Topics of parliamentary speeches</a><ul class="vertical menu"><li><a href="ch6.html#ch6.1.1">6.1.1. Computing document vectors</a></li><li><a href="ch6.html#ch6.1.2">6.1.2. Topic modelling</a></li><li><a href="ch6.html#ch6.1.3">6.1.3. Topic definition</a></li><li><a href="ch6.html#ch6.1.4">6.1.4. Distribution of topics in a corpus</a></li></ul></li><li><a href="ch6.html#ch6.2">6.2. Topic map</a></li><li><a href="ch6.html#ch6.3">6.3. Topics before and during the pandemic</a></li></ul></li><li><a href="ch7.html">7. Conclusion</a></li></ul></li><li><a href="bibl.html">Bibliography</a></li><li><a href="acknw.html">Appendix</a></li><li><a href="summary.html">Summary</a></li><li><a href="#">English</a><ul class="menu"><li><a href="ch6-sl.html">Slovenščina</a></li></ul></li></ul></div></div></div></div><div class="show-for-large"><nav class="title-bar"><div class="title-bar-left"><a class="title-bar-title" href="https://sidih.si/20.500.12325/120"><i class="fi-home" style="color:white;"></i> <span>SI-DIH</span></a></div><div class="title-bar-right"><ul class="dropdown menu" data-dropdown-menu=""><li><a href="index.html">Cover Page</a></li><li><a href="cip.html">Colophon</a></li><li><a href="toc.html">TOC</a></li><li class="active"><a href="preface1.html">Chapters</a><ul class="menu"><li><a href="preface1.html">1. Introduction</a></li><li><a href="preface2.html">2. Tutorial overview and instructions</a></li><li><a href="ch3.html">3. Parliamentary debates</a><ul class="menu"><li><a href="ch3.html#ch3.1">3.1. Characteristics of parliamentary debates</a></li><li><a href="ch3.html#ch3.2">3.2. Parliamentary corpora</a></li><li><a href="ch3.html#ch3.3">3.3. The ParlaMint corpus</a></li></ul></li><li><a href="ch4.html">4. Topic modelling</a><ul class="menu"><li><a href="ch4.html#ch4.1">4.1. The LDA method</a></li><li><a href="ch4.html#ch4.2">4.2. Characteristics of the LDA method</a></li><li><a href="ch4.html#ch4.3">4.3. Data preprocessing</a></li><li><a href="ch4.html#ch4.4">4.4. Limitations of LDA</a></li><li><a href="ch4.html#ch4.5">4.5. Topic modelling of parliamentary debates</a></li></ul></li><li><a href="ch5.html">5. Preparing for the analysis</a><ul class="menu"><li><a href="ch5.html#ch5.1">5.1. Orange: setup and use</a></li><li><a href="ch5.html#ch5.2">5.2. Loading data into Orange</a></li><li><a href="ch5.html#ch5.3">5.3. Data overview</a></li><li><a href="ch5.html#ch5.4">5.4. Preparing and preprocessing the subcorpus</a><ul class="menu"><li><a href="ch5.html#ch5.4.1">5.4.1. Removing unwanted speeches</a></li><li><a href="ch5.html#ch5.4.2">5.4.2. Removing unwanted words</a></li></ul></li></ul></li><li class="active"><a href="ch6.html">6. Analysis of parliamentary speeches</a><ul class="menu"><li><a href="ch6.html#ch6.1">6.1. Topics of parliamentary speeches</a><ul class="menu"><li><a href="ch6.html#ch6.1.1">6.1.1. Computing document vectors</a></li><li><a href="ch6.html#ch6.1.2">6.1.2. Topic modelling</a></li><li><a href="ch6.html#ch6.1.3">6.1.3. Topic definition</a></li><li><a href="ch6.html#ch6.1.4">6.1.4. Distribution of topics in a corpus</a></li></ul></li><li><a href="ch6.html#ch6.2">6.2. Topic map</a></li><li><a href="ch6.html#ch6.3">6.3. Topics before and during the pandemic</a></li></ul></li><li><a href="ch7.html">7. Conclusion</a></li></ul></li><li><a href="bibl.html">Bibliography</a></li><li><a href="acknw.html">Appendix</a></li><li><a href="summary.html">Summary</a></li><li><a href="#">English</a><ul class="menu"><li><a href="ch6-sl.html">Slovenščina</a></li></ul></li></ul></div></nav></div><form action="search.html"><div class="row collapse"><div class="small-10 large-11 columns"><input type="text" name="q" id="tipue_search_input" placeholder="Your search text" /></div><div class="small-2 large-1 columns"><img type="button" class="tipue_search_button" /></div></div></form></header><section><div class="row"><div class="medium-2 columns show-for-medium"><p><a class="button" href="ch5.html" title="Previous: 5. Preparing for the analysis">&lt;&lt;</a></p></div><div class="medium-8 small-12 columns"><h2 lang="en" class="maintitle"><span class="head" itemprop="head" id="head-40">6. Analysis of parliamentary speeches</span></h2></div><div class="medium-2 columns show-for-medium text-right"><p><a class="button" href="ch7.html" title="Next: 7. Conclusion">&gt;&gt;</a></p></div></div><div class="row hide-for-medium"><div class="small-6 columns text-center"><p><a class="button" href="ch5.html" title="Previous: 5. Preparing for the analysis">&lt;&lt;</a></p></div><div class="small-6 columns text-center"><p><a class="button" href="ch7.html" title="Next: 7. Conclusion">&gt;&gt;</a></p></div></div><div lang="en" class="chapter" id="ch6"><p id="p-82"><span><a class="numberParagraphLink" href="#p-82" title="number paragraph link"><span class="numberParagraph">1</span></a></span>This chapter is divided into three practical tasks in which we use topic modelling and visualizations to explore the content of parliamentary debates before and during the COVID pandemic. We will answer the following questions:</p><ul itemprop="list" id="list-11"><li class="item" itemprop="item" id="d46e3533">Task 1: Which topics are characteristic of the corpus?</li><li class="item" itemprop="item" id="d46e3534">Task 2: Which topics did MPs debate on the most?</li><li class="item" itemprop="item" id="d46e3535">Task 3: Which topics were more frequent before and during the pandemic?</li></ul><div class="subchapter" id="ch6.1"><h3><span class="head" itemprop="head" id="head-41">6.1. Topics of parliamentary speeches</span></h3><p id="p-83"><span><a class="numberParagraphLink" href="#p-83" title="number paragraph link"><span class="numberParagraph">1</span></a></span>In this chapter, we will first prepare a numeric description of the corpus, which is necessary for the LDA methods. Next, we will extract the topics and name them. In the end, we will observe how these topics are distributed in the corpus and how we can find the speech on a given topic.</p><div class="subchapter" id="ch6.1.1"><h4><span class="head" itemprop="head" id="head-42">6.1.1. Computing document vectors</span></h4><p id="p-84"><span><a class="numberParagraphLink" href="#p-84" title="number paragraph link"><span class="numberParagraph">1</span></a></span>Before we can begin topic modelling, we need preprocessed data and a vector representation of speeches. We have already preprocessed the corpus (see <a class="link_ref" itemprop="ref" href="ch5.html#ch5.4" title="5.4. Preparing and preprocessing the subcorpus">Chapter 5.4</a>). To compute the vector representation of the speeches, we will use the <span style="font-weight:bold" itemprop="hi">Bag of Words</span> widget, which constructs a numeric description of the speeches. Using this description, one can compute word distributions for topics or, in other words, perform topic modelling. The numeric description, which we retrieve with bag of words, contains words in columns, with their values representing the number of times a word appears in a given speech. Each speech is thus characterised with a vector, which represents the content of the speech. The more frequent the word, the more prominent the vector of the speech is in the direction of the word.</p><p id="p-85"><span><a class="numberParagraphLink" href="#p-85" title="number paragraph link"><span class="numberParagraph">2</span></a></span>However, not all words are equal. Some words in the corpus are procedural or genre-specific (see <a class="link_ref" itemprop="ref" href="ch5.html#ch5.4" title="5.4. Preparing and preprocessing the subcorpus">Chapter 5.4</a>), stopwords (i.e., pronouns, articles) or not specific for a given speech. The word <span style="font-style:italic" itemprop="hi">thank</span>, for example, appears in thematically heterogeneous speeches, as many MPs thank the speaker before them. Hence the word is not thematically informative. We would like to weigh the words so that the words specific to a given speech have a higher weight than those that frequently appear across the entire corpus. This type of weighting is called TF-IDF or<span style="font-style:italic" itemprop="hi">term frequency-inverse document frequency</span> (<a class="link_ref" itemprop="ref" href="bibl.html#Jones.1972" title="Jones K. S. (1972). A statistical interpretation of term specificity and its application in retrieval. Journal of Documentation...">Jones, 1972</a>) and can be selected in the <span style="font-weight:bold" itemprop="hi">Bag of Words</span> widget.</p><p id="p-86"><span><a class="numberParagraphLink" href="#p-86" title="number paragraph link"><span class="numberParagraph">3</span></a></span>We add <span style="font-weight:bold" itemprop="hi">Bag of Words</span> directly to <span style="font-weight:bold" itemprop="hi">Preprocess Text</span> and set the parameters to keep the <span style="font-style:italic" itemprop="hi">Count</span> under <span style="font-style:italic" itemprop="hi">Term Frequency</span> and select <span style="font-style:italic" itemprop="hi">IDF</span> under <span style="font-style:italic" itemprop="hi">Document Frequency</span> (<a class="link_ref" itemprop="ref" href="ch6.html#figure.11" title="Figure 11 Setting the bagofwords parameters.">Figure 11</a>).</p><figure id="figure.11"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure11_bag-of-words.png/full/max/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure11_bag-of-words.png" alt="Figure 11: Setting the bag-of-words parameters." /><figcaption><figcaption class="caption" itemprop="head"><b></b>Figure 11: Setting the bag-of-words parameters.</figcaption></figcaption></figure><br /><br /></div><div class="subchapter" id="ch6.1.2"><h4><span class="head" itemprop="head" id="head-44">6.1.2. Topic modelling</span></h4><p id="p-87"><span><a class="numberParagraphLink" href="#p-87" title="number paragraph link"><span class="numberParagraph">1</span></a></span>Now that we have the vector representation of speeches, we can begin with topic modelling. If the <span style="font-weight:bold" itemprop="hi">Bag of Words </span>process completed successfully, continue with <span style="font-style:italic" itemprop="hi">Option 1.</span> However, if the computing is taking too long, follow the instructions under <span style="font-style:italic" itemprop="hi">Option 2.</span></p><div class="rules" itemprop="table" id="table-13"><table style="border-collapse:collapse;border-spacing:0;"><tr itemprop="row"><td class="left">Option 1: follow the tutorial</td><td class="left">Option 2: speed up the analysis</td></tr><tr itemprop="row"><td class="left"><figure id=""><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure0.7.png/full/max/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure0.7.png" alt="" /><figcaption></figcaption></figure><br /><br /></td><td class="left"><figure id=""><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure0.8.png/full/max/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure0.8.png" alt="" /><figcaption></figcaption></figure><br /><br /></td></tr><tr itemprop="row"><td class="left">Add <span style="font-weight:bold" itemprop="hi">Topic Modelling </span>to the canvas and connect it to <span style="font-weight:bold" itemprop="hi">Bag of Words.</span> From here, continue as described below.</td><td class="left"><p id="index-p-d46e3638"><span class="numberParagraph">1</span>If the computation is taking too long, first open a new session in Orange. Then download <a class="link_ref" itemprop="ref" href="https://www2.sistory.si/publikacije/material/parlamint/ParlaMint-GB-bow.pkl">ParlaMint-GB-bow.pkl</a> and load the data into Orange with the <span style="font-weight:bold" itemprop="hi">Corpus </span>widget. The file contains a pre-constructed bag-of-words matrix.</p> <p id="index-p-d46e3647"><span class="numberParagraph">2</span>Now add the <span style="font-weight:bold" itemprop="hi">Topic Modelling</span> widget and connect it directly to the <span style="font-weight:bold" itemprop="hi">Corpus. </span>Continue as described below.</p></td></tr></table></div><p id="p-90"><span><a class="numberParagraphLink" href="#p-90" title="number paragraph link"><span class="numberParagraph">2</span></a></span>Open the <span style="font-weight:bold" itemprop="hi">Topic Modelling</span> widget and select the LDA method. Let us set the <span style="font-style:italic" itemprop="hi">Number of topics</span> to 20. The number of topics is up to the researcher, but related work shows that with larger corpora, 20 is a good choice (see <a class="link_ref" itemprop="ref" href="ch4.html" title="4. Topic modelling">Chapter 4</a>). On the right, we see twenty groups of words that characterize the topics in the corpus (<a class="link_ref" itemprop="ref" href="ch6.html#figure.12" title="Figure 12 LDA results for twenty topics.">Figure 12</a>). Some topics are easy to name, while others appear a little tricky. In the following chapter, we will further explore the topics which will help us to define the topics better.</p><figure id="figure.12"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure12_topic-modelling.png/full/,600/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure12_topic-modelling.png" alt="Figure 12: LDA results for twenty topics." /><figcaption><figcaption class="caption" itemprop="head"><b></b>Figure 12: LDA results for twenty topics.</figcaption></figcaption></figure><br /><br /><p id="p-91"><span><a class="numberParagraphLink" href="#p-91" title="number paragraph link"><span class="numberParagraph">3</span></a></span>It is important to note that LDA is a stochastic method, which means that it returns different results at each run as it is based on a random initial topic assignment. In Orange, we bypass this characteristic by setting a fixed starting point, which enables the reproducibility of the results.</p><div id="note-16" class="callout warning"><p id="index-p-d46e3677"><span class="numberParagraph">1</span>Try it yourself: use a different number of topics, say 5 or 10. Does a smaller number of topics give better results? What about setting a large number of topics, say 50?</p></div></div><div class="subchapter" id="ch6.1.3"><h4><span class="head" itemprop="head" id="head-46">6.1.3. Topic definition</span></h4><p id="p-93"><span><a class="numberParagraphLink" href="#p-93" title="number paragraph link"><span class="numberParagraph">1</span></a></span>LDA returns the ten words most related to each topic.<span id="ftn15_return"><a class="notelink" title="It is possible to get a different result with LDA than seen in the tutorial. LDA is a generative model, which initiates randomly. You should always be…" href="#ftn15"><sup>15</sup></a></span> However, these words are sometimes not informative enough to enable defining a topic. Hence, we use <span style="font-weight:bold" itemprop="hi">LDAvis</span> (<a class="link_ref" itemprop="ref" href="bibl.html#Sievert.2014" title="Sievert C.  Shirley K. (2014). LDAvis A method for visualizing and interpreting topics. 6370.">Sievert and Shirley, 2014</a>) to help us define the themes. The main advantage of this visualisation is that it scores words based on how <span style="font-style:italic" itemprop="hi">specific a word is in the topic</span> vs <span style="font-style:italic" itemprop="hi">in the corpus</span>. The value of the lambda parameter, which can be set in the widget with the <span style="font-style:italic" itemprop="hi">Relevance</span> slider, can be between 0 and 1, where 1 displays words based on how specific they are to the topic (as shown in the <span style="font-weight:bold" itemprop="hi">Topic Modelling</span> widget) and 0 displays words based on how frequent they are in the corpus. The exclusivity of the word in the corpus is called <span style="font-style:italic" itemprop="hi">lift</span>, which represents the ratio between the frequency of the word in the topic and the frequency of the word in the corpus.</p><p id="p-94"><span><a class="numberParagraphLink" href="#p-94" title="number paragraph link"><span class="numberParagraph">2</span></a></span>Connect <span style="font-weight:bold" itemprop="hi">LDAvis</span> to <span style="font-weight:bold" itemprop="hi">Topic Modelling</span> and ensure that the right data are sent to the input. The LDAvis widget needs a table of word frequency per topic, which is present in the <span style="font-style:italic" itemprop="hi">All Topics</span> output. The output can be edited by clicking on the connection between the widgets and connecting the <span style="font-style:italic" itemprop="hi">All Topics</span> signal to <span style="font-style:italic" itemprop="hi">Topics</span> (<a class="link_ref" itemprop="ref" href="ch6.html#figure.13" title="Figure 13 Setting correct input data for the LDAvis widget.">Figure 13</a>).</p><figure id="figure.13"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure13_edit-links.png/full/max/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure13_edit-links.png" alt="Figure 13: Setting correct input data for the LDAvis widget." /><figcaption><figcaption class="caption" itemprop="head"><b></b>Figure 13: Setting correct input data for the LDAvis widget.</figcaption></figcaption></figure><br /><br /><p id="p-95"><span><a class="numberParagraphLink" href="#p-95" title="number paragraph link"><span class="numberParagraph">3</span></a></span>By default, <span style="font-weight:bold" itemprop="hi">LDAvis</span> shows words in balanced order with the same proportion of exclusivity of the word in the topic and the exclusivity of the word in the corpus, which usually gives good results.</p><p id="p-96"><span><a class="numberParagraphLink" href="#p-96" title="number paragraph link"><span class="numberParagraph">4</span></a></span>The balanced relevance setting gives a different, more informative set of words than seen in the <span style="font-weight:bold" itemprop="hi">Topic Modelling</span> widget (<a class="link_ref" itemprop="ref" href="ch6.html#figure.14" title="Figure 14 Visualisation of word frequency in the topic (red) to word frequency in the corpus (grey) for Topic 2.">Figure 14</a>). It is evident that Topic 2 talks about furlough and essential workers, Topic 4 about Brexit, and Topic 9 about different tiers of responses to the pandemic.</p><figure id="figure.14"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure14_ldavis.png/full/,600/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure14_ldavis.png" alt="Figure 14: Visualisation of word frequency in the topic (red) to word frequency in the corpus (grey) for Topic 2." /><figcaption><figcaption class="caption" itemprop="head"><b></b>Figure 14: Visualisation of word frequency in the topic (red) to word frequency in the corpus (grey) for Topic 2.</figcaption></figcaption></figure><br /><br /><div id="note-18" class="callout warning"><p id="index-p-d46e3751"><span class="numberParagraph">1</span>Try it yourself: move the slider left and right. Which setting gives the best set of words to define the topic?</p></div><figure id="figure-22"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure0.9.png/full/max/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure0.9.png" alt="" /><figcaption></figcaption></figure><br /><br /><p id="p-98"><span><a class="numberParagraphLink" href="#p-98" title="number paragraph link"><span class="numberParagraph">5</span></a></span>In this way, we can inspect all the topics. For an easier interpretation of the results, we can replace the generic topic names (i.e., Topic 1) with meaningful labels (i.e., T1: UK &amp; nation). To do this, we connect <span style="font-weight:bold" itemprop="hi">Topic Modelling</span> with <span style="font-weight:bold" itemprop="hi">Select Columns</span> and the latter with <span style="font-weight:bold" itemprop="hi">Edit Domain.</span></p><p id="p-99"><span><a class="numberParagraphLink" href="#p-99" title="number paragraph link"><span class="numberParagraph">6</span></a></span>First, let's open <span style="font-weight:bold" itemprop="hi">Select Columns</span>, where we see the entire variable list, including word frequencies, which we created with <span style="font-weight:bold" itemprop="hi">Bag of Words</span> for topic modelling. These variables are no longer needed, so we remove them by selecting all the variables using Ctrl+A in Windows or Cmd+A in MacOS in the <span style="font-style:italic" itemprop="hi">Features</span> section and drag-and-drop them to the left side, where all the variables we would like to ignore are placed. We enter <span style="font-style:italic" itemprop="hi">Topic</span> in the filter on the left side, which lists only variables containing the name <span style="font-style:italic" itemprop="hi">Topic</span> (i.e., Topic 1, Topic 2). Next, we select them and transfer them back to the right side, where all the variables we would like to include in the analysis are placed (<a class="link_ref" itemprop="ref" href="ch6.html#figure.15" title="Figure 15 The list of variables in Select Columns.">Figure 15</a>).</p><figure id="figure.15"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure15_select-columns.png/full/,600/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure15_select-columns.png" alt="Figure 15: The list of variables in Select Columns." /><figcaption><figcaption class="caption" itemprop="head"><b></b>Figure 15: The list of variables in Select Columns.</figcaption></figcaption></figure><br /><br /><p id="p-100"><span><a class="numberParagraphLink" href="#p-100" title="number paragraph link"><span class="numberParagraph">7</span></a></span>Then we open <span style="font-weight:bold" itemprop="hi">Edit Domain,</span> in which we will name the topics. From the list on the left, we select the first topic and set its name in the <span style="font-style:italic" itemprop="hi">Name</span> field on the right, i.e., <span style="font-style:italic" itemprop="hi">T1: UK &amp; nation</span> (<a class="link_ref" itemprop="ref" href="ch6.html#figure.16" title="Figure 16 Renaming of topics in the Edit Domain widget.">Figure 16</a>). Naming the topics can help interpret the visualizations, which we will use later to explore the topics.</p><figure id="figure.16"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure16_edit-domain.png/full/,600/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure16_edit-domain.png" alt="Figure 16: Renaming of topics in the Edit Domain widget." /><figcaption><figcaption class="caption" itemprop="head"><b></b>Figure 16: Renaming of topics in the Edit Domain widget.</figcaption></figcaption></figure><br /><br /><p id="p-101"><span><a class="numberParagraphLink" href="#p-101" title="number paragraph link"><span class="numberParagraph">8</span></a></span>Once the topics are named, we get a list of topics MPs debated between January 2019 and December 2020. Unsurprisingly, we find some epidemic-specific topics on the list, such as <span style="font-style:italic" itemprop="hi">virus and politics</span> and <span style="font-style:italic" itemprop="hi">vaccination</span>. Others, such as <span style="font-style:italic" itemprop="hi">UK &amp; nation</span> and <span style="font-style:italic" itemprop="hi">media freedom</span>, might be more difficult to name if we are unfamiliar with the concurrent events. Roughly, the topics cover the ministry areas, such as security, trade, economy, higher education, transport, and crime. At the same time, looking at the list of missing topics, which one would generally expect to see covered, is telling (i.e., health and social care). The fact that certain topics are missing from the list does not mean the MPs did not debate them, but it does show they were not talked about as much, or that they were debated only in combination with other topics (i.e., the pandemic).</p><p id="p-102"><span><a class="numberParagraphLink" href="#p-102" title="number paragraph link"><span class="numberParagraph">9</span></a></span>Such a list of topics enables a quick overview of the themes that characterised parliamentary debates at a given time. However, these results do not reveal additional information, such as which topic was debated the most, how the topics are related to one another and what the topical differences between different periods are. To answer these questions, we have to analyse the results further, which we will do in the following chapters. However, we will inspect how the topics are distributed in the corpus before doing so. In this way, we can better understand the context of speeches and, if necessary, adjust the names of the topics. At the same time, it is a great way to retrieve the speeches where a certain topic is prevalent.</p><div id="note-19" class="callout warning"><p id="index-p-d46e3826"><span class="numberParagraph">1</span>Try it yourself: name all the topics with a suitable label. Some topics will be harder to define. You can use <span style="font-weight:bold" itemprop="hi">Corpus Viewer</span> to find a word from the topic and explore its context.</p></div></div><div class="subchapter" id="ch6.1.4"><h4><span class="head" itemprop="head" id="head-51">6.1.4. Distribution of topics in a corpus</span></h4><p id="p-104"><span><a class="numberParagraphLink" href="#p-104" title="number paragraph link"><span class="numberParagraph">1</span></a></span>Due to the nature of topic modelling (see <a class="link_ref" itemprop="ref" href="ch4.html" title="4. Topic modelling">Chapter 4</a>), the speeches are characterised by more than a single topic, but topics will have different frequencies in different documents. Topic frequency or the likelihood of the topic in the speech is given between 0 and 1, where 1 means the topic fully characterizes the speech and 0 means the topic does not characterize it. Since we deal with values on the same scale and want to compare topic frequency, the most suitable visualization is the heat map. Connect the <span style="font-weight:bold" itemprop="hi">Heat Map</span> widget with <span style="font-weight:bold" itemprop="hi">Edit Domain.</span></p><p id="p-105"><span><a class="numberParagraphLink" href="#p-105" title="number paragraph link"><span class="numberParagraph">2</span></a></span>Colour represents the value in the visualisation: high values are displayed in yellow and white (or any other colour on the right side of the colour scale). In contrast, low values are displayed in blue (or any other colour on the left side of the scale). Each column represents a topic, and each row a speech. In the visualization, the speeches are displayed in the same order they were read initially, making the diagram quite difficult to interpret. A couple of settings can fix this.</p><p id="p-106"><span><a class="numberParagraphLink" href="#p-106" title="number paragraph link"><span class="numberParagraph">3</span></a></span>First, we will join speeches with similar topic distributions. We are dealing with many speeches (130,453), so the visualization is extremely tall. We can represent very similar speeches with a single line and make the visualisation more compact. To do this, use <span style="font-style:italic" itemprop="hi">Merge by k-means</span>, which uses the k-means method to join similar speeches. The default value is 50, but we will increase it to 500 because we have many speeches and do not want to lose too many details.</p><p id="p-107"><span><a class="numberParagraphLink" href="#p-107" title="number paragraph link"><span class="numberParagraph">4</span></a></span>Visualization is now more organised, but it would be even more informative if similar rows lay close to each other. Note that each row is no longer a single speech but a group of similar speeches. Rows can be further organised with another clustering technique, which we set in the <span style="font-style:italic" itemprop="hi">Clustering </span>section. Set the <span style="font-style:italic" itemprop="hi">Rows</span> option to <span style="font-style:italic" itemprop="hi">Clustering (opt. ordering)</span>.</p><figure id="figure.17"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure17_heat-map.png/full/,600/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure17_heat-map.png" alt="Figure 17: A heat map of topic frequency. The selected branch of the dendrogram contains topics with a highly expressed T8: constituency-related issues topic." /><figcaption><figcaption class="caption" itemprop="head"><b></b>Figure 17: A heat map of topic frequency. The selected branch of the dendrogram contains topics with a highly expressed T8: constituency-related issues topic.</figcaption></figcaption></figure><br /><br /><p id="p-108"><span><a class="numberParagraphLink" href="#p-108" title="number paragraph link"><span class="numberParagraph">5</span></a></span>We see a much nicer diagram (<a class="link_ref" itemprop="ref" href="ch6.html#figure.17" title="Figure 17 A heat map of topic frequency. The selected branch of the dendrogram contains topics with a highly expressed T8 const...">Figure 17</a>) with a dendrogram on the left side. A dendrogram is a tree-like structure of speech similarity, which shows connections between groups and enables an easy speech selection. In the previous chapter, we learned that the interpretation of certain topics is not quite clear, for example, <span style="font-style:italic" itemprop="hi">constituency-related issues</span>. The diagram enables selecting speeches for a highly expressed topic, which can be inspected further.</p><p id="p-109"><span><a class="numberParagraphLink" href="#p-109" title="number paragraph link"><span class="numberParagraph">6</span></a></span>We have selected <span style="font-style:italic" itemprop="hi">T8: constituency-related issues</span> for further observation. Speeches are selected by clicking on a branch in the dendrogram, where the topic is most expressed (yellow or green colour). Clicking will send the selected subgroup to the output of the widget. Now add <span style="font-weight:bold" itemprop="hi">Corpus Viewer</span> to <span style="font-weight:bold" itemprop="hi">Heat Map</span> to read a couple of speeches.</p><p id="p-110"><span><a class="numberParagraphLink" href="#p-110" title="number paragraph link"><span class="numberParagraph">7</span></a></span>The speeches deal with various topics concerning MPs’ constituents, from access to health care to discrimination against minorities. In this way, we have clarified the topic label and selected a subset of speeches on a given topic, which we can use for downstream analyses.</p><p id="p-111"><span><a class="numberParagraphLink" href="#p-111" title="number paragraph link"><span class="numberParagraph">8</span></a></span>When interpreting the results of topic modelling, we need to consider that a speech is not characterised by a single topic but a mixture of them, which we can see for the topic <span style="font-style:italic" itemprop="hi">T4: trade</span>. If we select the speeches and give them a careful read, we will see that they touch upon various topics, including the new taxation of foreign goods after Brexit. The topic is also evident from the diagram, where certain topics with high values of <span style="font-style:italic" itemprop="hi">T4</span> also have high values of <span style="font-style:italic" itemprop="hi">T3: legislative</span>. These two topics thus overlap in certain points as already evident from the heat map. The visualisation is great for investigating topic overlap, which is crucial if we are interested in selecting speeches on a given topic for further analysis.</p><div id="note-20" class="callout warning"><p id="index-p-d46e3901"><span class="numberParagraph">1</span>Try it yourself: select speeches about the virus and politics and explore them.</p></div></div></div><div class="subchapter" id="ch6.2"><h3><span class="head" itemprop="head" id="head-53">6.2. Topic map</span></h3><p id="p-113"><span><a class="numberParagraphLink" href="#p-113" title="number paragraph link"><span class="numberParagraph">1</span></a></span>Now we know the distribution of topics by speech. We have learned that several topics characterise a speech, so we would like to know how the topics are related to one another. Besides, we would like to know which topics are the most prevalent in our corpus. To answer these two questions, we will use a topic map, where the topics will be positioned based on their similarity to one another and marked by their frequency.</p><p id="p-114"><span><a class="numberParagraphLink" href="#p-114" title="number paragraph link"><span class="numberParagraph">2</span></a></span>We will construct the map with <span style="font-weight:bold" itemprop="hi">MDS</span>, which is short for <span style="font-style:italic" itemprop="hi">multidimensional scaling</span>. The visualisation tries to find a projection in a 2-dimensional space such that related topics lie close to one another and those unrelated are far apart. MDS computes topic relatedness based on the importance of words in the topic. High relatedness means a very similar word distribution, where some words can be even shared among the topics.</p><p id="p-115"><span><a class="numberParagraphLink" href="#p-115" title="number paragraph link"><span class="numberParagraph">3</span></a></span>We set the connection between <span style="font-weight:bold" itemprop="hi">Topic Modelling</span> and <span style="font-weight:bold" itemprop="hi">MDS</span> by connecting <span style="font-style:italic" itemprop="hi">All Topics</span> to <span style="font-style:italic" itemprop="hi">Data</span>. In the beginning, we will see only grey points in space. A point represents a topic. For easier interpretation, we will label the points. We do this by setting <span style="font-style:italic" itemprop="hi">Labels</span> to <span style="font-style:italic" itemprop="hi">Topics</span>. Each point will be marked with a topic name – not the one we gave them in <span style="font-weight:bold" itemprop="hi">Edit Domain</span>, but the original names. Thus, we need to use a manually created list of topics for interpretation (<a class="link_ref" itemprop="ref" href="ch6.html#table.1" title="Table 1 A list of topics with the original and assigned label. Topic name Assigned label Topic 1T1 UK  nationTopic 2T2 security...">Table 1</a>).</p><div class="rules" itemprop="table" id="table.1"><table style="border-collapse:collapse;border-spacing:0;"><caption>Table 1: A list of topics with the original and assigned label.</caption><tr itemprop="row"><td class="center"><span style="font-weight:bold" itemprop="hi">Topic name</span></td><td class="center"><span style="font-weight:bold" itemprop="hi">Assigned label</span></td></tr><tr itemprop="row"><td class="left">Topic 1</td><td class="left">T1: UK &amp; nation</td></tr><tr itemprop="row"><td class="left">Topic 2</td><td class="left">T2: security</td></tr><tr itemprop="row"><td class="left">Topic 3</td><td class="left">T3: legislative</td></tr><tr itemprop="row"><td class="left">Topic 4</td><td class="left">T4: trade</td></tr><tr itemprop="row"><td class="left">Topic 5</td><td class="left">T5: procedural</td></tr><tr itemprop="row"><td class="left">Topic 6</td><td class="left">T6: business &amp; industry</td></tr><tr itemprop="row"><td class="left">Topic 7</td><td class="left">T7: virus and politics</td></tr><tr itemprop="row"><td class="left">Topic 8</td><td class="left">T8: constituency-related issues</td></tr><tr itemprop="row"><td class="left">Topic 9</td><td class="left">T9: pandemic and energy transition</td></tr><tr itemprop="row"><td class="left">Topic 10</td><td class="left">T10: economy</td></tr><tr itemprop="row"><td class="left">Topic 11</td><td class="left">T11: sports</td></tr><tr itemprop="row"><td class="left">Topic 12</td><td class="left">T12: child well-being</td></tr><tr itemprop="row"><td class="left">Topic 13</td><td class="left">T13: climate change</td></tr><tr itemprop="row"><td class="left">Topic 14</td><td class="left">T14: vaccination</td></tr><tr itemprop="row"><td class="left">Topic 15</td><td class="left">T15: higher education</td></tr><tr itemprop="row"><td class="left">Topic 16</td><td class="left">T16: media freedom</td></tr><tr itemprop="row"><td class="left">Topic 17</td><td class="left">T17: schools in pandemic</td></tr><tr itemprop="row"><td class="left">Topic 18</td><td class="left">T18: transport</td></tr><tr itemprop="row"><td class="left">Topic 19</td><td class="left">T19: crime</td></tr><tr itemprop="row"><td class="left">Topic 20</td><td class="left">T20: housing</td></tr></table></div><p id="p-116"><span><a class="numberParagraphLink" href="#p-116" title="number paragraph link"><span class="numberParagraph">4</span></a></span>We will also set the size of the points to match the frequency of the topic (which is the sum of topic probability in all the speeches, weighted by the length of the speech). Set the <span style="font-style:italic" itemprop="hi">Size</span> option to <span style="font-style:italic" itemprop="hi">Marginal Topic Probability</span>. To make things even clearer, set the <span style="font-style:italic" itemprop="hi">Color</span> to <span style="font-style:italic" itemprop="hi">Marginal Topic Probability</span>.</p><figure id="figure.18"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure18_mds.png/full/,600/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure18_mds.png" alt="Figure 18: Displaying topic relatedness in MDS." /><figcaption><figcaption class="caption" itemprop="head"><b></b>Figure 18: Displaying topic relatedness in MDS.</figcaption></figcaption></figure><br /><br /><p id="p-117"><span><a class="numberParagraphLink" href="#p-117" title="number paragraph link"><span class="numberParagraph">5</span></a></span>Thematic map displays topic relatedness with the position of the points, while the size and the colour show how frequent the topic is (<a class="link_ref" itemprop="ref" href="ch6.html#figure.18" title="Figure 18 Displaying topic relatedness in MDS.">Figure 18</a>). When topics are related, but the points lie far apart due to the limitations of the 2-dimensional display, the relatedness is marked with a line between the points. The most frequent topics are <span style="font-style:italic" itemprop="hi">T3: legislative</span> and <span style="font-style:italic" itemprop="hi">T8: constituency-related issues</span>, while narrower topics such as <span style="font-style:italic" itemprop="hi">T11: sports</span>, <span style="font-style:italic" itemprop="hi">T13: climate change</span> and <span style="font-style:italic" itemprop="hi">T14: vaccination</span> are the least frequent.</p><p id="p-118"><span><a class="numberParagraphLink" href="#p-118" title="number paragraph link"><span class="numberParagraph">6</span></a></span>The high frequency of Topic 3 (<span style="font-style:italic" itemprop="hi">legislative</span>) is unsurprising, as the parliament is the main legislative body of the state. It is placed close to Topic 5 (<span style="font-style:italic" itemprop="hi">procedural</span>), which means legislative speeches contain a lot of procedural words. It is also close to Topic 7 (<span style="font-style:italic" itemprop="hi">virus and politics</span>), which shows that the government had to adopt certain legislative measures to combat the pandemic. Topic 7 is also close to Topic 8 (<span style="font-style:italic" itemprop="hi">constituency-related issues</span>), which could mean there was a debate on translating pandemic measures into a local environment.</p><figure id="figure-27"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure0.10.png/full/max/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure0.10.png" alt="" /><figcaption></figcaption></figure><br /><br /><p id="p-119"><span><a class="numberParagraphLink" href="#p-119" title="number paragraph link"><span class="numberParagraph">7</span></a></span>In short, topics that lie close to each other or are connected with a line are related. However, sometimes it is not easy to understand how the two topics are related — for example, Topic 1 (<span style="font-style:italic" itemprop="hi">UK &amp; nation</span>) and Topic 16 (<span style="font-style:italic" itemprop="hi">media freedom</span>). To better understand this connection, we can review the speeches with a high frequency of both topics.</p><p id="p-120"><span><a class="numberParagraphLink" href="#p-120" title="number paragraph link"><span class="numberParagraph">8</span></a></span>First, we will create a subcorpus with a strong presence of topics <span style="font-style:italic" itemprop="hi">T1: UK &amp; nation</span> and <span style="font-style:italic" itemprop="hi">T16: media freedom</span>. We do this with the <span style="font-weight:bold" itemprop="hi">Select Rows</span> widget, which we will connect to <span style="font-weight:bold" itemprop="hi">Topic Modelling</span>. We have to set two conditions in the <span style="font-weight:bold" itemprop="hi">Select Rows </span>widget: <span style="font-style:italic" itemprop="hi">Topic 1 is greater than 0.4,</span> and <span style="font-style:italic" itemprop="hi">Topic 16 is greater than 0.4</span> (<a class="link_ref" itemprop="ref" href="ch6.html#figure.19" title="Figure 19 Setting the threshold in the Select Rows widget.">Figure 19</a>). We will select the speeches where the two topics are present with over 40-percent probability.<span id="ftn16_return"><a class="notelink" title="The threshold of 40 percent is selected because it is the lowest value which returns at least a couple of documents. One should be aware that the thre…" href="#ftn16"><sup>16</sup></a></span></p><figure id="figure.19"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure19_select-rows.png/full/,600/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure19_select-rows.png" alt="Figure 19: Setting the threshold in the Select Rows widget." /><figcaption><figcaption class="caption" itemprop="head"><b></b>Figure 19: Setting the threshold in the Select Rows widget.</figcaption></figcaption></figure><br /><br /><p id="p-121"><span><a class="numberParagraphLink" href="#p-121" title="number paragraph link"><span class="numberParagraph">9</span></a></span><span style="font-weight:bold" itemprop="hi">Select Rows</span> is then connected to <span style="font-weight:bold" itemprop="hi">Corpus Viewer</span>, which displays the selected 26 speeches at the intersection of nation and media (<a class="link_ref" itemprop="ref" href="ch6.html#figure.20" title="Figure 20 Overview of the selected speeches in the Corpus Viewer widget.">Figure 20</a>). It is clear from the speeches that they refer to internal matters of organisation of the two Houses of the Parliament and the specific roles given to the MPs.</p><figure id="figure.20"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure20_corpus-viewer.png/full/,600/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure20_corpus-viewer.png" alt="Figure 20: Overview of the selected speeches in the Corpus Viewer widget." /><figcaption><figcaption class="caption" itemprop="head"><b></b>Figure 20: Overview of the selected speeches in the Corpus Viewer widget.</figcaption></figcaption></figure><br /><br /><div id="note-22" class="callout warning"><p id="index-p-d46e4169"><span class="numberParagraph">1</span>Try it yourself: Explore the Topics 3 and 5 in the same way.</p></div></div><div class="subchapter" id="ch6.3"><h3><span class="head" itemprop="head" id="head-58">6.3. Topics before and during the pandemic</span></h3><p id="p-123"><span><a class="numberParagraphLink" href="#p-123" title="number paragraph link"><span class="numberParagraph">1</span></a></span>We identified the topics which stand out the most in our corpus, but now we would like to investigate which topics are the most characteristic of the pre-pandemic and the pandemic periods. The differences between the two periods (already labelled in the data with <span style="font-style:italic" itemprop="hi">Reference</span> and <span style="font-style:italic" itemprop="hi">COVID</span>) can be explored with <span style="font-weight:bold" itemprop="hi">Box Plot</span>. The visualisation, also known as a box-and-whisker plot, shows the distribution of the variable and enables an easy comparison of topic probability by <a class="link_ref" itemprop="ref" href="https://en.wikipedia.org/wiki/Categorical_variable">categorical variables</a> (i.e., gender, date, party).</p><p id="p-124"><span><a class="numberParagraphLink" href="#p-124" title="number paragraph link"><span class="numberParagraph">2</span></a></span>Connect <span style="font-weight:bold" itemprop="hi">Box Plot</span> to <span style="font-weight:bold" itemprop="hi">Edit Domain</span>, which will keep our assigned topic labels. As we wish to compare two periods, select the <span style="font-style:italic" itemprop="hi">Subcorpus</span> variable in the lower-left section of the widget. In the upper left section, select <span style="font-style:italic" itemprop="hi">T1: UK &amp; nation</span>. On the right side, we will see two box plots, the upper for the pandemic period (<span style="font-style:italic" itemprop="hi">COVID</span>) and the lower for the pre-pandemic period (<span style="font-style:italic" itemprop="hi">Reference</span>) (<a class="link_ref" itemprop="ref" href="ch6.html#figure.21" title="Figure 21 Box plot for topic T1 UK  nation before and during the pandemic.">Figure 21</a>). The visualisation shows that the debates on the UK nation were more frequent before the pandemic than during the pandemic. At the same time, the test result below the plot shows that the difference is statistically significant, as its p-value is below 0.05. We can conclude that historical topics were more frequent before the pandemic based on this information.</p><figure id="figure.21"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure21_box-plot1.png/full/,600/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure21_box-plot1.png" alt="Figure 21: Box plot for topic T1: UK &amp; nation before and during the pandemic." /><figcaption><figcaption class="caption" itemprop="head"><b></b>Figure 21: Box plot for topic T1: UK &amp; nation before and during the pandemic.</figcaption></figcaption></figure><br /><br /><figure id="figure-31"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure0.11.png/full/max/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure0.11.png" alt="" /><figcaption></figcaption></figure><br /><br /><p id="p-125"><span><a class="numberParagraphLink" href="#p-125" title="number paragraph link"><span class="numberParagraph">3</span></a></span>We could inspect the distribution for every topic separately, but this would be quite laborious. Since we are not focusing on a single topic but would like to understand which topics show the most difference between the two periods, we will use the <span style="font-style:italic" itemprop="hi">Order by relevance to subgroups</span> option in the <span style="font-style:italic" itemprop="hi">Variable</span> section. This option will sort the variables based on the results of the statistical test. At the top, we will see those variables that show the greatest difference for the selected categories, which we defined in the <span style="font-style:italic" itemprop="hi">Subgroups</span> section (the <span style="font-style:italic" itemprop="hi">Subcorpus</span> variable).</p><p id="p-126"><span><a class="numberParagraphLink" href="#p-126" title="number paragraph link"><span class="numberParagraph">4</span></a></span>At the top of the list, we will see the variables such as <span style="font-style:italic" itemprop="hi">category</span>, <span style="font-style:italic" itemprop="hi">From, To, </span>and <span style="font-style:italic" itemprop="hi">Term.</span> These variables show the greatest differences between <span style="font-style:italic" itemprop="hi">Reference</span> and <span style="font-style:italic" itemprop="hi">COVID</span> subcorpora. The difference is unsurprising since these variables are time-related, which was also a criterion for forming the two subcorpora (see Chapter 5.3). We are more interested in the variables following these four.</p><p id="p-127"><span><a class="numberParagraphLink" href="#p-127" title="number paragraph link"><span class="numberParagraph">5</span></a></span>At the top are the topics <span style="font-style:italic" itemprop="hi">T7: virus and politics</span> (<a class="link_ref" itemprop="ref" href="ch6.html#figure.22" title="Figure 22 Box plot for topic T7 virus and politics.">Figure 22</a>) and <span style="font-style:italic" itemprop="hi">T17: schools in a pandemic</span>. Once we select one of them, the visualisation on the right shows that the MPs talked more about the virus and politics in the pre-pandemic period and more about the school in the, unsurprisingly, pandemic period. The Student's t-test (57.184, p&lt;0.05) below the plot shows that the difference between the two periods is significant and that the topic is more prominent in the given period. The result for Topic 17 is unsurprising, but the result for Topic 7 is a little strange. One would expect the speeches on the virus to be more prominent during the pandemic. Looking at the speeches in <span style="font-weight:bold" itemprop="hi">Corpus Viewer</span>, this is indeed the case – all the speeches containing the word »virus« come from the <span style="font-style:italic" itemprop="hi">COVID</span> period. We see that these speeches talk about the virus in the context of the EU response to the pandemic (making it likely that the virus under consideration is indeed the coronavirus and not some other pathogen). However, the significance of the pre-pandemic period in this case is due to a large portion of speeches belonging to the pre-pandemic period. Skimming through the speeches, we can see that the topic consists of speeches covering a range of EU-related issues linked to Brexit which was in the spotlight before the COVID outbreak.</p><figure id="figure.22"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure22_box-plot2.png/full/,600/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure22_box-plot2.png" alt="Figure 22: Box plot for topic T7: virus and politics." /><figcaption><figcaption class="caption" itemprop="head"><b></b>Figure 22: Box plot for topic T7: virus and politics.</figcaption></figcaption></figure><br /><br /><p id="p-128"><span><a class="numberParagraphLink" href="#p-128" title="number paragraph link"><span class="numberParagraph">6</span></a></span>The results show the usefulness of topic modelling, but they also point out how vital it is to understand the corpus and explore the speeches with close reading.</p><p id="p-129"><span><a class="numberParagraphLink" href="#p-129" title="number paragraph link"><span class="numberParagraph">7</span></a></span>The topics can be further explored with <span style="font-weight:bold" itemprop="hi">Select Rows</span> and <span style="font-weight:bold" itemprop="hi">Corpus Viewer</span>. Connect <span style="font-weight:bold" itemprop="hi">Select Rows</span> to<span style="font-weight:bold" itemprop="hi">Edit Domain.</span> In <span style="font-weight:bold" itemprop="hi">Select Rows</span>, set <span style="font-style:italic" itemprop="hi">T7: virus and politics is greater than 0.98</span>, by which we will output only the speeches with more than 98% likelihood of T7. The selected speeches can be inspected in <span style="font-weight:bold" itemprop="hi">Corpus Viewer</span> or with <span style="font-weight:bold" itemprop="hi">Word Cloud.</span></p><p id="p-130"><span><a class="numberParagraphLink" href="#p-130" title="number paragraph link"><span class="numberParagraph">8</span></a></span><span style="font-weight:bold" itemprop="hi">Corpus Viewer</span> enables us to explore the context of a given word. Let’s say we are interested in learning more about the lemma »vote«, which is characteristic of Topic 7 (see <a class="link_ref" itemprop="ref" href="ch6.html#ch6.1.2" title="6.1.2. Topic modelling">Chapter 6.1.2</a>). We have already selected speeches with a high frequency of Topic 7, which outputs 62 speeches. We would like to see which out of those contain the lemma »vote«. We can enter the lemma in the filter at the top of the widget and press <span style="font-style:italic" itemprop="hi">Enter</span>. The widget will display the speeches where the lemma »vote« appears – there are 36 such speeches. Indeed, we can see that the speeches refer to the relationship with the EU (<a class="link_ref" itemprop="ref" href="ch6.html#figure.23" title="Figure 23 Corpus Viewer with speeches containing the word vote.">Figure 23</a>).</p><figure id="figure.23"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure23_corpus-viewer.png/full/,600/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure23_corpus-viewer.png" alt="Figure 23: Corpus Viewer with speeches containing the word &#34;vote&#34;." /><figcaption><figcaption class="caption" itemprop="head"><b></b>Figure 23: Corpus Viewer with speeches containing the word "vote".</figcaption></figcaption></figure><br /><br /><p id="p-131"><span><a class="numberParagraphLink" href="#p-131" title="number paragraph link"><span class="numberParagraph">9</span></a></span>An alternative option is to display the most frequent lemmas for the topic in a <span style="font-weight:bold" itemprop="hi">Word Cloud</span>. Word cloud would give an in-depth look into the concepts discussed in this topic (<a class="link_ref" itemprop="ref" href="ch6.html#figure.24" title="Figure 24 Word cloud of the most frequent words in Topic 7.">Figure 24</a>).</p><figure id="figure.24"><img class="imageviewer" src="https://sidih.si/iiif/2/entity|2001-3000|2177|Figure24_word-cloud.png/full/,600/0/default.jpg" data-high-res-src="https://sidih.si/cdn/2177/Figure24_word-cloud.png" alt="Figure 24: Word cloud of the most frequent words in Topic 7." /><figcaption><figcaption class="caption" itemprop="head"><b></b>Figure 24: Word cloud of the most frequent words in Topic 7.</figcaption></figcaption></figure><br /><br /><p id="p-132"><span><a class="numberParagraphLink" href="#p-132" title="number paragraph link"><span class="numberParagraph">10</span></a></span>The speeches mostly refer to <span style="font-style:italic" itemprop="hi">deals, voting, government, people,</span> and <span style="font-style:italic" itemprop="hi">extension</span>. Considering that the lemma <span style="font-style:italic" itemprop="hi">referendum</span> is also quite prominent, these speeches probably refer to Brexit. While almost exclusively present in this topic, it seems like the word virus is generally quite infrequent in these speeches. The results indicate <span style="font-style:italic" itemprop="hi">virus</span> has to be interpreted in the context of other words characterising Topic 7. It is vital to compare the frequency of characteristic words for the topic and the frequency of words in the corpus (like we did in <a class="link_ref" itemprop="ref" href="ch6.html#ch6.1.3" title="6.1.3. Topic definition">Chapter 6.1.3</a>) to ensure accurate topic interpretation.</p><div id="note-23" class="callout warning"><p id="index-p-d46e4345"><span class="numberParagraph">1</span>Try it yourself: In the same way we compared the subcorpora <span style="font-style:italic" itemprop="hi">Reference</span> and <span style="font-style:italic" itemprop="hi">COVID</span>, compare the distribution of topics in opposition and coalition speeches.</p></div></div></div><div class="row"><div class="small-6 columns text-center"><p><a class="button" href="ch5.html" title="Previous: 5. Preparing for the analysis">&lt;&lt;</a></p></div><div class="small-6 columns text-center"><p><a class="button" href="ch7.html" title="Next: 7. Conclusion">&gt;&gt;</a></p></div></div><!--Notes in [div]--><div class="notes"><div class="noteHeading">Notes</div><div class="note" id="ftn15"><p><a class="link_return" title="Pojdi nazaj k besedilu" href="#ftn15_return"><sup>15.</sup></a> <span class="noteBody">It is possible to get a different result with LDA than seen in the tutorial. LDA is a generative model, which initiates randomly. You should always be able to get the same results on your computer, but the results can differ between different versions of Orange and different operating systems.</span></p></div><div class="note" id="ftn16"><p><a class="link_return" title="Pojdi nazaj k besedilu" href="#ftn16_return"><sup>16.</sup></a> <span class="noteBody">The threshold of 40 percent is selected because it is the lowest value which returns at least a couple of documents. One should be aware that the threshold is low, which means the speeches do not have a very high likelihood of the two topics. The value can be adjusted freely.</span></p></div></div><div class="row"><div class="small-6 columns text-center"><p><a class="button" href="ch5.html" title="Previous: 5. Preparing for the analysis">&lt;&lt;</a></p></div><div class="small-6 columns text-center"><p><a class="button" href="ch7.html" title="Next: 7. Conclusion">&gt;&gt;</a></p></div></div></section></div><script type="text/javascript">
         
         $(function () {
         var viewer = ImageViewer();
         $('.imageviewer').click(function () {
         var imgSrc = this.src,
         highResolutionImage = $(this).data('high-res-src');
         viewer.show(imgSrc, highResolutionImage);
         });
         });
      </script><script src="https://www2.sistory.si/publikacije/themes/foundation/6/js/vendor/what-input.js"></script><script src="https://www2.sistory.si/publikacije/themes/foundation/6/js/vendor/foundation.min.js"></script><script src="https://www2.sistory.si/publikacije/themes/foundation/6/js/app.js"></script><script src="https://www2.sistory.si/publikacije/themes/js/plugin/back-to-top/back-to-top.js"></script></body></html>